import json
import os
import numpy as np
import matplotlib.pyplot as plt

from scipy.ndimage import gaussian_filter1d

from .context_manager import SpectroState
from .base_agent import BaseAgent
from .mcp_manager import MCPManager

from .utils import (
    _detect_axis_ticks, _detect_chart_border, _crop_img,
    _remap_to_cropped_canvas, _pixel_tickvalue_fitting,
    _process_and_extract_curve_points, _convert_to_spectrum,
    _find_features_multiscale, _plot_spectrum, _plot_features,
    parse_list, getenv_float, getenv_int, _load_feature_params, 
    _ROI_features_finding, merge_features, plot_merged_features, safe_to_bool
)

# ---------------------------------------------------------
# 1. Visual Assistant â€” è´Ÿè´£å›¾åƒç†è§£ä¸åæ ‡é˜…è¯»
# ---------------------------------------------------------

class SpectralVisualInterpreter(BaseAgent):
    """
    SpectralVisualInterpreter

    ä»ç§‘å­¦å…‰è°±å›¾ä¸­è‡ªåŠ¨æå–åæ ‡è½´åˆ»åº¦ã€è¾¹æ¡†ã€åƒç´ æ˜ å°„ã€å³°/è°·ç­‰ä¿¡æ¯
    """

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Visual Interpreter',
            mcp_manager=mcp_manager
        )

    # --------------------------
    # Step 1.1: æ£€æµ‹åæ ‡è½´åˆ»åº¦
    # --------------------------
    async def detect_axis_ticks(self, state: SpectroState):
        """
        è°ƒç”¨è§†è§‰ LLM æ£€æµ‹åæ ‡è½´åˆ»åº¦ï¼Œå¦‚æœæ— å›¾åƒæˆ–éå…‰è°±å›¾æŠ¥é”™
        """
        class NoImageError(Exception): pass
        class NotSpectralImageError(Exception): pass

        if not state['image_path'] or not os.path.exists(state['image_path']):
            print(state['image_path'])
            raise NoImageError("âŒ æœªè¾“å…¥å›¾åƒæˆ–å›¾åƒè·¯å¾„ä¸å­˜åœ¨")

        system_prompt = state['prompt'][f'{self.agent_name}']['detect_axis_ticks']['system_prompt']
        user_prompt = state['prompt'][f'{self.agent_name}']['detect_axis_ticks']['user_prompt']

        axis_info = await self.call_llm_with_context(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            image_path=state['image_path'],
            parse_json=True,
            description="åæ ‡è½´ä¿¡æ¯"
        )
        if axis_info == "éå…‰è°±å›¾":
            raise NotSpectralImageError(f"âŒ å›¾åƒä¸æ˜¯å…‰è°±å›¾ï¼ŒLLM è¾“å‡º: {axis_info}")
        # print(axis_info)
        state["axis_info"] = axis_info

    # --------------------------
    # Step 1.2~1.3: åˆå¹¶è§†è§‰+OCRåˆ»åº¦
    # --------------------------
    async def combine_axis_mapping(self, state: SpectroState):
        """ç»“åˆè§†è§‰ç»“æœä¸ OCR ç»“æœç”Ÿæˆåƒç´ -æ•°å€¼æ˜ å°„"""
        axis_info_json = json.dumps(state['axis_info'], ensure_ascii=False)
        ocr_json = json.dumps(state['OCR_detected_ticks'], ensure_ascii=False)

        system_prompt = state['prompt'][f'{self.agent_name}']['combine_axis_mapping']['system_prompt']
        user_prompt = state['prompt'][f'{self.agent_name}']['combine_axis_mapping']['user_prompt'].format(
            axis_info_json=axis_info_json,
            ocr_json=ocr_json
        )
        tick_pixel_raw = await self.call_llm_with_context(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            image_path=None,
            parse_json=True,
            description="åˆ»åº¦-åƒç´ æ˜ å°„"
        )
        state["tick_pixel_raw"] = tick_pixel_raw

    # --------------------------
    # Step 1.4: æ ¡éªŒä¸ä¿®æ­£
    # --------------------------
    async def revise_axis_mapping(self, state: SpectroState):
        """æ£€æŸ¥å¹¶ä¿®æ­£åˆ»åº¦å€¼ä¸åƒç´ ä½ç½®åŒ¹é…å…³ç³»"""
        axis_mapping_json = json.dumps(state['tick_pixel_raw'], ensure_ascii=False)

        system_prompt = state['prompt'][f'{self.agent_name}']['revise_axis_mapping']['system_prompt']
        user_prompt = state['prompt'][f'{self.agent_name}']['revise_axis_mapping']['user_prompt'].format(
            axis_mapping_json=axis_mapping_json
        )

        tick_pixel_revised = await self.call_llm_with_context(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            image_path=None,
            parse_json=True,
            description="ä¿®æ­£åçš„åˆ»åº¦æ˜ å°„"
        )
        state["tick_pixel_raw"] = tick_pixel_revised
        # print(tick_pixel_revised)

    # --------------------------
    # Step 1.1~1.11: ä¸»æµç¨‹
    # --------------------------
    async def run(self, state: SpectroState, plot: bool = True):
        """æ‰§è¡Œå®Œæ•´è§†è§‰åˆ†ææµç¨‹"""
        try:
            # Step 1.1: è§†è§‰ LLM æå–åæ ‡è½´
            await self.detect_axis_ticks(state)

            # Step 1.2: OCR æå–åˆ»åº¦
            state["OCR_detected_ticks"] = _detect_axis_ticks(state['image_path'])
            # for i in state["OCR_detected_ticks"]:
            #     print(i)

            # Step 1.3: åˆå¹¶
            await self.combine_axis_mapping(state)
            # for i in state["tick_pixel_raw"]:
            #     print(i)

            # Step 1.4: ä¿®æ­£
            await self.revise_axis_mapping(state)
            # for i in state["tick_pixel_raw"]:
            #     print(i)

            # Step 1.5: è¾¹æ¡†æ£€æµ‹ä¸è£å‰ª
            state["chart_border"] = _detect_chart_border(state['image_path'])
            _crop_img(state['image_path'], state["chart_border"], state['crop_path'])

            # Step 1.6: é‡æ˜ å°„åƒç´ 
            state["tick_pixel_remap"] = _remap_to_cropped_canvas(state['tick_pixel_raw'], state["chart_border"])

            # Step 1.7: æ‹Ÿåˆåƒç´ -æ•°å€¼
            state["pixel_to_value"] = _pixel_tickvalue_fitting(state['tick_pixel_remap'])

            # Step 1.8: æå–æ›²çº¿ & ç°åº¦åŒ–
            curve_points, curve_gray_values = _process_and_extract_curve_points(state['crop_path'])
            state["curve_points"] = curve_points
            state["curve_gray_values"] = curve_gray_values

            # Step 1.9: å…‰è°±è¿˜åŸ
            state["spectrum"] = _convert_to_spectrum(state['curve_points'], state['curve_gray_values'], state['pixel_to_value'])
            # print(state["spectrum"]['new_wavelength'])
            # print(state["spectrum"]['weighted_flux'])
            # Step 1.10: æ£€æµ‹å³°å€¼/è°·å€¼
            sigma_list, tol_pixels, prom_peaks, prom_troughs, weight_original, plot_peaks, plot_troughs = _load_feature_params()
            state['sigma_list'] = sigma_list
            try:
                spec = state["spectrum"]
                wavelengths = np.array(spec["new_wavelength"])
                flux = np.array(spec["weighted_flux"])
                state["peaks"] = _find_features_multiscale(
                    wavelengths, flux,
                    state, feature="peak", sigma_list=sigma_list,
                    prom=prom_peaks, tol_pixels=tol_pixels, weight_original=weight_original,
                    use_continuum_for_trough=True
                )
                # print(f"peaks: \n {state['peaks']}")
                # print(state["peaks"])
                state["troughs"] = _find_features_multiscale(
                    wavelengths, flux,
                    state, feature="trough", sigma_list=sigma_list,
                    prom=prom_troughs, tol_pixels=tol_pixels, weight_original=weight_original,
                    use_continuum_for_trough=True,
                    min_depth=0.08
                )
                # print(f"troughs: \n {state['troughs']}")
            except Exception as e:
                print(f"âŒ find features multiscale terminated with error: {e}")
                raise

            # Step 1.11: å¯é€‰ç»˜å›¾
            if plot:
                try:
                    state["spectrum_fig"] = _plot_spectrum(state)
                    # state["features_fig"] = _plot_features(state, sigma_list, [plot_peaks, plot_troughs])
                except Exception as e:
                    print(f"âŒ plot spectrum or features terminated with error: {e}")
                    raise

            return state

        except Exception as e:
            print(f"âŒ run pipeline terminated with error: {e}")
            raise


# ---------------------------------------------------------
# 2. Rule-based Analyst â€” è´Ÿè´£åŸºäºè§„åˆ™çš„ç‰©ç†åˆ†æ
# ---------------------------------------------------------
class SpectralRuleAnalyst(BaseAgent):
    """
    è§„åˆ™é©±åŠ¨å‹åˆ†æå¸ˆï¼šåŸºäºç»™å®šçš„ç‰©ç†ä¸è°±çº¿çŸ¥è¯†è¿›è¡Œå®šæ€§åˆ†æ
    """

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Rule Analyst',
            mcp_manager=mcp_manager
        )

    async def describe_spectrum_picture(self, state: SpectroState):
        function_prompt = state['prompt'][f'{self.agent_name}']['describe_spectrum_picture']
        async def _filter_noise(state):
            BR = [5650, 5850]
            RZ = [7500, 7700]
            spec = state['spectrum']
            wv = np.array(spec['new_wavelength'])
            ceiling = np.array(spec['max_unresolved_flux'])
            floor = np.array(spec['min_unresolved_flux'])
            delta = ceiling - floor
            mask_BR = (wv >= BR[0]) & (wv <= BR[1])
            mask_RZ = (wv >= RZ[0]) & (wv <= RZ[1])
            wv_BR, delta_BR = wv[mask_BR], delta[mask_BR]
            wv_RZ, delta_RZ = wv[mask_RZ], delta[mask_RZ]
            def truncate(arr, N=150):
                return arr[:N] if len(arr) > N else arr
            wv_BR_t = truncate(wv_BR)
            wv_BR_t = wv_BR_t.tolist()
            delta_BR_t = truncate(delta_BR)
            delta_BR_t = delta_BR_t.tolist()
            wv_RZ_t = truncate(wv_RZ)
            wv_RZ_t = wv_RZ_t.tolist()
            delta_RZ_t = truncate(delta_RZ)
            delta_RZ_t = delta_RZ_t.tolist()

            system_prompt = function_prompt['_filter_noise']['system_prompt']
            user_prompt = function_prompt['_filter_noise']['user_prompt'].format(
                BR_L=BR[0],
                BR_R=BR[1],
                RZ_L=RZ[0],
                RZ_R=RZ[1],
                wv_BR_t=wv_BR_t,
                delta_BR_t=delta_BR_t,
                wv_RZ_t=wv_RZ_t,
                delta_RZ_t=delta_RZ_t
            )

            response = await self.call_llm_with_context(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                image_path=None,
                parse_json=True,
                description="Filterå™ªå£°åˆ¤æ–­"
            )
            return(response)

        async def _visual(state):
            system_prompt = function_prompt['_visual']['system_prompt']
            user_prompt_1 = function_prompt['_visual']['user_prompt_continuum']
            response_1 = await self.call_llm_with_context(
                system_prompt=system_prompt,
                user_prompt=user_prompt_1,
                image_path=state['spec_extract_path'],
                parse_json=True,
                description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
            )

            user_prompt_2 = function_prompt['_visual']['user_prompt_lines']
            response_2 = await self.call_llm_with_context(
                system_prompt=system_prompt,
                user_prompt=user_prompt_2,
                image_path=state['spec_extract_path'],
                parse_json=True,
                description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
            )

            user_prompt_3 = function_prompt['_visual']['user_prompt_quality']
            response_3 = await self.call_llm_with_context(
                system_prompt=system_prompt,
                user_prompt=user_prompt_3,
                image_path=state['spec_extract_path'],
                parse_json=True,
                description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
            )
            return '\n'.join([response_1, response_2, response_3])

        async def _get_ROI(state):
            _visual_json = json.dumps(state['visual_interpretation'][1], ensure_ascii=False)
            system_prompt = function_prompt['_get_ROI']['system_prompt']
            user_prompt = function_prompt['_get_ROI']['user_prompt'].format(_visual_json=_visual_json)

            response_2 = await self.call_llm_with_context(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                parse_json=True,
                description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
            )
            return response_2

        async def _integrate(state):
            filter_noise_json = json.dumps(state['visual_interpretation'][0], ensure_ascii=False)
            visual_json       = json.dumps(state['visual_interpretation'][1], ensure_ascii=False)
            roi_json          = json.dumps(state['visual_interpretation'][2], ensure_ascii=False)

            system_prompt = function_prompt['_integrate']['system_prompt']
            user_prompt_integrate = function_prompt['_integrate']['user_prompt'].format(
                filter_noise_json=filter_noise_json,
                visual_json=visual_json,
                roi_json=roi_json
            )
            response = await self.call_llm_with_context(
                system_prompt=system_prompt,
                user_prompt=user_prompt_integrate,
                parse_json=True,
                description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
            )
            return response

        result_filter_noise = await _filter_noise(state)
        state['visual_interpretation'] = [result_filter_noise]
        result_visual = await _visual(state)
        state['visual_interpretation'].append(result_visual)
        result_ROI = await _get_ROI(state)
        state['visual_interpretation'].append(result_ROI)
        result_integrate = await _integrate(state)
        state['visual_interpretation'] = result_integrate

        visual_interpretation_path = os.path.join(state['output_dir'], f'{state['image_name']}_visual_interpretation.txt')
        with open(visual_interpretation_path, 'w', encoding='utf-8') as f:
            json_str = json.dumps(state['visual_interpretation'], indent=2, ensure_ascii=False)
            f.write(json_str)
    
    async def preliminary_classification(self, state: SpectroState) -> str:
        """åˆæ­¥åˆ†ç±»ï¼šæ ¹æ®å…‰è°±å½¢æ€åˆæ­¥åˆ¤æ–­å¤©ä½“ç±»å‹"""

        visual_interpretation_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
        sigma_list_json = json.dumps(state['sigma_list'], ensure_ascii=False)
        peaks_info = [
            {
                "wavelength": pe.get('wavelength'),
                "flux": pe.get('mean_flux'),
                "width": pe.get('width_mean'),
                "prominance": pe.get('max_prominence'),
                # "seen_in_scales_of_sigma": pe.get('seen_in_scales_of_sigma'),
            }
            for pe in state.get('merged_peaks', [])[:10]
        ]
        peak_json = json.dumps(peaks_info, ensure_ascii=False)
        trough_info = [
            {
                "wavelength": tr.get('wavelength'),
                "flux": tr.get('mean_flux'),
                "width": tr.get('width_mean'),
                # "seen_in_scales_of_sigma": tr.get('seen_in_scales_of_sigma')
            }
            for tr in state.get('merged_troughs', [])[:15]
        ]
        trough_json = json.dumps(trough_info, ensure_ascii=False)
#         prompt = f"""
# ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

# ä½ å°†çœ‹åˆ°ä¸€æ¡å¤©æ–‡å…‰è°±æ›²çº¿ï¼ˆæ¥è‡ªæœªçŸ¥çº¢ç§»çš„å¤©ä½“ï¼‰ï¼Œå®ƒå¯èƒ½å±äºä»¥ä¸‹ä¸‰ç±»ä¹‹ä¸€ï¼š
# 1. **Star**ï¼š
#     - è¿ç»­è°±è¾ƒå¼ºï¼Œè°±çº¿é€šå¸¸æ˜¯å¸æ”¶çº¿ï¼ˆå¦‚ Balmer ç³»åˆ—ã€é‡‘å±çº¿ç­‰ï¼‰ï¼Œå‡ ä¹æ²¡æœ‰æ˜æ˜¾çº¢ç§»ã€‚
# 2. **Galaxy**ï¼š
#     - æœ‰ä¸€å®šçº¢ç§»ï¼Œå¸¸æœ‰å‘å°„çº¿æˆ–å¸æ”¶çº¿ï¼Œè°±çº¿è¾ƒçª„ã€‚
#     - è¿ç»­è°±ï¼ˆä¸å‘å°„çº¿åŠå™ªå£°ç›¸æ¯”ï¼‰å¼ºåº¦è¾ƒå¼±ã€‚
#     - éƒ¨åˆ†æ˜Ÿç³»çš„è¿ç»­è°±å‘ˆç°è“ç«¯è¾ƒä½è€Œçº¢ç«¯æ˜¾è‘—å‡é«˜çš„è¶‹åŠ¿ã€‚
# 3. **QSO**ï¼š
#     - å…·æœ‰**å¼ºå‘å°„çº¿**ã€‚è°±çº¿å®½åº¦æ˜æ˜¾ã€‚
#     - è¿ç»­è°±è¦†ç›–å¯è§/ç´«å¤–æ³¢æ®µã€‚
#     - é€šå¸¸æœ‰æ˜æ˜¾çº¢ç§»ã€‚

# å‰ä¸€ä½å¤©æ–‡å­¦åŠ©æ‰‹å·²ç»å®šæ€§åœ°æè¿°äº†å…‰è°±çš„æ•´ä½“å½¢æ€ï¼š

# {visual_interpretation_json}

# ç»¼åˆåŸæ›²çº¿å’Œ sigma={state['sigma_list']} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
# å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
# - ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
# {peak_json}
# - å¯èƒ½çš„å¸æ”¶çº¿ï¼š
# {trough_json}

# è¯·æ ¹æ®ä»–çš„æè¿°è¿›è¡Œåˆ¤æ–­ï¼ŒçŒœæµ‹è¯¥å…‰è°±å¯èƒ½å±äºå“ªä¸€ç±»æˆ–å‡ ç±»ï¼Œç»™å‡ºç½®ä¿¡åº¦ã€‚

# ä½ çš„å›ç­”æ ¼å¼è¯·ä¸¥æ ¼éµå¾ªï¼š

# çŒœæµ‹ 1ï¼š
# - **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
# - **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿ç»­è°±å½¢æ€ï¼‰
# - **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½
# çŒœæµ‹ 2ï¼š
# - **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
# - **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿ç»­è°±å½¢æ€ï¼‰
# - **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½
# ç­‰ç­‰ã€‚

# âš ï¸ **æ³¨æ„**ï¼š
# - åªè¾“å‡º**ä¸­ç­‰ç½®ä¿¡åº¦**ä»¥ä¸Šçš„å›ç­”
# - ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼
# - ä¸å°è¯•è®¡ç®—çº¢ç§»
# - é‡ç‚¹åœ¨è§†è§‰ä¸å½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­
# - ä¸è¦è°ƒç”¨å·¥å…·ï¼›
# """
        system_prompt = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å…‰è°±çš„å®šæ€§æè¿°å’Œç‰¹å¾æ•°æ®ï¼ŒçŒœæµ‹å¤©ä½“å¯èƒ½å±äºçš„ç±»åˆ«ã€‚

å¯é€‰çš„ç±»åˆ«ï¼š
1. **Star**ï¼š
    - è¿ç»­è°±è¾ƒå¼ºï¼Œè°±çº¿é€šå¸¸æ˜¯å¸æ”¶çº¿ï¼ˆå¦‚ Balmer ç³»åˆ—ã€é‡‘å±çº¿ç­‰ï¼‰ï¼Œå‡ ä¹æ²¡æœ‰æ˜æ˜¾çº¢ç§»ã€‚
2. **Galaxy**ï¼š
    - æœ‰ä¸€å®šçº¢ç§»ï¼Œå¸¸æœ‰å‘å°„çº¿æˆ–å¸æ”¶çº¿ã€‚
    - è°±çº¿é€šå¸¸è¾ƒçª„ã€‚
    - è¿ç»­è°±è¾ƒä¸æ˜æ˜¾ã€‚
    - éƒ¨åˆ†æ˜Ÿç³»çš„è¿ç»­è°±å‘ˆç°è“ç«¯è¾ƒä½è€Œçº¢ç«¯æ˜¾è‘—å‡é«˜çš„è¶‹åŠ¿ã€‚
3. **QSO**ï¼š
    - å…·æœ‰**å¼ºå‘å°„çº¿**ã€‚è°±çº¿å®½åº¦æ˜æ˜¾ã€‚
    - è¿ç»­è°±è¦†ç›–å¯è§/ç´«å¤–æ³¢æ®µã€‚
    - é€šå¸¸æœ‰æ˜æ˜¾çº¢ç§»ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- æ¯ä¸ªçŒœæµ‹åŒ…å«ï¼šç±»åˆ«ã€ç†ç”±ã€ç½®ä¿¡åº¦
- ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼
- ä¸å°è¯•è®¡ç®—çº¢ç§»
- é‡ç‚¹åœ¨è§†è§‰ä¸å½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­
- ä¸è¦è°ƒç”¨å·¥å…·

è¾“å‡ºæ ¼å¼ï¼š
çŒœæµ‹ 1ï¼š
- **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
- **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿ç»­è°±å½¢æ€ï¼‰
- **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½
çŒœæµ‹ 2ï¼š
...
"""
        user_prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹å…‰è°±æ•°æ®è¿›è¡Œåˆ†æï¼š

å‰ä¸€ä½å¤©æ–‡å­¦åŠ©æ‰‹å·²ç»å®šæ€§åœ°æè¿°äº†å…‰è°±çš„æ•´ä½“å½¢æ€ï¼š
{visual_interpretation_json}
å…¶ä¸­ filter noise æ˜¯å› ä¸ºåœ¨ä¸åŒ filterï¼ˆå¦‚ B,R,Zï¼‰é‡å å¤„å‡ºç°çš„éç‰©ç†çš„å™ªå£°ã€‚

åœ¨å…¨å±€ä¸Šï¼Œç»¼åˆåŸæ›²çº¿å’Œ sigma={sigma_list_json} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
åœ¨ ROI (region of interest) ä¸Šï¼Œç»¼åˆå±€éƒ¨çš„åŸæ›²çº¿å’Œ sigma={sigma_list_json} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚

å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}

è¯·æ ¹æ®è¿™äº›æè¿°å’Œæ•°æ®ï¼ŒçŒœæµ‹è¯¥å…‰è°±å¯èƒ½å±äºå“ªä¸€ç±»æˆ–å‡ ç±»å¤©ä½“ã€‚
"""
        response = await self.call_llm_with_context(
            system_prompt = system_prompt,
            user_prompt = user_prompt,
            image_path=state['image_path'],
            parse_json=True,
            description="åˆæ­¥åˆ†ç±»"
        )
        state['preliminary_classification'] = response

    async def preliminary_classification_monkey(self, state):
        """ My dear monkey friend and its typewriter """
        preliminary_classification_json = json.dumps(state['preliminary_classification'], ensure_ascii=False)
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚
ä½ æ¥æ”¶åˆ°çš„æ˜¯å…¶ä»–åŠ©æ‰‹å¯¹ä¸€å¼ å…‰è°±çš„å…‰æºç±»åˆ«çš„åˆæ­¥çŒœæµ‹ï¼š
{preliminary_classification_json}

è¯·è¾“å‡ºè¿™ä»½çŒœæµ‹é‡Œç»™å‡ºçš„å…‰æºç±»åˆ«ã€‚

è¾“å‡ºæ ¼å¼ä¸ºæ•°ç»„ List[str]ï¼Œæ•°ç»„çš„å…ƒç´ å¿…é¡»åœ¨ "Star", "Galaxy" å’Œ "QSO" ä¸­é€‰æ‹©ã€‚

- æ³¨æ„ï¼šå³ä½¿åªæœ‰ä¸€ä¸ªæ»¡è¶³æ¡ä»¶çš„å…‰æºç±»åˆ«ï¼Œä¹Ÿè¦ä»¥ List[str] çš„æ ¼å¼è¾“å‡ºã€‚
"""
        response = await self.call_llm_with_context(
            system_prompt = '',
            user_prompt = prompt,
            parse_json=True,
            description="åˆæ­¥åˆ†ç±»çŒ´å­"
        )
        return response
    ###################################
    # QSO part
    ###################################
    async def _QSO(self, state):
        """QSO"""
        def _common_prompt_header_QSO(state, include_rule_analysis=True, include_step_1_only=False):
            """æ„é€ æ¯ä¸ª step å…¬å…±çš„ prompt å‰æ®µ"""
            visual_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
            # peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)
            # trough_json = json.dumps(state['troughs'], ensure_ascii=False)
            peaks_info = [
                {
                    "wavelength": pe.get('wavelength'),
                    "flux": pe.get('mean_flux'),
                    "width": pe.get('width_mean'),
                    "prominance": pe.get('max_prominence'),
                    "seen_in_scales_of_sigma": pe.get('seen_in_scales_of_sigma'),
                }
                for pe in state.get('merged_peaks', [])[:10]
            ]
            peak_json = json.dumps(peaks_info, ensure_ascii=False)
            trough_info = [
                {
                    "wavelength": tr.get('wavelength'),
                    "flux": tr.get('mean_flux'),
                    "width": tr.get('width_mean'),
                    "seen_in_scales_of_sigma": tr.get('seen_in_scales_of_sigma')
                }
                for tr in state.get('merged_troughs', [])[:15]
            ]
            trough_json = json.dumps(trough_info, ensure_ascii=False)

            header = f"""
    ä½ æ˜¯ä¸€ä½å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

    ä»¥ä¸‹ä¿¡æ¯å¯èƒ½æ¥è‡ªäºä¸€ä¸ªæœªçŸ¥çº¢ç§»çš„ QSO å…‰è°±ã€‚

    ä¹‹å‰çš„åŠ©æ‰‹å·²ç»å¯¹è¿™ä¸ªå…‰è°±è¿›è¡Œäº†åˆæ­¥æè¿°ï¼š
    {visual_json}

    è¯¥å…‰è°±çš„æ³¢é•¿èŒƒå›´æ˜¯{state['spectrum']['new_wavelength'][0]} Ã… åˆ° {state['spectrum']['new_wavelength'][-1]} Ã…ã€‚
    """

            if include_rule_analysis and state['rule_analysis_QSO']:
                if include_step_1_only==True:
                    rule_json = json.dumps(state['rule_analysis_QSO'][0], ensure_ascii=False)
                else:
                    rule_json = json.dumps("\n".join(str(item) for item in state['rule_analysis_QSO']), ensure_ascii=False)
                header += f"\nä¹‹å‰çš„åŠ©æ‰‹å·²ç»è¿›è¡Œäº†ä¸€äº›åˆ†æ:\n{rule_json}\n"

            tol_pixels = getenv_int("TOL_PIXELS", 10)
            a_x = state['pixel_to_value']['x']['a']
            tol_wavelength = a_x * tol_pixels
            header += f"""
    ç»¼åˆåŸæ›²çº¿å’Œ sigma={state['sigma_list']} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
    å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
    - ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
    {peak_json}
    - å¯èƒ½çš„å¸æ”¶çº¿ï¼š
    {trough_json}
    - æ³¢é•¿è¯¯å·®åœ¨ ~ Â±{tol_wavelength/2} Ã… çš„é‡çº§æˆ–æ›´å¤§
    """
            return header

        def _common_prompt_tail(step_title, extra_notes=""):
            """æ„é€ æ¯ä¸ª step å…¬å…±å°¾éƒ¨ï¼Œä¿ç•™ step ç‰¹æœ‰è¾“å‡º/åˆ†ææŒ‡ç¤º"""
            tail = f"""
    ---

    è¾“å‡ºæ ¼å¼ä¸ºï¼š
    {step_title}
    ...

    ---

    ğŸ§­ æ³¨æ„ï¼š
    - è®¡ç®—å¾—æ¥çš„éåŸå§‹æ•°æ®ï¼Œè¾“å‡ºæ—¶ä¿ç•™ 3 ä½å°æ•°ã€‚
    - ä¸éœ€è¦è¿›è¡Œé‡å¤æ€»ç»“ã€‚
    - ä¸éœ€è¦é€è¡Œåœ°é‡å¤è¾“å…¥æ•°æ®ï¼›
    - é‡ç‚¹åœ¨ç‰©ç†æ¨ç†ä¸åˆç†è§£é‡Šï¼›
    - è¯·ä¿è¯æœ€ç»ˆè¾“å‡ºå®Œæ•´ï¼Œä¸è¦ä¸­é€”æˆªæ–­ã€‚
    """
            if extra_notes:
                tail = extra_notes + "\n" + tail
            return tail
    
        async def step_1_QSO(state):
            header = _common_prompt_header_QSO(state, include_rule_analysis=False)
            tail = _common_prompt_tail("Step 1: LyÎ± è°±çº¿æ£€æµ‹")

            prompt = header + """
è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æ:

Step 1: LyÎ± è°±çº¿æ£€æµ‹
å‡è®¾è¯¥å…‰è°±ä¸­å­˜åœ¨ LyÎ± å‘å°„çº¿ï¼ˆÎ»_rest = 1216 Ã…ï¼‰ï¼š
1. åœ¨å…‰è°±è“ç«¯ï¼Œæµé‡è¾ƒå¤§ï¼Œä¸”æœ‰ä¸€å®šå®½åº¦çš„å³°ä¸­ï¼Œæ¨æµ‹å“ªæ¡æœ€å¯èƒ½ä¸º LyÎ± çº¿ï¼ˆä»æä¾›çš„å³°åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰ã€‚
2. è¾“å‡ºï¼š
- è§‚æµ‹æ³¢é•¿ Î»_obs
- æµé‡ Flux
- è°±çº¿å®½åº¦
3. ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—è¯¥å³°ä¸º LyÎ± å‘å°„çº¿æ—¶çš„çº¢ç§» zã€‚
4. æ£€æŸ¥è“ç«¯ï¼ˆçŸ­æ³¢é•¿æ–¹å‘ï¼‰æ˜¯å¦å­˜åœ¨ LyÎ± forest ç‰¹å¾ï¼šå¸æ”¶çº¿ç›¸å¯¹æ›´å¯†é›†ã€è¾ƒçª„ä¸”åˆ†å¸ƒåœ¨ LyÎ± è“ç«¯é™„è¿‘ã€‚è¯·æŒ‡å‡ºå¹¶è¿›è¡Œç®€çŸ­è¯´æ˜ã€‚
""" + tail
            
            response = await self.call_llm_with_context(
                system_prompt='', 
                user_prompt=prompt, 
                parse_json=True, 
                description="Step 1 LyÎ± åˆ†æ"
            )
            state['rule_analysis_QSO'].append(response)

        async def step_2_QSO(state):
            header = _common_prompt_header_QSO(state)
            tail = _common_prompt_tail("Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æ")

            prompt = header + """
è¯·ç»§ç»­åˆ†æ:

Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æ
1. åœ¨ Step 1 å¾—åˆ°çš„çº¢ç§»ä¸‹ï¼Œä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—ä»¥ä¸‹ä¸‰æ¡ä¸»è¦å‘å°„çº¿ï¼šC IV 1549, C III] 1909, Mg II 2799 åœ¨å…‰è°±ä¸­çš„ç†è®ºä½ç½®ã€‚
2. å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸ä¸‰è€…ç›¸åŒ¹é…çš„å³°ï¼Ÿ
3. å¦‚æœå­˜åœ¨å‘å°„çº¿ä¸è§‚æµ‹å³°å€¼çš„åŒ¹é…ï¼Œæ ¹æ®åŒ¹é…ç»“æœï¼Œåˆ†åˆ«ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—çº¢ç§»ã€‚æŒ‰â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¾“å‡ºã€‚
""" + tail

            response = await self.call_llm_with_context('', prompt, parse_json=False, description="Step 2 å‘å°„çº¿åˆ†æ")
            state['rule_analysis_QSO'].append(response)

        async def step_3_QSO(state):
            header = _common_prompt_header_QSO(state)
            tail = _common_prompt_tail("Step 3: ç»¼åˆåˆ¤æ–­")

            prompt = header + """
è¯·ç»§ç»­åˆ†æ:

Step 3: ç»¼åˆåˆ¤æ–­
1. åœ¨ Step 1 åˆ° Step 2 ä¸­ï¼Œå¦‚æœï¼š
    - C IV å’Œ C III] ä¸¤æ¡ä¸»è¦è°±çº¿å­˜åœ¨ç¼ºå¤±æˆ–å¤§å¹…åç§»
    - ä½¿ç”¨ lyÎ± è°±çº¿è®¡ç®—çš„çº¢ç§»ä¸å…¶ä»–è°±çº¿çš„è®¡ç®—ç»“æœä¸ä¸€è‡´ï¼Œ
æ­¤æ—¶è¯·è¾“å‡ºâ€œåº”ä¼˜å…ˆå‡è®¾ LyÎ± è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·â€ï¼Œå¹¶ç»“æŸ Step 3 çš„åˆ†æã€‚ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯ã€‚
2.ä»…åœ¨æœ‰æ˜¾è‘—çš„ LyÎ± å³°å€¼ï¼Œä¸”çº¢ç§»è®¡ç®—ç»“æœä¸å…¶ä»–è°±çº¿åŸºæœ¬ä¸€è‡´æ—¶ï¼Œè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š
    - å› ä¸ºå¤©æ–‡å­¦ä¸­å­˜åœ¨å¤–æµç­‰ç°è±¡ï¼Œè¯·å°†å½“å‰æ‰€æœ‰åŒ¹é…ä¸­**æœ€ä½ç”µç¦»æ€è°±çº¿çš„çº¢ç§»**ä½œä¸ºå…‰è°±çš„çº¢ç§»ã€‚è¾“å‡ºçº¢ç§»ç»“æœã€‚ï¼ˆå› ä¸ºå­˜åœ¨ä¸å¯¹ç§°å’Œå±•å®½ï¼ŒLyÎ±çš„ç½®ä¿¡åº¦æ˜¯è¾ƒä½çš„ï¼‰
""" + tail

            response = await self.call_llm_with_context('', prompt, parse_json=False, description="Step 3 ç»¼åˆåˆ¤æ–­")
            state['rule_analysis_QSO'].append(response)
            
        async def step_4_QSO(state):
            header = _common_prompt_header_QSO(state, include_step_1_only=True)
            tail = _common_prompt_tail("Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ Step 1 æ‰€é€‰æ‹©çš„è°±çº¿å¹¶é LyÎ±ï¼‰")

            prompt = header + """
è¯·ç»§ç»­åˆ†æ:

Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ Step 1 æ‰€é€‰æ‹©çš„è°±çº¿å¹¶é LyÎ±ï¼‰
- è¯·æŠ›å¼€å‰è¿°æ­¥éª¤çš„åˆ†æå†…å®¹ã€‚è€ƒè™‘ Step 1 æ‰€é€‰æ‹©çš„è°±çº¿å®é™…ä¸Šæ˜¯é™¤ LyÎ± å¤–çš„å…¶ä»–ä¸»è¦å‘å°„çº¿ã€‚
    - å‡è®¾è¯¥å³°å€¼å¯èƒ½å¯¹åº”çš„è°±çº¿ä¸º C IVï¼š
        - è¾“å‡ºè¯¥å³°å¯¹åº”è°±çº¿çš„ä¿¡æ¯ï¼š
            - è§‚æµ‹æ³¢é•¿ Î»_obs
            - æµé‡ Flux
            - è°±çº¿å®½åº¦
            - æ ¹æ® Î»_restï¼Œä½¿ç”¨å·¥å…· calculate_redshift åˆæ­¥è®¡ç®—çº¢ç§» z
        - ä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—åœ¨æ­¤çº¢ç§»ä¸‹çš„å…¶ä»–ä¸»è¦å‘å°„çº¿ï¼ˆå¦‚ C III] å’Œ Mg IIï¼‰çš„ç†è®ºä½ç½®ã€‚å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸å®ƒä»¬åŒ¹é…çš„å‘å°„çº¿ï¼Ÿ
        - å¦‚æœå­˜åœ¨å¯èƒ½çš„å‘å°„çº¿-è§‚æµ‹æ³¢é•¿åŒ¹é…ç»“æœï¼Œä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—å®ƒä»¬çš„çº¢ç§»ã€‚æŒ‰ç…§â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¿›è¡Œè¾“å‡º
    
    - è‹¥ä»¥ä¸Šå‡è®¾ä¸åˆç†ï¼Œåˆ™å‡è®¾è¯¥å³°å€¼å¯èƒ½å¯¹åº” C III] ç­‰å…¶ä»–ä¸»è¦è°±çº¿ï¼Œé‡å¤æ¨æ–­ã€‚

    - ç»¼åˆ Step 4 çš„æ‰€æœ‰åˆ†æï¼Œç»™å‡ºï¼š
        - **æœ€ä½ç”µç¦»æ€è°±çº¿çš„çº¢ç§»** ä½œä¸ºå…‰è°±çº¢ç§»
        - è¾“å‡º â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€ åŒ¹é…

- æ³¨æ„ï¼šå…è®¸åœ¨ç”±äºå…‰è°±è¾¹ç¼˜çš„ä¿¡å·æ®‹ç¼ºæˆ–ä¿¡å™ªæ¯”ä¸ä½³å¯¼è‡´éƒ¨åˆ†å‘å°„çº¿ä¸å¯è§ã€‚   
- æŠ›å¼€å…¶ä»–æ­¥éª¤çš„åˆ†æå†…å®¹ï¼Œæœ¬èŠ‚çš„åˆ¤æ–­æ˜¯å¦æ”¯æŒ LyÎ± è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·çš„å‡è®¾ï¼Ÿ
""" + tail

            response = await self.call_llm_with_context('', prompt, parse_json=False, description="Step 4 è¡¥å……åˆ†æ")
            state['rule_analysis_QSO'].append(response)
        
        await step_1_QSO(state)
        await step_2_QSO(state)
        await step_3_QSO(state)
        await step_4_QSO(state)

#     ###################################
#     # Galaxy part
#     ###################################
#     # async def further_discription_galaxy(self, state):

#     def _common_prompt_header_galaxy(self, state, include_rule_analysis=True, include_step_1_only=False):
#         """æ„é€ æ¯ä¸ª step å…¬å…±çš„ prompt å‰æ®µ"""
#         visual_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
#         peaks_info = [
#             {
#                 "wavelength": pe.get('wavelength'),
#                 "flux": pe.get('mean_flux'),
#                 "width": pe.get('width_mean'),
#                 "prominance": pe.get('max_prominence'),
#                 "seen_in_scales_of_sigma": pe.get('seen_in_scales_of_sigma'),
#             }
#             for pe in state.get('peaks', [])[:10]
#         ]
#         peak_json = json.dumps(peaks_info, ensure_ascii=False)
#         trough_info = [
#             {
#                 "wavelength": tr.get('wavelength'),
#                 "flux": tr.get('mean_flux'),
#                 "width": tr.get('width_mean'),
#                 "seen_in_scales_of_sigma": tr.get('seen_in_scales_of_sigma'),
#                 "prominance": tr.get('max_prominence'),
#             }
#             for tr in state.get('troughs', [])[:15]
#         ]
#         trough_json = json.dumps(trough_info, ensure_ascii=False)

#         header = f"""
# ä½ æ˜¯ä¸€ä½å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

# ä»¥ä¸‹ä¿¡æ¯å¯èƒ½æ¥è‡ªäºä¸€ä¸ªæœªçŸ¥çº¢ç§»çš„ Galaxy å…‰è°±ã€‚

# ä¹‹å‰çš„åŠ©æ‰‹å·²ç»å¯¹è¿™ä¸ªå…‰è°±è¿›è¡Œäº†åˆæ­¥æè¿°ï¼š
# {visual_json}

# è¯¥å…‰è°±çš„æ³¢é•¿èŒƒå›´æ˜¯{state['spectrum']['new_wavelength'][0]} Ã… åˆ° {state['spectrum']['new_wavelength'][-1]} Ã…ã€‚
# """

#         if include_rule_analysis and state['rule_analysis_galaxy']:
#             if include_step_1_only==True:
#                 rule_json = json.dumps(state['rule_analysis_galaxy'][0], ensure_ascii=False)
#             else:
#                 rule_json = json.dumps("\n".join(str(item) for item in state['rule_analysis_galaxy']), ensure_ascii=False)
#             header += f"\nä¹‹å‰çš„åŠ©æ‰‹å·²ç»è¿›è¡Œäº†ä¸€äº›åˆ†æ:\n{rule_json}\n"

#         tol_pixels = getenv_int("TOL_PIXELS", 10)
#         a_x = state['pixel_to_value']['x']['a']
#         tol_wavelength = a_x * tol_pixels
#         header += f"""
# ç»¼åˆåŸæ›²çº¿å’Œ sigma={state['sigma_list']} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
# å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
# - ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
# {peak_json}
# - å¯èƒ½çš„å¸æ”¶çº¿ï¼š
# {trough_json}
# - æ³¢é•¿è¯¯å·®åœ¨ ~ Â±{tol_wavelength/2} Ã… çš„é‡çº§æˆ–æ›´å¤§
# """
#         return header
    
#     async def step_1_galaxy(self, state):
#         try:
#             # ç¡®ä¿ state['rule_analysis_galaxy'] å·²åˆå§‹åŒ–ä¸ºåˆ—è¡¨
#             if 'rule_analysis_galaxy' not in state:
#                 state['rule_analysis_galaxy'] = []

#             header = self._common_prompt_header_galaxy(state, include_rule_analysis=False)
#             tail = self._common_prompt_tail("Step 1: O [III] è°±çº¿æ£€æµ‹")

#             prompt = header + """
# è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æ:

# Step 1: O [III] è°±çº¿æ£€æµ‹
# å‡è®¾è¯¥å…‰è°±ä¸­å­˜åœ¨ O [III] å‘å°„çº¿ï¼ˆå› å³°å€¼è¯†åˆ«çš„åˆ†è¾¨ç‡æœ‰é™ï¼Œåªè€ƒè™‘åŒçº¿ä¸­æœ€å¼ºçš„ Î»_rest = 5008.2 Ã… è¿™ä¸€æ¡ï¼‰ï¼š
# 1. åœ¨å…‰è°±ä¸­æµé‡è¾ƒå¤§çš„çª„å³°ä¸­ï¼Œæ¨æµ‹å“ªæ¡æœ€å¯èƒ½ä¸º O [III] çº¿ï¼ˆä»æä¾›çš„å³°åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰ã€‚
# 2. è¾“å‡ºï¼š
# - è§‚æµ‹æ³¢é•¿ Î»_obs
# - æµé‡ Flux
# - è°±çº¿å®½åº¦
# 3. ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—è¯¥å³°ä¸º O [III] å‘å°„çº¿æ—¶çš„çº¢ç§» zã€‚
# """ + tail

#             response = await self.call_llm_with_context(
#                 prompt,
#                 parse_json=False,
#                 description="Step 1 O [III] è°±çº¿æ£€æµ‹"
#             )

#             # æ·»åŠ åˆ° rule_analysis_galaxy
#             state['rule_analysis_galaxy'].append(response)

#         except Exception as e:
#             print("âŒ Step 1 Galaxy åˆ†æå‡ºé”™ï¼š", e)
#             # å¯ä»¥é€‰æ‹©ç»§ç»­æŠ›å‡ºå¼‚å¸¸æˆ–è€…è®°å½•é”™è¯¯
#             raise

#     async def step_2_galaxy(self, state):
#         header = self._common_prompt_header_galaxy(state)
#         tail = self._common_prompt_tail("Step 2: å…¶ä»–ä¸»è¦å‘å°„çº¿åˆ†æ")

#         prompt = header + """
# è¯·ç»§ç»­åˆ†æ:

# Step 2: å…¶ä»–ä¸»è¦å‘å°„çº¿åˆ†æ
# 1. åœ¨ Step 1 å¾—åˆ°çš„çº¢ç§»ä¸‹ï¼Œä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—ä»¥ä¸‹ä¸»è¦è°±çº¿åœ¨è§‚æµ‹å…‰è°±ä¸Šçš„ç†è®ºä½ç½®ï¼š
#     - å‘å°„çº¿
#         - O [II] = 3727.1 Ã… / 3729.9 Ã… åŒçº¿
#         - N [II] = 6549.8 Ã… / 6585.3 Ã… åŒçº¿
#         - S [II] = 6718.3 Ã… / 6732.7 Ã… åŒçº¿
#     - å¸æ”¶çº¿
#         - Ca (K) = 3934.8 Ã…
#         - Ca (H) = 3969.6 Ã…
#         - G-band = 4305.6 Ã…
#         - Mg = 5176.7 Ã…
#         - Na = 5895.6 Ã…
#         - CaT = 8498, 8542, 8662 Ã… ä¸‰çº¿
#     - å‘å°„çº¿æˆ–å¸æ”¶çº¿ï¼šBalmer çº¿ç³»
#         - HÎ´ = 4102.9 A
#         - HÎ³ = 4341.7 A
#         - HÎ² = 4862.7 A
#         - HÎ± = 6564.6 A
# 2. å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸è¿™äº›è°±çº¿ç›¸åŒ¹é…çš„å³°æˆ–è°·ï¼Ÿ
# 3. å¦‚æœå­˜åœ¨å‘å°„çº¿ä¸è§‚æµ‹å³°/è°·çš„åŒ¹é…ï¼Œæ ¹æ®åŒ¹é…ç»“æœï¼Œåˆ†åˆ«ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—çº¢ç§»ã€‚æŒ‰â€œè°±çº¿æ€§è´¨ï¼ˆå‘å°„çº¿/å¸æ”¶çº¿ï¼‰--è°±çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¾“å‡ºã€‚

# """ + tail

#         response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 2 å…¶ä»–ä¸»è¦å‘å°„çº¿åˆ†æ")
#         state['rule_analysis_galaxy'].append(response)

#     async def step_3_galaxy(self, state):
#         header = self._common_prompt_header_galaxy(state)
#         tail = self._common_prompt_tail("Step 3: ç»¼åˆåˆ¤æ–­")
#         a = state["pixel_to_value"]["x"]["a"]
#         rms = state["pixel_to_value"]["x"]["rms"]
#         tolerence = getenv_int("TOL_PIXELS", 10)

#         prompt = header + f"""
# è¯·ç»§ç»­åˆ†æ:

# Step 3: ç»¼åˆåˆ¤æ–­
# 1. åœ¨ Step 1 åˆ° Step 2 ä¸­ï¼Œå¦‚æœï¼š
#     - ç¼ºå¤± O [II] çš„å¯èƒ½åŒ¹é…
#     - ä½¿ç”¨ O [III] è°±çº¿è®¡ç®—çš„çº¢ç§»ä¸å…¶ä»–è°±çº¿çš„è®¡ç®—ç»“æœä¸ä¸€è‡´ï¼Œ
# æ­¤æ—¶è¯·è¾“å‡ºâ€œåº”ä¼˜å…ˆå‡è®¾ O [III] è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·â€ï¼Œå¹¶ç»“æŸ Step 3 çš„åˆ†æã€‚ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯ã€‚
# 2.ä»…åœ¨æœ‰æ˜¾è‘—çš„ O [III] å³°å€¼ï¼Œä¸”çº¢ç§»è®¡ç®—ç»“æœä¸å…¶ä»–è°±çº¿åŸºæœ¬ä¸€è‡´æ—¶ï¼Œè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š
#     - ä½¿ç”¨å·¥å…· galaxy_weighted_averageï¼Œä»¥ flux ä¸ºæƒé‡è®¡ç®—å…‰è°±çš„çº¢ç§»ã€‚
#         - å·¥å…·è¾“å…¥ä¸º
#             wavelength_obs: List[float],
#             wavelength_rest: List[float],
#             flux: List[float],
#             a: float = {a}, 
#             tolerance: int = {tolerence}, 
#             rms_lambda: float = {rms} 
#     è¾“å‡ºçº¢ç§»ç»“æœå’Œè¯¯å·® z Â± Î”zã€‚
# """ + tail

#         response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 3 ç»¼åˆåˆ¤æ–­")
#         state['rule_analysis_galaxy'].append(response)
        
#     async def step_4_galaxy(self, state):
#         header = self._common_prompt_header_galaxy(state, include_step_1_only=True)
#         tail = self._common_prompt_tail("Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ LyÎ± è°±çº¿æœªè¢«æ‰¾å³°è¿‡ç¨‹æ•è·ï¼‰")
        
#         prompt = header + f"""
# è¯·ç»§ç»­åˆ†æ:

# Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ O [III] è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·ï¼‰
# - è¯·æŠ›å¼€å‰è¿°æ­¥éª¤çš„åˆ†æå†…å®¹ã€‚è€ƒè™‘ Step 1 æ‰€é€‰æ‹©çš„å³°å€¼è°±çº¿å®é™…ä¸Šå¯èƒ½æ˜¯ Balmer çº¿ç³»çš„ HÎ± è°±çº¿ã€‚
#         - è¾“å‡ºè¯¥å³°å¯¹åº”è°±çº¿çš„ä¿¡æ¯ï¼š
#             - è§‚æµ‹æ³¢é•¿ Î»_obs
#             - æµé‡ Flux
#             - è°±çº¿å®½åº¦
#             - æ ¹æ® Î»_restï¼Œä½¿ç”¨å·¥å…· calculate_redshift åˆæ­¥è®¡ç®—çº¢ç§» z
#         - ä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—åœ¨æ­¤çº¢ç§»ä¸‹çš„å…¶ä»– Balmer çº¿
#             - HÎ´ = 4102.9 A
#             - HÎ³ = 4341.7 A
#             - HÎ² = 4862.7 A
#             - HÎ± = 6564.6 A
#         çš„ç†è®ºä½ç½®ã€‚å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸å®ƒä»¬åŒ¹é…çš„å‘å°„çº¿ï¼Ÿå…¶ä»–å‘å°„çº¿å¦‚
#             - å‘å°„çº¿
#                 - O [II] = 3727.1 Ã… / 3729.9 Ã… åŒçº¿
#                 - N [II] = 6549.8 Ã… / 6585.3 Ã… åŒçº¿
#                 - S [II] = 6718.3 Ã… / 6732.7 Ã… åŒçº¿
#         æ˜¯å¦å­˜åœ¨ï¼Ÿ
#         - å¦‚æœå­˜åœ¨å¯èƒ½çš„å‘å°„çº¿-è§‚æµ‹æ³¢é•¿åŒ¹é…ç»“æœ:
#             - ä½¿ç”¨å·¥å…· calculate_redshift åˆ†åˆ«è®¡ç®—å®ƒä»¬çš„çº¢ç§»ã€‚æŒ‰ç…§â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¿›è¡Œè¾“å‡ºã€‚
    
#     - è‹¥ä»¥ä¸Šå‡è®¾ä¸åˆç†ï¼Œåˆ™å‡è®¾æœ€å¼ºçš„è°·å€¼å¯èƒ½å¯¹åº” HÎ± è°±çº¿ï¼Œé‡å¤æ¨æ–­ã€‚

# - æŠ›å¼€å…¶ä»–æ­¥éª¤çš„åˆ†æå†…å®¹ï¼Œæœ¬èŠ‚çš„åˆ¤æ–­æ˜¯å¦æ”¯æŒ O [III] è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·çš„å‡è®¾ï¼Ÿ
# """ + tail

#         response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 4 è¡¥å……æ­¥éª¤")
#         state['rule_analysis_galaxy'].append(response)

#     async def step_5_galaxy(self, state):
#         header = self._common_prompt_header_galaxy(state, include_step_1_only=True)
#         tail = self._common_prompt_tail("Step 5: è¡¥å……æ­¥éª¤ï¼ˆCa çš„ K&H å¸æ”¶çº¿æ£€æµ‹ï¼‰")

#         prompt = header + """
# è¯·ç»§ç»­åˆ†æ:

# Step 5: è¡¥å……æ­¥éª¤ï¼ˆCa çš„ K&H å¸æ”¶çº¿æ£€æµ‹ï¼‰
# - è¯·æŠ›å¼€å‰è¿°æ­¥éª¤çš„åˆ†æå†…å®¹ã€‚å‡è®¾å…‰è°±ä¸­prominanceçš„è°·å€¼ä¸º Ca çš„ K å¸æ”¶çº¿ã€‚
#         - è¾“å‡ºè¯¥å³°å¯¹åº”è°±çº¿çš„ä¿¡æ¯ï¼š
#             - è§‚æµ‹æ³¢é•¿ Î»_obs
#             - æµé‡ Flux
#             - è°±çº¿å®½åº¦
#             - æ ¹æ® Î»_restï¼Œä½¿ç”¨å·¥å…· calculate_redshift åˆæ­¥è®¡ç®—çº¢ç§» z
#         - ä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—åœ¨æ­¤çº¢ç§»ä¸‹çš„å…¶ä»–ä¸»è¦å¸æ”¶çº¿
#             - Ca (H) = 3969.6 Ã…
#             - G-band = 4305.6 Ã…
#             - Mg = 5176.7 Ã…
#             - Na = 5895.6 Ã…
#             - CaT = 8498, 8542, 8662 Ã… ä¸‰çº¿
#         çš„ç†è®ºä½ç½®ã€‚å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸å®ƒä»¬åŒ¹é…çš„è°·å€¼ï¼Ÿç‰¹åˆ«æ³¨æ„ Ca çš„ H å¸æ”¶çº¿ã€‚å¦‚æœè¯¥çº¿ä¸¢å¤±ï¼Œåˆ™èŠ‚æœ¬åˆ¤æ–­çš„å¯ä¿¡åº¦ä½ã€‚
#         - å¦‚æœå­˜åœ¨å¯èƒ½çš„å¸æ”¶çº¿çº¿-è§‚æµ‹æ³¢é•¿åŒ¹é…ç»“æœï¼š
#             - ä½¿ç”¨å·¥å…· calculate_redshift åˆ†åˆ«è®¡ç®—å®ƒä»¬çš„çº¢ç§»ã€‚æŒ‰ç…§â€œå¸æ”¶çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¿›è¡Œè¾“å‡ºã€‚

# - æŠ›å¼€å…¶ä»–æ­¥éª¤çš„åˆ†æå†…å®¹ï¼Œæœ¬èŠ‚çš„åˆ¤æ–­æ˜¯å¦æ”¯æŒæœ€æ˜æ˜¾çš„è°·å€¼ä¸º Ca çš„ K å¸æ”¶çº¿çš„å‡è®¾ï¼Ÿ
# """ + tail

#         response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 5 è¡¥å……æ­¥éª¤")
#         state['rule_analysis_galaxy'].append(response)
#     # --------------------------
#     # Run å…¨æµç¨‹
#     # --------------------------
    async def run(self, state: SpectroState):
        """æ‰§è¡Œè§„åˆ™åˆ†æå®Œæ•´æµç¨‹"""
        try:
            await self.describe_spectrum_picture(state)
            ROI_peaks, ROI_troughs = _ROI_features_finding(state)
            # print(f"ROI_peaks:\n{ROI_peaks}")
            # print(f"ROI_troughs:\n{ROI_troughs}")
            state['merged_peaks'], state['merged_troughs'] = merge_features(
                global_peaks=state['peaks'],
                global_troughs=state['troughs'],
                ROI_peaks=ROI_peaks,
                ROI_troughs=ROI_troughs, 
                tol_pixels=10,
            )
            
            plot_merged_features(state)
            
            await self.preliminary_classification(state)
            # print(state['preliminary_classification'])

            _shakespear = await self.preliminary_classification_monkey(state)
            state['possible_object'] = _shakespear
            # print(f"Monkeys types: {_shakespear}")

            if "QSO" in _shakespear:
                await self._QSO(state)
                # await self.step_1_QSO(state)
                # await self.step_2_QSO(state)
                # await self.step_3_QSO(state)
                # await self.step_4_QSO(state)
            # if "Galaxy" in _shakespear:
            #     await self.step_1_galaxy(state)
            #     await self.step_2_galaxy(state)
            #     await self.step_3_galaxy(state)
            #     await self.step_4_galaxy(state)
            #     await self.step_5_galaxy(state)
            return state
        except Exception as e:
            import traceback
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Full traceback:")
            traceback.print_exc()
            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸
            raise  # å¦‚æœä½ å¸Œæœ›è°ƒç”¨è€…ä¹Ÿèƒ½æ•è·è¯¥å¼‚å¸¸
        


# # ---------------------------------------------------------
# # 3. Revision Supervisor â€” è´Ÿè´£äº¤å‰å®¡æ ¸ä¸è¯„ä¼°
# # ---------------------------------------------------------
class SpectralAnalysisAuditor(BaseAgent):
    """å®¡æŸ¥åˆ†æå¸ˆï¼šå®¡æŸ¥å¹¶æ ¡æ­£å…¶ä»–åˆ†æ agent çš„è¾“å‡º"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Analysis Auditor',
            mcp_manager=mcp_manager
        )

    def _common_prompt_header(self, state: SpectroState, obj) -> str:
        peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)
        trough_json = json.dumps(state['troughs'], ensure_ascii=False)
        a = state["pixel_to_value"]["x"]["a"]
        rms = state["pixel_to_value"]["x"]["rms"]
        tolerence = getenv_int("TOL_PIXELS", 10)
        rule_analysis = "\n\n".join(str(item) for item in state['rule_analysis_QSO'])
        prompt_1 = f"""
ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„ã€å¤©æ–‡å­¦å…‰è°±æŠ¥å‘Šå®¡æŸ¥åˆ†æå¸ˆã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- å®¡æ ¸å…¶ä»–åˆ†æå¸ˆçš„å…‰è°±åˆ†ææŠ¥å‘Šæˆ–æƒ³æ³•
- è¯†åˆ«å…¶ä¸­çš„é€»è¾‘æ¼æ´ã€è®¡ç®—æ¼æ´ã€ä¸ä¸€è‡´æˆ–é”™è¯¯æ¨æ–­
- æå‡ºä¿®æ­£æ„è§æˆ–è¡¥å……åˆ†ææ–¹å‘

å·¥ä½œåŸåˆ™ï¼š
- ä¿æŒå®¢è§‚ä¸æ‰¹åˆ¤æ€§æ€ç»´
- ä¸é‡å¤åŸåˆ†æï¼ŒåªæŒ‡å‡ºé—®é¢˜ä¸æ”¹è¿›å»ºè®®
- è‹¥åŸæŠ¥å‘Šåˆç†ï¼Œåº”æ˜ç¡®ç¡®è®¤å…¶æœ‰æ•ˆæ€§
- æ¶‰åŠçº¢ç§»å’Œå…‰è°±è§‚æµ‹æ³¢é•¿çš„è®¡ç®—å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshift å’Œ  predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- è¯·è¾“å‡ºè¯´æ˜æ€§çš„è¯­è¨€
- ç®€æ˜åˆ—å‡ºå®¡æŸ¥æ„è§ï¼ˆä¾‹å¦‚ï¼šâ€œç»“è®ºåæ—©â€ï¼Œâ€œè°±çº¿è§£é‡Šæ­£ç¡®â€ï¼‰
- å¯¹æ¯ä¸ªå‘ç°é™„ä¸Šæ”¹è¿›å»ºè®®
- æœ€åç»™å‡ºæ•´ä½“è¯„ä»·ï¼ˆå¯é /éƒ¨åˆ†å¯ä¿¡/ä¸å¯ä¿¡ï¼‰

å·²çŸ¥ï¼šç»¼åˆåŸæ›²çº¿å’Œ sigma=2ã€sigma=4ã€sigma=16 ä¸‰æ¡é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}

å…¶ä»–åˆ†æå¸ˆç»™å‡ºçš„å…‰è°±åˆ†ææŠ¥å‘Šä¸ºï¼š

{rule_analysis}

è¯¥æŠ¥å‘Šåœ¨çº¢ç§»è®¡ç®—æ—¶ä¿ç•™äº† 3 ä½å°æ•°ã€‚

è¯¥å…‰è°±çš„æ³¢é•¿èŒƒå›´æ˜¯{state['spectrum']['new_wavelength'][0]} Ã… åˆ° {state['spectrum']['new_wavelength'][-1]} Ã…ã€‚
"""
        prompt_2 = f"""

æˆ‘å¸Œæœ›å…‰è°±åˆ†ææŠ¥å‘Šèƒ½å¤Ÿå°½å¯èƒ½å¥½åœ°åŒ¹é… LyÎ±ã€C IVã€C III]ã€Mg II ç­‰å…¸å‹å‘å°„çº¿ï¼Œä½†ä¹Ÿå…è®¸åœ¨ç”±äºå…‰è°±è¾¹ç¼˜çš„ä¿¡å·æ®‹ç¼ºæˆ–ä¿¡å™ªæ¯”ä¸ä½³å¯¼è‡´éƒ¨åˆ†å‘å°„çº¿ä¸å¯è§ã€‚

åŒæ—¶ï¼Œåœ¨ä¿¡å™ªæ¯”ä¸ä½³æ—¶ï¼Œå¯»æ‰¾è°±çº¿çš„ç®—æ³•ä¹Ÿä¼šå—åˆ°å½±å“ï¼Œå› æ­¤ä¹Ÿå…è®¸çº¿å®½ä¸æœŸæœ›å­˜åœ¨ä¸€å®šçš„çš„å·®å¼‚ã€‚

ç”±äºå¤©æ–‡å­¦ä¸Šå¤–æµæ•ˆåº”çš„å½±å“ï¼Œåº”ä½¿ç”¨æœ€ä½ç”µç¦»æ€çš„å‘å°„çº¿çš„çº¢ç§»ä½œä¸ºå…‰è°±çº¢ç§»çš„æœ€ä½³ç»“æœã€‚

ä½¿ç”¨å·¥å…· QSO_rms è®¡ç®—çº¢ç§»è¯¯å·® Â± Î”z
    - å·¥å…·çš„è¾“å…¥ä¸º
        wavelength_rest: List[float], #æœ€ä½ç”µç¦»æ€çš„å‘å°„çº¿çš„é™æ­¢ç³»æ³¢é•¿
        a: float = {a},           
        tolerance: int = {tolerence},     
        rms_lambda = {rms}: float    

å¦‚æœåˆ†æä¸­ä¸æ”¯æŒ2æ¡åŠä»¥ä¸Šä¸»è¦è°±çº¿ï¼ˆæŒ‡ LyÎ±, C IV, C III, Mg IIï¼‰å‡ºç°çš„è¯æ®ï¼Œåˆ™é¦–å…ˆè½¬å‘è€ƒè™‘æ˜¯Galaxyçš„å¯èƒ½æ€§ã€‚
å¯¹ Galaxy çš„è®¤è¯æ— éœ€è€ƒè™‘è°±çº¿å’Œçº¢ç§»ï¼Œä»…éœ€ä»å½¢æ€ä¸Šè¿›è¡Œåˆ†æ
"""
        return prompt_1 + prompt_2

    async def auditing(self, state: SpectroState, obj):
        header = self._common_prompt_header(state, obj)

        if state['count'] == 0:
            body = f"""
è¯·å¯¹è¿™ä»½åˆ†ææŠ¥å‘Šè¿›è¡Œæ£€æŸ¥ã€‚
"""
        elif state['count']: 
            auditing_history = state['auditing_history_QSO'][-1] if obj == 'QSO' else state['auditing_history_galaxy'][-1] 
            auditing_history_json = json.dumps(auditing_history, ensure_ascii=False)
            response_history = state['refine_history_QSO'][-1] if obj == 'QSO' else state['refine_history_galaxy'][-1] 
            response_history_json = json.dumps(response_history, ensure_ascii=False)

            body = f"""
ä½ å¯¹è¿™ä»½åˆ†ææŠ¥å‘Šçš„æœ€æ–°è´¨ç–‘ä¸º
{auditing_history_json}

å…¶ä»–åˆ†æå¸ˆçš„å›ç­”ä¸º
{response_history_json}

è¯·å›åº”å…¶ä»–åˆ†æå¸ˆçš„å›ç­”ï¼Œå¹¶ç»§ç»­è¿›è¡Œå®¡æŸ¥ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context('', prompt, parse_json=False, description="æŠ¥å‘Šå®¡æŸ¥")
        state['auditing_history_QSO'].append(response) if obj == 'QSO' else state['auditing_history_galaxy'].append(response)

    async def run(self, state: SpectroState) -> SpectroState:
        if 'QSO' in state['possible_object']:
            await self.auditing(state, obj='QSO')
        # if 'Galaxy' in state['possible_object']:
        #     await self.auditing(state, obj='Galaxy')
        return state



# # ---------------------------------------------------------
# # 4. Reflective Analyst â€” è‡ªç”±å›åº”å®¡æŸ¥å¹¶æ”¹è¿›
# # ---------------------------------------------------------
class SpectralRefinementAssistant(BaseAgent):
    """æ”¹è¿›è€…ï¼šå›åº”å®¡æŸ¥å¹¶æ”¹è¿›åˆ†æ"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Refinement Assistant',
            mcp_manager=mcp_manager
        )

    def _common_prompt_header(self, state, obj) -> str:
        peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)
        trough_json = json.dumps(state['troughs'], ensure_ascii=False)
        rule_analysis = "\n\n".join(str(item) for item in state['rule_analysis_QSO'])
        a = state["pixel_to_value"]["x"]["a"]
        rms = state["pixel_to_value"]["x"]["rms"]
        tolerence = getenv_int("TOL_PIXELS", 10)
        prompt_1 = f"""
ä½ æ˜¯ä¸€ä½å…·å¤‡åæ€èƒ½åŠ›çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æå¸ˆã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- é˜…è¯»å¹¶ç†è§£ä»–äººçš„å…‰è°±åˆ†ææŠ¥å‘Š
- é˜…è¯»å¹¶ç†è§£å®¡æŸ¥å®˜æå‡ºçš„åé¦ˆ
- å¯¹è‡ªèº«æˆ–ä»–äººå…ˆå‰çš„åˆ†æè¿›è¡Œæ”¹è¿›
- æå‡ºæ–°çš„è§£é‡Šæˆ–ä¿®æ­£ç»“è®º

å·¥ä½œåŸåˆ™ï¼š
- è®¤çœŸå›åº”æ¯æ¡åé¦ˆï¼Œé€ä¸€è¯´æ˜æ”¹è¿›ä¹‹å¤„
- å¦‚æœè®¤ä¸ºåŸç»“è®ºæ­£ç¡®ï¼Œéœ€ç»™å‡ºå……åˆ†ç†ç”±
- æœ€ç»ˆè¾“å‡ºä¸€ä¸ªæ›´ä¸¥è°¨ã€å®Œå–„çš„åˆ†æç‰ˆæœ¬
- æ¶‰åŠçº¢ç§»å’Œå…‰è°±è§‚æµ‹æ³¢é•¿çš„è®¡ç®—å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshift å’Œ  predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- è¯·è¾“å‡ºè¯´æ˜æ€§çš„è¯­è¨€
- åˆ—å‡ºæ”¶åˆ°çš„åé¦ˆåŠå¯¹åº”å›åº”
- æä¾›æ”¹è¿›åçš„å…‰è°±åˆ†ææ€»ç»“
- è¯´æ˜ä¿®æ”¹å†…å®¹åŠå…¶ç§‘å­¦åˆç†æ€§

å·²çŸ¥ï¼šç»¼åˆåŸæ›²çº¿å’Œ sigma=2ã€sigma=4ã€sigma=16 ä¸‰æ¡é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}

å…¶ä»–åˆ†æå¸ˆç»™å‡ºçš„å…‰è°±åˆ†ææŠ¥å‘Šä¸ºï¼š

{rule_analysis}

è¯¥æŠ¥å‘Šåœ¨çº¢ç§»è®¡ç®—æ—¶ä¿ç•™äº† 3 ä½å°æ•°ã€‚

è¯¥å…‰è°±çš„æ³¢é•¿èŒƒå›´æ˜¯{state['spectrum']['new_wavelength'][0]} Ã… åˆ° {state['spectrum']['new_wavelength'][-1]} Ã…ã€‚
"""

        prompt_2 = f"""

æˆ‘å¸Œæœ›å…‰è°±åˆ†ææŠ¥å‘Šèƒ½å¤Ÿå°½å¯èƒ½å¥½åœ°åŒ¹é… LyÎ±ã€C IVã€C III]ã€Mg II ç­‰å…¸å‹å‘å°„çº¿ï¼Œä½†ä¹Ÿå…è®¸åœ¨ç”±äºå…‰è°±è¾¹ç¼˜çš„ä¿¡å·æ®‹ç¼ºæˆ–ä¿¡å™ªæ¯”ä¸ä½³å¯¼è‡´éƒ¨åˆ†å‘å°„çº¿ä¸å¯è§ã€‚

åŒæ—¶ï¼Œåœ¨ä¿¡å™ªæ¯”ä¸ä½³æ—¶ï¼Œå¯»æ‰¾è°±çº¿çš„ç®—æ³•ä¹Ÿä¼šå—åˆ°å½±å“ï¼Œå› æ­¤ä¹Ÿå…è®¸çº¿å®½ä¸æœŸæœ›å­˜åœ¨ä¸€å®šçš„çš„å·®å¼‚ã€‚

ç”±äºå¤©æ–‡å­¦ä¸Šå¤–æµæ•ˆåº”çš„å½±å“ï¼Œåº”ä½¿ç”¨æœ€ä½ç”µç¦»æ€çš„å‘å°„çº¿çš„çº¢ç§»ä½œä¸ºå…‰è°±çº¢ç§»çš„æœ€ä½³ç»“æœã€‚

ä½¿ç”¨å·¥å…· QSO_rms è®¡ç®—çº¢ç§»è¯¯å·® Â± Î”z
    - å·¥å…·çš„è¾“å…¥ä¸º
        wavelength_rest: List[float], # æœ€ä½ç”µç¦»æ€çš„å‘å°„çº¿çš„é™æ­¢ç³»æ³¢é•¿
        a: float = {a},           
        tolerance: int = {tolerence},     
        rms_lambda = {rms}: float 

å¦‚æœåˆ†æä¸­ä¸æ”¯æŒ2æ¡åŠä»¥ä¸Šä¸»è¦è°±çº¿ï¼ˆæŒ‡ LyÎ±, C IV, C III, Mg IIï¼‰å‡ºç°çš„è¯æ®ï¼Œåˆ™é¦–å…ˆè½¬å‘è€ƒè™‘æ˜¯Galaxyçš„å¯èƒ½æ€§ã€‚
å¯¹ Galaxy çš„è®¤è¯æ— éœ€è€ƒè™‘è°±çº¿å’Œçº¢ç§»ï¼Œä»…éœ€ä»å½¢æ€ä¸Šè¿›è¡Œåˆ†æ
"""
        return prompt_1 + prompt_2

    async def refine(self, state: SpectroState, obj):
        header = self._common_prompt_header(state, obj)
        auditing_history = state['auditing_history_QSO'][-1] if obj == 'QSO' else state['auditing_history_galaxy'][-1]
        auditing_history_json = json.dumps(auditing_history, ensure_ascii=False)
        body = f"""
è´Ÿè´£æ ¸éªŒæŠ¥å‘Šçš„å®¡æŸ¥åˆ†æå¸ˆç»™å‡ºçš„æœ€æ–°å»ºè®®ä¸º
{auditing_history_json}

è¯·å¯¹å»ºè®®è¿›è¡Œå›åº”ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context('', prompt, parse_json=False, description="å›åº”å®¡æŸ¥")
        state['refine_history_QSO'].append(response) if obj == 'QSO' else state['refine_history_galaxy'].append(response)

    async def run(self, state: SpectroState) -> SpectroState:
        try:
            if 'QSO' in state['possible_object']:
                await self.refine(state, obj='QSO')
            # if 'Galaxy' in state['possible_object']:
            #     await self.refine(state, obj='Galaxy')
            return state
        except Exception as e:
            import traceback
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Full traceback:")
            traceback.print_exc()
            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸
            raise  # å¦‚æœä½ å¸Œæœ›è°ƒç”¨è€…ä¹Ÿèƒ½æ•è·è¯¥å¼‚å¸¸


# ---------------------------------------------------------
# ğŸ§© 5. Host Integrator â€” æ±‡æ€»ä¸æ€»ç»“å¤šæ–¹è§‚ç‚¹
# ---------------------------------------------------------
class SpectralSynthesisHost(BaseAgent):
    """æ±‡æ€»ä¸»æŒäººï¼šæ•´åˆå¤šAgentçš„åˆ†æä¸ç»“è®º"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Synthesis Host',
            mcp_manager=mcp_manager
        )

    def get_system_prompt(self) -> str:
        return f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- æ±‡æ€»è§†è§‰åˆ†æå¸ˆã€è§„åˆ™åˆ†æå¸ˆã€å®¡æŸ¥å®˜å’Œå†åˆ†æå¸ˆçš„æ‰€æœ‰è¾“å‡º
- ç»¼åˆä¸åŒè§’åº¦çš„ç»“è®ºï¼Œå½¢æˆæœ€ç»ˆçš„å…‰è°±è§£é‡Š
- æ¸…æ¥šæŒ‡å‡ºå„æ–¹æ„è§çš„å·®å¼‚ä¸ä¸€è‡´ç‚¹

å·¥ä½œåŸåˆ™ï¼š
- æ— éœ€è°ƒç”¨å·¥å…·
- ä¸ç›²ä»ä»»ä½•å•ä¸€åˆ†æ
- ä¿æŒæ•´ä½“ç§‘å­¦æ€§ä¸é€»è¾‘ä¸€è‡´æ€§
- æœ€ç»ˆè¾“å‡ºå¿…é¡»å…·å¤‡å¯è¿½æº¯æ€§ï¼ˆè¯´æ˜æ¥è‡ªå“ªäº›agentçš„ä¾æ®ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- è¾“å‡ºè¯´æ˜æ€§æ–‡å­—
- è¾“å‡ºæ•°æ®ä¿ç•™ 3 ä½å°æ•°
- åªéœ€è¾“å‡ºåˆ†æå†…å®¹ï¼Œæ— éœ€å£°æ˜å„æ®µåˆ†ææ–‡å­—çš„æ¥æº
- ç»™å‡ºæœ€ç»ˆç»¼åˆç»“è®ºåŠå¯ä¿¡åº¦è¯„çº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
- å¦‚æœä»å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
- æŒ‰æ ¼å¼è¾“å‡ºã€‚ä¸è¦è¾“å‡ºå¤šä½™å†…å®¹
"""


    async def summary(self, state):
        try:
            preliminary_classification_json = json.dumps(state['preliminary_classification'], ensure_ascii=False)
            visual_interpretation_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
        except Exception as e:
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            raise

        header = self.get_system_prompt()

        prompt_1 = f"""

å¯¹å…‰è°±çš„è§†è§‰æè¿°
{visual_interpretation_json}

å…‰è°±çš„åˆæ­¥åˆ†ç±»
{preliminary_classification_json}
"""
        if "QSO" in state['preliminary_classification']:
            rule_analysis_QSO = "\n\n".join(str(item) for item in state['rule_analysis_QSO'])
            rule_analysis_QSO_json = json.dumps(rule_analysis_QSO, ensure_ascii=False)
            auditing_QSO = "\n\n".join(str(item) for item in state['auditing_history_QSO'])
            auditing_QSO_json = json.dumps(auditing_QSO, ensure_ascii=False)
            refine_QSO = "\n\n".join(str(item) for item in state['refine_history_QSO'])
            refine_QSO_json = json.dumps(refine_QSO, ensure_ascii=False)
            prompt_2 = f"""

è§„åˆ™åˆ†æå¸ˆçš„è§‚ç‚¹ï¼š
{rule_analysis_QSO_json}

å®¡æŸ¥åˆ†æå¸ˆçš„è§‚ç‚¹ï¼š
{auditing_QSO_json}

å®Œå–„åˆ†æå¸ˆçš„è§‚ç‚¹ï¼š
{refine_QSO_json}
"""
        prompt_3 = f"""

è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š

- å…‰è°±çš„è§†è§‰ç‰¹ç‚¹
- åˆ†ææŠ¥å‘Šï¼ˆç»¼åˆè§„åˆ™åˆ†æå¸ˆã€å®¡æŸ¥åˆ†æå¸ˆå’Œå®Œå–„åˆ†æå¸ˆçš„æ‰€æœ‰è§‚ç‚¹ï¼Œé€ä¸ª Step è¿›è¡Œç»“æ„åŒ–è¾“å‡ºï¼‰
    - Step 1
    - Step 2
    - Step 3
    - Step 4
- ç»“è®º
    - è¯¥å¤©ä½“æœ€æœ‰å¯èƒ½çš„çš„å¤©ä½“ç±»å‹ï¼ˆStarï¼ŒGalaxy è¿˜æ˜¯ QSOï¼‰ï¼Œå¦‚æœåˆ†æä¸­ä¸æ”¯æŒ2æ¡åŠä»¥ä¸Šä¸»è¦è°±çº¿ï¼ˆæŒ‡ LyÎ±, C IV, C III, Mg IIï¼‰å‡ºç°çš„è¯æ®ï¼Œåˆ™è½¬å‘è€ƒè™‘æ˜¯Galaxyçš„å¯èƒ½æ€§
    - å¦‚æœå¤©ä½“æ˜¯QSOï¼Œè¾“å‡ºçº¢ç§» z Â± Î”z
    - è®¤è¯å‡ºçš„è°±çº¿ï¼ˆè¾“å‡º è°±çº¿å - Î»_rest - Î»_obs - çº¢ç§»ï¼‰
    - å…‰è°±çš„ä¿¡å™ªæ¯”å¦‚ä½•
    - åˆ†ææŠ¥å‘Šçš„å¯ä¿¡åº¦è¯„åˆ†ï¼ˆ0-4ï¼‰
        - å¯¹äºQSOï¼š
            å¦‚æœèƒ½è®¤è¯å‡º 2 æ¡ä»¥ä¸Šçš„ä¸»è¦è°±çº¿ï¼ˆæŒ‡ LyÎ±, C IV, C III, Mg IIï¼‰ï¼Œåˆ™å¯ä¿¡åº¦ä¸º 3ï¼›
            èƒ½è®¤è¯å‡º 1 æ¡ä¸»è¦è°±çº¿ï¼Œä¸”æœ‰å…¶ä»–è¾ƒå¼±çš„ç‰¹å¾ï¼Œåˆ™å¯ä¿¡åº¦ä¸º 2ï¼›
            èƒ½è®¤è¯å‡º 1 æ¡ä¸»è¦è°±çº¿ï¼Œä½†æ²¡æœ‰å…¶ä»–ç‰¹å¾è¾…åŠ©åˆ¤æ–­ï¼Œåˆ™å¯ä¿¡åº¦ä¸º 1ï¼›
            å…‰è°±ä¿¡å™ªæ¯”æä½ï¼Œå«ä¹‰è¿›è¡Œæ¨æ–­ï¼Œåˆ™å¯ä¿¡åº¦ä¸º 0.
        - å¯¹äº Galaxy
            å¦‚æœåŸºæœ¬æ»¡è¶³
    - æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥åˆ¤æ–­ï¼ˆå¯ä¿¡åº¦ä¸º 0-2 æ—¶å¿…é¡»å¼•å…¥äººå·¥åˆ¤æ–­ã€‚å…¶ä½™æƒ…å†µè‡ªè¡Œå†³ç­–ã€‚ï¼‰
"""
        prompt = header + prompt_1 + prompt_2 + prompt_3
        response = await self.call_llm_with_context('', prompt, parse_json=False, description="æ€»ç»“")
        state['summary'] = response
    async def in_brief(self, state):
        summary_json = json.dumps(state['summary'], ensure_ascii=False)
        prompt_type = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

- è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **å¤©ä½“ç±»å‹**ï¼ˆä»è¿™ä¸‰ä¸ªè¯è¯­ä¸­é€‰æ‹©ï¼šStar, Galaxy, QSOï¼‰

- è¾“å‡ºæ ¼å¼ä¸º str
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_type = await self.call_llm_with_context('', prompt_type, parse_json=False, description="æ€»ç»“")
        state['in_brief']['type'] = response_type

        prompt_redshift = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **çº¢ç§» z**ï¼ˆä¸éœ€è¦è¾“å‡º Â± Î”zï¼‰

- è¾“å‡ºæ ¼å¼ä¸º float
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_redshift = await self.call_llm_with_context('', prompt_redshift, parse_json=False, description="æ€»ç»“")
        state['in_brief']['redshift'] = response_redshift

        prompt_rms = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **çº¢ç§»è¯¯å·® Î”z**ï¼ˆä¸éœ€è¦è¾“å‡º zï¼‰

- è¾“å‡ºæ ¼å¼ä¸º float
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_rms = await self.call_llm_with_context('', prompt_rms, parse_json=False, description="æ€»ç»“")
        state['in_brief']['rms'] = response_rms

        prompt_human = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥åˆ¤æ–­**

- ä»…è¾“å‡ºâ€œæ˜¯â€æˆ–â€œå¦â€
- è¾“å‡ºæ ¼å¼ä¸º str
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_human = await self.call_llm_with_context('', prompt_human, parse_json=False, description="æ€»ç»“")
        state['in_brief']['human'] = response_human
    
    async def run(self, state: SpectroState) -> SpectroState:
        try:
            await self.summary(state)
            await self.in_brief(state)
            return state
        except Exception as e:
            import traceback
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Full traceback:")
            traceback.print_exc()
            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸
