import json
import os

from .context_manager import SpectroState
from .base_agent import BaseAgent
from .mcp_manager import MCPManager

from .utils import (
    _detect_axis_ticks, _detect_chart_border, _crop_img,
    _remap_to_cropped_canvas, _pixel_tickvalue_fitting,
    _process_and_extract_curve_points, _convert_to_spectrum,
    _find_features_multiscale, _plot_spectrum, _plot_features,
    parse_list, getenv_float, getenv_int
)

# ---------------------------------------------------------
# 1. Visual Assistant â€” è´Ÿè´£å›¾åƒç†è§£ä¸åæ ‡é˜…è¯»
# ---------------------------------------------------------

class SpectralVisualInterpreter(BaseAgent):
    """
    SpectralVisualInterpreter

    ä»ç§‘å­¦å…‰è°±å›¾ä¸­è‡ªåŠ¨æå–åæ ‡è½´åˆ»åº¦ã€è¾¹æ¡†ã€åƒç´ æ˜ å°„ã€å³°/è°·ç­‰ä¿¡æ¯
    """

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Visual Interpreter',
            mcp_manager=mcp_manager
        )

    # --------------------------
    # Step 1.1: æ£€æµ‹åæ ‡è½´åˆ»åº¦
    # --------------------------
    async def detect_axis_ticks(self, state: SpectroState):
        """
        è°ƒç”¨è§†è§‰ LLM æ£€æµ‹åæ ‡è½´åˆ»åº¦ï¼Œå¦‚æœæ— å›¾åƒæˆ–éå…‰è°±å›¾æŠ¥é”™
        """
        class NoImageError(Exception): pass
        class NotSpectralImageError(Exception): pass

        if not state['image_path'] or not os.path.exists(state['image_path']):
            raise NoImageError("âŒ æœªè¾“å…¥å›¾åƒæˆ–å›¾åƒè·¯å¾„ä¸å­˜åœ¨")

        prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè§†è§‰åˆ†ææ¨¡å‹ï¼Œæ“…é•¿ä»ç§‘å­¦å›¾è¡¨æå–åæ ‡è½´åˆ»åº¦ä¿¡æ¯ã€‚
å¦‚æœè¾“å…¥ä¸­ä¸åŒ…å«å…‰è°±å›¾ï¼Œè¯·è¾“å‡º â€œéå…‰è°±å›¾â€ã€‚
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema è¾“å‡ºï¼š
{
  "x_axis": {
    "label_and_Unit": "str",
    "tick_range": {"min": float, "max": float},
    "ticks": [float]
  },
  "y_axis": {
    "label_and_Unit": "str",
    "tick_range": {"min": float, "max": float},
    "ticks": [float]
  }
}
"""

        axis_info = await self.call_llm_with_context(
            prompt,
            image_path=state['image_path'],
            parse_json=True,
            description="åæ ‡è½´ä¿¡æ¯"
        )

        if axis_info == "éå…‰è°±å›¾":
            raise NotSpectralImageError(f"âŒ å›¾åƒä¸æ˜¯å…‰è°±å›¾ï¼ŒLLM è¾“å‡º: {axis_info}")

        state["axis_info"] = axis_info
        return state

    # --------------------------
    # Step 1.2~1.3: åˆå¹¶è§†è§‰+OCRåˆ»åº¦
    # --------------------------
    async def combine_axis_mapping(self, state: SpectroState):
        """ç»“åˆè§†è§‰ç»“æœä¸ OCR ç»“æœç”Ÿæˆåƒç´ -æ•°å€¼æ˜ å°„"""
        axis_info_json = json.dumps(state['axis_info'], ensure_ascii=False)
        ocr_json = json.dumps(state['OCR_detected_ticks'], ensure_ascii=False)

        prompt = f"""
ä½ æ˜¯ç§‘å­¦å›¾è¡¨é˜…è¯»åŠ©æ‰‹ã€‚
è¾“å…¥ä¸¤ç»„åˆ»åº¦ä¿¡æ¯ï¼š
1. è§†è§‰æ¨¡å‹ï¼š{axis_info_json}
2. OCR/Opencvï¼š{ocr_json}

ä»»åŠ¡ï¼š
- åˆå¹¶ä¸¤ç»„ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ»åº¦å€¼-åƒç´ æ˜ å°„
- x è½´ pixel å•è°ƒé€’å¢ï¼Œy è½´ pixel å•è°ƒé€’å‡
- ä¿®æ­£ OCR ä¸å•è°ƒæ€§å†²çªçš„ pixel
- ç¼ºå¤±åˆ»åº¦ç”¨ null å¡«å……ï¼Œbounding-box-scale_x/y ç¼ºå¤±ç”¨ null å¡«å……
- sigma_pixel = bounding-box-scale / 2ï¼Œç¼ºå¤±ä¸º null
- conf_llm: OCR é«˜å¯ä¿¡åº¦ 0.9ï¼Œæ’å€¼/ä¿®æ­£ 0.7ï¼Œç¼ºå¤±è§†è§‰é¢„æµ‹ 0.5

è¾“å‡ºï¼š
- ä¸¥æ ¼ JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
  "axis" ("x" æˆ– "y"), "value", "position_x", "position_y",
  "bounding-box-scale_x", "bounding-box-scale_y",
  "sigma_pixel", "conf_llm"
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–æ–‡å­—
"""
        tick_pixel_raw = await self.call_llm_with_context(
            prompt,
            image_path=state['image_path'],
            parse_json=True,
            description="åˆ»åº¦-åƒç´ æ˜ å°„"
        )

        state["tick_pixel_raw"] = tick_pixel_raw
        return state

    # --------------------------
    # Step 1.4: æ ¡éªŒä¸ä¿®æ­£
    # --------------------------
    async def revise_axis_mapping(self, state: SpectroState):
        """æ£€æŸ¥å¹¶ä¿®æ­£åˆ»åº¦å€¼ä¸åƒç´ ä½ç½®åŒ¹é…å…³ç³»"""
        axis_mapping_json = json.dumps(state['tick_pixel_raw'], ensure_ascii=False)

        prompt = f"""
ä½ æ˜¯ç§‘å­¦å›¾è¡¨é˜…è¯»åŠ©æ‰‹ã€‚
æ£€æŸ¥ä»¥ä¸‹åˆ»åº¦å€¼ä¸åƒç´ æ˜ å°„ï¼š
{axis_mapping_json}

è§„åˆ™ï¼š
- y è½´: æ•°å€¼ä»å°åˆ°å¤§ pixel åº”ä¸¥æ ¼é€’å‡
- x è½´: æ•°å€¼ä»å°åˆ°å¤§ pixel åº”ä¸¥æ ¼é€’å¢
å…è®¸å­˜åœ¨ null
å¦‚æœæœ‰é—®é¢˜ï¼Œè¯·ä¿®è®¢å¹¶è¾“å‡º JSONï¼›å¦åˆ™ç›´æ¥è¿”å›åŸè¾“å…¥
ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—
"""

        tick_pixel_revised = await self.call_llm_with_context(
            prompt,
            image_path=state['image_path'],
            parse_json=True,
            description="ä¿®æ­£åçš„åˆ»åº¦æ˜ å°„"
        )

        state["tick_pixel_raw"] = tick_pixel_revised

    # --------------------------
    # è¯»å–ç¯å¢ƒå˜é‡
    # --------------------------
    def _load_feature_params(self):
        """å®‰å…¨è¯»å–å³°å€¼/è°·å€¼æ£€æµ‹å‚æ•°"""
        sigma_list = parse_list(os.getenv("SIGMA_LIST"), [2, 4, 16])
        tol_pixels = getenv_int("TOL_PIXELS", 10)
        prom_peaks = getenv_float("PROM_THRESHOLD_PEAKS", 0.01)
        prom_troughs = getenv_float("PROM_THRESHOLD_TROUGHS", 0.05)
        weight_original = getenv_float("WEIGHT_ORIGINAL", 1.0)
        plot_peaks = getenv_int("PLOT_PEAKS_NUMBER", 10)
        plot_troughs = getenv_int("PLOT_TROUGHS_NUMBER", 15)

        return sigma_list, tol_pixels, prom_peaks, prom_troughs, weight_original, plot_peaks, plot_troughs

    # --------------------------
    # Step 1.1~1.11: ä¸»æµç¨‹
    # --------------------------
    async def run(self, state: SpectroState, plot: bool = True):
        """æ‰§è¡Œå®Œæ•´è§†è§‰åˆ†ææµç¨‹"""
        try:
            # Step 1.1: è§†è§‰ LLM æå–åæ ‡è½´
            await self.detect_axis_ticks(state)

            # Step 1.2: OCR æå–åˆ»åº¦
            state["OCR_detected_ticks"] = _detect_axis_ticks(state['image_path'])
            print(state["OCR_detected_ticks"])

            # Step 1.3: åˆå¹¶
            await self.combine_axis_mapping(state)
            print(state["tick_pixel_raw"])

            # Step 1.4: ä¿®æ­£
            await self.revise_axis_mapping(state)
            print(state["tick_pixel_raw"])

            # Step 1.5: è¾¹æ¡†æ£€æµ‹ä¸è£å‰ª
            state["chart_border"] = _detect_chart_border(state['image_path'])
            _crop_img(state['image_path'], state["chart_border"], state['crop_path'])

            # Step 1.6: é‡æ˜ å°„åƒç´ 
            state["tick_pixel_remap"] = _remap_to_cropped_canvas(state['tick_pixel_raw'], state["chart_border"])

            # Step 1.7: æ‹Ÿåˆåƒç´ -æ•°å€¼
            state["pixel_to_value"] = _pixel_tickvalue_fitting(state['tick_pixel_remap'])

            # Step 1.8: æå–æ›²çº¿ & ç°åº¦åŒ–
            curve_points, curve_gray_values = _process_and_extract_curve_points(state['crop_path'])
            state["curve_points"] = curve_points
            state["curve_gray_values"] = curve_gray_values

            # Step 1.9: å…‰è°±è¿˜åŸ
            state["spectrum"] = _convert_to_spectrum(state['curve_points'], state['curve_gray_values'], state['pixel_to_value'])

            # Step 1.10: æ£€æµ‹å³°å€¼/è°·å€¼
            sigma_list, tol_pixels, prom_peaks, prom_troughs, weight_original, plot_peaks, plot_troughs = self._load_feature_params()
            state['sigma_list'] = sigma_list
            # state["peaks"] = _find_features_multiscale(state, "peak", sigma_list, prom_peaks, tol_pixels, weight_original)
            # state["troughs"] = _find_features_multiscale(state, "trough", sigma_list, prom_troughs, tol_pixels, weight_original)
            try:
                state["peaks"] = _find_features_multiscale(
                    state, feature="peak", sigma_list=sigma_list,
                    prom=prom_peaks, tol_pixels=tol_pixels, weight_original=weight_original,
                    use_continuum_for_trough=True
                )
                state["troughs"] = _find_features_multiscale(
                    state, feature="trough", sigma_list=sigma_list,
                    prom=prom_troughs, tol_pixels=tol_pixels, weight_original=weight_original,
                    use_continuum_for_trough=True,
                    min_depth=0.08
                )
            except Exception as e:
                print(f"âŒ find features multiscale terminated with error: {e}")
                raise
            print(len(state["troughs"]))

            # await self.features_cleaning_peaks(state)

            # Step 1.11: å¯é€‰ç»˜å›¾
            if plot:
                try:
                    state["spectrum_fig"] = _plot_spectrum(state)
                    state["features_fig"] = _plot_features(state, sigma_list, [plot_peaks, plot_troughs])
                except Exception as e:
                    print(f"âŒ plot spectrum or features terminated with error: {e}")
                    raise

            return state

        except Exception as e:
            print(f"âŒ run pipeline terminated with error: {e}")
            raise

# ---------------------------------------------------------
# 2. Rule-based Analyst â€” è´Ÿè´£åŸºäºè§„åˆ™çš„ç‰©ç†åˆ†æ
# ---------------------------------------------------------
class SpectralRuleAnalyst(BaseAgent):
    
    """è§„åˆ™é©±åŠ¨å‹åˆ†æå¸ˆï¼šåŸºäºç»™å®šçš„ç‰©ç†ä¸è°±çº¿çŸ¥è¯†è¿›è¡Œå®šæ€§åˆ†æ"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Rule Analyst',
            mcp_manager=mcp_manager
        )

    async def describe_spectrum_picture(self, state: SpectroState):
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

ä½ å°†çœ‹åˆ°ä¸€æ¡å¤©æ–‡å…‰è°±æ›²çº¿ï¼ˆæ¥è‡ªæœªçŸ¥çº¢ç§»çš„å¤©ä½“ï¼‰ã€‚

è¯·ç»“åˆå›¾åƒï¼Œ**å®šæ€§åœ°æè¿°å…‰è°±çš„æ•´ä½“å½¢æ€**ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

---

### Step 1: è¿ç»­è°±å½¢æ€
- æ•´ä½“çš„é€šé‡åˆ†å¸ƒè¶‹åŠ¿ï¼ˆä¾‹å¦‚è“ç«¯å¢å¼º / çº¢ç«¯å¢å¼º / å¤§è‡´å¹³å¦ / å‘ˆæ‹±å½¢ç­‰ï¼‰ã€‚
- æ˜¯å¦å¯ä»¥çœ‹å‡ºå¹‚å¾‹å‹è¿ç»­è°±ã€é»‘ä½“å‹è°±æˆ–å¹³å¦è°±çš„ç‰¹å¾ã€‚
- è¿ç»­è°±ä¸­æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æ–­è£‚æˆ–æŠ˜ç‚¹ï¼ˆä¾‹å¦‚å·´å°”æœ«æ–­è£‚ã€LyÎ± forest åŒºåŸŸç­‰ï¼‰ã€‚

### Step 2: ä¸»è¦å‘å°„ä¸å¸æ”¶ç‰¹å¾
- æ˜¯å¦å­˜åœ¨çªå‡ºçš„å‘å°„å³°æˆ–å¸æ”¶è°·ã€‚
- å‘å°„çº¿ï¼ˆæˆ–å¸æ”¶çº¿ï¼‰çš„å¤§è‡´æ•°é‡ä¸ç›¸å¯¹å¼ºå¼±ã€‚
- è¿™äº›çº¿æ˜¯å®½çš„è¿˜æ˜¯çª„çš„ã€å¯¹ç§°çš„è¿˜æ˜¯ä¸å¯¹ç§°çš„ã€‚
- è¯·é¿å…ç»™å‡ºå…·ä½“æ•°å€¼ï¼ˆå¦‚ç²¾ç¡®æ³¢é•¿æˆ–é€šé‡ï¼‰ï¼Œåªéœ€è¯´æ˜å®ƒä»¬ç›¸å¯¹çš„ä½ç½®ä¸ç‰¹å¾ã€‚

### Step 3: æ•´ä½“ç»“æ„ä¸å™ªå£°ç‰¹å¾
- å…‰è°±ä¿¡å™ªæ¯”çš„æ€»ä½“å°è±¡ï¼ˆé«˜ / ä¸­ / ä½ï¼‰ã€‚
- æ˜¯å¦å­˜åœ¨å™ªå£°æ³¢åŠ¨ã€å¼‚å¸¸å°–å³°æˆ–æ•°æ®ç¼ºå£ã€‚
- å…‰è°±åœ¨é•¿æ³¢ç«¯æˆ–çŸ­æ³¢ç«¯çš„è´¨é‡å˜åŒ–æƒ…å†µã€‚

---

âš ï¸ **æ³¨æ„ï¼š**
- ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼
- ä¸å°è¯•è®¡ç®—çº¢ç§»
- é‡ç‚¹åœ¨è§†è§‰ä¸å½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­
- ä¸è¦è°ƒç”¨å·¥å…·ï¼›

æœ€åï¼Œè¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼è¾“å‡ºä½ çš„è§‚å¯Ÿç»“æœï¼Œä¾‹å¦‚ä½¿ç”¨åˆ†èŠ‚æ ‡é¢˜ï¼š
-ï¼ˆè¿ç»­è°±ï¼‰
-ï¼ˆå‘å°„ä¸å¸æ”¶ï¼‰
-ï¼ˆå™ªå£°ä¸æ•°æ®è´¨é‡ï¼‰
"""
        
        response = await self.call_llm_with_context(
            prompt,
            image_path=state['image_path'],
            parse_json=False,
            description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
        )
        state['visual_interpretation'] = response
        
    
    async def preliminary_classification(self, state: SpectroState) -> str:
        """åˆæ­¥åˆ†ç±»ï¼šæ ¹æ®å…‰è°±å½¢æ€åˆæ­¥åˆ¤æ–­å¤©ä½“ç±»å‹"""

        visual_interpretation_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

ä½ å°†çœ‹åˆ°ä¸€æ¡å¤©æ–‡å…‰è°±æ›²çº¿ï¼ˆæ¥è‡ªæœªçŸ¥çº¢ç§»çš„å¤©ä½“ï¼‰ï¼Œå®ƒå¯èƒ½å±äºä»¥ä¸‹ä¸‰ç±»ä¹‹ä¸€ï¼š
- **Starï¼ˆæ’æ˜Ÿï¼‰**ï¼šè¿ç»­è°±è¾ƒå¼ºï¼Œè°±çº¿é€šå¸¸æ˜¯å¸æ”¶çº¿ï¼ˆå¦‚ Balmer ç³»åˆ—ã€é‡‘å±çº¿ç­‰ï¼‰ï¼Œå‡ ä¹æ²¡æœ‰æ˜æ˜¾çº¢ç§»ã€‚
- **Galaxyï¼ˆæ˜Ÿç³»ï¼‰**ï¼šæœ‰ä¸€å®šçº¢ç§»ï¼Œå¸¸è§å‘å°„çº¿æˆ–å¸æ”¶çº¿ï¼ˆå¦‚ [O II], HÎ², [O III], HÎ±ï¼‰ï¼Œè°±çº¿è¾ƒçª„ï¼Œè¿ç»­è°±ç›¸å¯¹è¾ƒå¼±ã€‚
- **QSOï¼ˆç±»æ˜Ÿä½“/ç±»æ˜Ÿä½“å€™é€‰ï¼‰**ï¼šå¼ºçƒˆçš„å®½å‘å°„çº¿è¦†ç›–å¯è§/ç´«å¤–æ³¢æ®µï¼Œè°±çº¿å®½åº¦æ˜¾è‘—å¤§äºæ™®é€šæ˜Ÿç³»ï¼Œé€šå¸¸æœ‰æ˜æ˜¾çº¢ç§»ã€‚

å‰ä¸€ä½å¤©æ–‡å­¦åŠ©æ‰‹å·²ç»å®šæ€§åœ°æè¿°äº†å…‰è°±çš„æ•´ä½“å½¢æ€ï¼š

{visual_interpretation_json}

è¯·æ ¹æ®ä»–çš„æè¿°è¿›è¡Œåˆ¤æ–­ï¼ŒçŒœæµ‹è¯¥å…‰è°±å¯èƒ½å±äºå“ªä¸€ç±»æˆ–å‡ ç±»ï¼Œç»™å‡ºç½®ä¿¡åº¦ã€‚

ä½ çš„å›ç­”æ ¼å¼è¯·ä¸¥æ ¼éµå¾ªï¼š

çŒœæµ‹ 1ï¼š
- **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
- **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿ç»­è°±å½¢æ€ï¼‰
- **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½
çŒœæµ‹ 2ï¼š
- **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
- **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿ç»­è°±å½¢æ€ï¼‰
- **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½
ç­‰ç­‰ã€‚

âš ï¸ **æ³¨æ„ï¼š**
- åªè¾“å‡ºä¸­ç­‰ç½®ä¿¡åº¦ä»¥ä¸Šçš„å›ç­”
- ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼
- ä¸å°è¯•è®¡ç®—çº¢ç§»
- é‡ç‚¹åœ¨è§†è§‰ä¸å½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­
- ä¸è¦è°ƒç”¨å·¥å…·ï¼›
"""
        response = await self.call_llm_with_context(
            prompt,
            image_path=state['image_path'],
            parse_json=False,
            description="åˆæ­¥åˆ†ç±»"
        )
        state['preliminary_classification'] = response
        
    def _common_prompt_header_QSO(self, state, include_rule_analysis=True):
        """æ„é€ æ¯ä¸ª step å…¬å…±çš„ prompt å‰æ®µ"""
        visual_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
        peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)
        trough_json = json.dumps(state['troughs'], ensure_ascii=False)

        header = f"""
ä½ æ˜¯ä¸€ä½å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚

ä»¥ä¸‹ä¿¡æ¯å¯èƒ½æ¥è‡ªäºä¸€ä¸ªæœªçŸ¥çº¢ç§»çš„ QSO å…‰è°±ã€‚

ä¹‹å‰çš„åŠ©æ‰‹å·²ç»å¯¹è¿™ä¸ªå…‰è°±è¿›è¡Œäº†åˆæ­¥æè¿°ï¼š
{visual_json}
"""

        if include_rule_analysis and state['rule_analysis']:
            rule_json = json.dumps("\n".join(str(item) for item in state['rule_analysis']), ensure_ascii=False)
            header += f"\nä¹‹å‰çš„åŠ©æ‰‹å·²ç»åœ¨å‡è®¾å…‰è°±ä¸­å­˜åœ¨ lyÎ± è°±çº¿çš„æƒ…å†µä¸‹è¿›è¡Œäº†åˆæ­¥åˆ†æ:\n{rule_json}\n"

        header += f"""
ç»¼åˆåŸæ›²çº¿å’Œ sigma={state['sigma_list']} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}
"""
        return header

    def _common_prompt_tail(self, step_title, extra_notes=""):
        """æ„é€ æ¯ä¸ª step å…¬å…±å°¾éƒ¨ï¼Œä¿ç•™ step ç‰¹æœ‰è¾“å‡º/åˆ†ææŒ‡ç¤º"""
        tail = f"""
---

è¾“å‡ºæ ¼å¼ä¸ºï¼š
{step_title}
...

---

ğŸ§­ æ³¨æ„ï¼š
- è®¡ç®—å¾—æ¥çš„éåŸå§‹æ•°æ®ï¼Œè¾“å‡ºæ—¶ä¿ç•™ 3 ä½å°æ•°ã€‚
- ä¸éœ€è¦è¿›è¡Œé‡å¤æ€»ç»“ã€‚
- ä¸éœ€è¦é€è¡Œåœ°é‡å¤è¾“å…¥æ•°æ®ï¼›
- é‡ç‚¹åœ¨ç‰©ç†æ¨ç†ä¸åˆç†è§£é‡Šï¼›
- è¯·ä¿è¯æœ€ç»ˆè¾“å‡ºå®Œæ•´ï¼Œä¸è¦ä¸­é€”æˆªæ–­ã€‚
"""
        if extra_notes:
            tail = extra_notes + "\n" + tail
        return tail
    
    async def step_1(self, state):
        header = self._common_prompt_header_QSO(state, include_rule_analysis=False)
        tail = self._common_prompt_tail("Step 1: LyÎ± åˆ†æ")

        prompt = header + """
è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æ:

Step 1: LyÎ± è°±çº¿æ£€æµ‹
å‡è®¾è¯¥å…‰è°±ä¸­å­˜åœ¨ LyÎ± å‘å°„çº¿ï¼ˆÎ»_rest = 1216 Ã…ï¼‰ï¼š
1. æ‰¾å‡ºæœ€å¯èƒ½å¯¹åº” LyÎ± çš„è§‚æµ‹å‘å°„çº¿ï¼ˆä»æä¾›çš„å³°åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰ã€‚
2. è¾“å‡ºï¼š
   - Î»_obs (è§‚æµ‹æ³¢é•¿)
   - å…‰å¼ºï¼ˆå¯å–ç›¸å¯¹å¼ºåº¦æˆ–å®šæ€§æè¿°ï¼‰
   - çº¿å®½ï¼ˆFWHM æˆ–åƒç´ å®½åº¦è¿‘ä¼¼ï¼‰
3. ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—åŸºäºè¯¥å‘å°„çº¿çš„çº¢ç§» zã€‚
4. æ£€æŸ¥è“ç«¯ï¼ˆçŸ­æ³¢é•¿æ–¹å‘ï¼‰æ˜¯å¦å­˜åœ¨ LyÎ± forest ç‰¹å¾ï¼š  
   è‹¥å¸æ”¶çº¿ç›¸å¯¹æ›´å¯†é›†ã€è¾ƒçª„ä¸”åˆ†å¸ƒåœ¨ LyÎ± è“ç«¯é™„è¿‘ï¼Œè¯·æŒ‡å‡ºå¹¶ç»™å‡ºç®€çŸ­è¯´æ˜ã€‚
""" + tail
        
        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 1 LyÎ± åˆ†æ")
        state['rule_analysis'].append(response)

    async def step_2(self, state):
        header = self._common_prompt_header_QSO(state)
        tail = self._common_prompt_tail("Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æ")

        prompt = header + """
è¯·ç»§ç»­åˆ†æ:

Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æ
1. ä»¥ Step 1 å¾—åˆ°çš„çº¢ç§»ä¸ºæ ‡å‡†ï¼Œä½¿ç”¨å·¥å…· predict_obs_wavelength æ£€æŸ¥å…‰è°±ä¸­æ˜¯å¦å¯èƒ½å­˜åœ¨å…¶ä»–æ˜¾è‘—å‘å°„çº¿ï¼ˆå¦‚ C IV 1549, C III] 1909, Mg II 2799, HÎ², HÎ± ç­‰ï¼‰ã€‚ä¸è¦è‡ªè¡Œè®¡ç®—ã€‚
2. è¿˜æœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„å‘å°„çº¿ï¼Ÿ
""" + tail

        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 2 å‘å°„çº¿åˆ†æ")
        state['rule_analysis'].append(response)

    async def step_3(self, state):
        header = self._common_prompt_header_QSO(state)
        tail = self._common_prompt_tail("Step 3: ç»¼åˆåˆ¤æ–­")

        prompt = header + """
è¯·ç»§ç»­åˆ†æ:

Step 3: ç»¼åˆåˆ¤æ–­
- åœ¨ Step 1 åˆ° Step 2 ä¸­ï¼Œå¦‚æœ LyÎ± çš„å­˜åœ¨è¯æ®ä¸è¶³ï¼ˆä¾‹å¦‚å¯¹åº”æ³¢é•¿æ²¡æœ‰æ˜æ˜¾å³°å€¼æˆ–çº¢ç§»ä¸å…¶ä»–è°±çº¿ä¸ä¸€è‡´ï¼‰ï¼Œè¯·**ä¼˜å…ˆå‡è®¾ LyÎ± ä¸å­˜åœ¨**ï¼Œå¹¶ç»“æŸåˆ†æã€‚  
- ä»…åœ¨ LyÎ± çš„å­˜åœ¨æœ‰å……åˆ†è¯æ®ï¼ˆæ˜¾è‘—å³°å€¼ + çº¢ç§»ä¸å…¶ä»–è°±çº¿ä¸€è‡´ï¼‰æ—¶ï¼Œæ‰å°† LyÎ± çº³å…¥ç»¼åˆçº¢ç§»è®¡ç®—ã€‚
- å¦‚æœ Step 1 å’Œ Step 2 çš„çº¢ç§»è®¡ç®—ç»“æœä¸€è‡´ï¼Œè¯·ç»¼åˆ Step 1 åˆ° Step 2 çš„åˆ†æï¼Œä½¿ç”¨ Step 1 å’Œ Step 2 å¾—åˆ°çš„è°±çº¿åŒ¹é…ï¼Œç»™å‡ºï¼š
    - å„ä¸ªè°±çº¿çš„çº¢ç§»
    - ç”±å„è°±çº¿åœ¨å…±æœ‰çš„æœ€å°æ•°å€¼çš„ sigma å¹³æ»‘ä¸‹çš„å¼ºåº¦ flux ä½œä¸ºæƒé‡ï¼Œä½¿ç”¨å·¥å…· weighted_average è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œè¾“å‡ºå¾—åˆ°çš„åŠ æƒçº¢ç§»å€¼ z Â± Î”z
    - æ¶‰åŠè®¡ç®—çº¢ç§»çš„æµç¨‹å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshiftï¼Œä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚
- ç»™å‡ºè¯¥çº¢ç§»ä¸‹ï¼Œä½ èƒ½ç¡®å®šçš„å„ä¸ªå‘å°„çº¿çš„æ³¢é•¿å’Œå‘å°„çº¿åã€‚
""" + tail

        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 3 ç»¼åˆåˆ¤æ–­")
        state['rule_analysis'].append(response)

    async def step_4(self, state):
        header = self._common_prompt_header_QSO(state)
        tail = self._common_prompt_tail("Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾æœ€é«˜å‘å°„çº¿ä¸æ˜¯ lyÎ± æ—¶çš„ä¸»è¦è°±çº¿æ¨æµ‹ï¼‰")

        prompt = header + """
è¯·ç»§ç»­åˆ†æ:

Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾æœ€é«˜å‘å°„çº¿ä¸æ˜¯ lyÎ± æ—¶çš„ä¸»è¦è°±çº¿æ¨æµ‹ï¼‰
- æ ¹æ® QSO çš„å…¸å‹è°±çº¿ç‰¹å¾ï¼Œæ‰¾å‡ºå…‰è°±ä¸­**å¼ºåº¦æœ€é«˜çš„å³°å€¼**ã€‚
- çŒœæµ‹è¯¥å³°å€¼å¯èƒ½å¯¹åº”çš„è°±çº¿ï¼ˆä¾‹å¦‚ C IV, C III], Mg II, HÎ², HÎ± ç­‰ï¼‰ã€‚
- ä»¿ç…§ Step1-3 çš„é€»è¾‘è¿›è¡Œåˆ¤æ–­ã€‚æ¶‰åŠçº¢ç§»è®¡ç®—çš„è¯·ä½¿ç”¨å·¥å…· calculate_redshiftï¼›æ¶‰åŠè§‚æµ‹çº¿æ³¢é•¿è®¡ç®—çš„è¯·ä½¿ç”¨å·¥å…· predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚
    - è¾“å‡ºè¯¥å³°å¯¹åº”è°±çº¿çš„ä¿¡æ¯ï¼š
        - è°±çº¿å
        - Î»_obs
        - å…‰å¼º
        - è°±çº¿å®½åº¦
        - æ ¹æ® Î»_rest åˆæ­¥è®¡ç®—çº¢ç§» zã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚
    - å¦‚æœå¯èƒ½ï¼Œæ¨æµ‹å…¶ä»–å¯è§å‘å°„çº¿ï¼Œå¹¶è®¡ç®—çº¢ç§»
    - ç»¼åˆæ‰€æœ‰è°±çº¿ï¼Œç»™å‡ºæœ€å¯èƒ½çš„çº¢ç§»å’Œçº¢ç§»èŒƒå›´
- ä»¥ä¸Šåˆ¤æ–­æ˜¯å¦æ”¯æŒæœ€é«˜å‘å°„çº¿ä¸æ˜¯ lyÎ± çš„å‡è®¾ï¼Ÿ
""" + tail

        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 4 è¡¥å……åˆ†æ")
        state['rule_analysis'].append(response)

#     # --------------------------
#     # Run å…¨æµç¨‹
#     # --------------------------
    async def run(self, state: SpectroState):
        """æ‰§è¡Œè§„åˆ™åˆ†æå®Œæ•´æµç¨‹"""
        try:
            await self.describe_spectrum_picture(state)
            await self.preliminary_classification(state)
            await self.step_1(state)
            await self.step_2(state)
            await self.step_3(state)
            await self.step_4(state)
            return state
        except Exception as e:
            import traceback
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Full traceback:")
            traceback.print_exc()
            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸
            raise  # å¦‚æœä½ å¸Œæœ›è°ƒç”¨è€…ä¹Ÿèƒ½æ•è·è¯¥å¼‚å¸¸
        



# # ---------------------------------------------------------
# # 3. Revision Supervisor â€” è´Ÿè´£äº¤å‰å®¡æ ¸ä¸è¯„ä¼°
# # ---------------------------------------------------------
class SpectralAnalysisAuditor(BaseAgent):
    """å®¡æŸ¥åˆ†æå¸ˆï¼šå®¡æŸ¥å¹¶æ ¡æ­£å…¶ä»–åˆ†æ agent çš„è¾“å‡º"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Analysis Auditor',
            mcp_manager=mcp_manager
        )

    def _common_prompt_header_QSO(self, state: SpectroState) -> str:
        peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)
        trough_json = json.dumps(state['troughs'], ensure_ascii=False)
        rule_analysis = "\n\n".join(str(item) for item in state['rule_analysis'])
        return f"""
ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„ã€å¤©æ–‡å­¦å…‰è°±æŠ¥å‘Šå®¡æŸ¥åˆ†æå¸ˆã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- å®¡æ ¸å…¶ä»–åˆ†æå¸ˆçš„å…‰è°±åˆ†ææŠ¥å‘Šæˆ–æƒ³æ³•
- è¯†åˆ«å…¶ä¸­çš„é€»è¾‘æ¼æ´ã€è®¡ç®—æ¼æ´ã€ä¸ä¸€è‡´æˆ–é”™è¯¯æ¨æ–­
- æå‡ºä¿®æ­£æ„è§æˆ–è¡¥å……åˆ†ææ–¹å‘

å·¥ä½œåŸåˆ™ï¼š
- ä¿æŒå®¢è§‚ä¸æ‰¹åˆ¤æ€§æ€ç»´
- ä¸é‡å¤åŸåˆ†æï¼ŒåªæŒ‡å‡ºé—®é¢˜ä¸æ”¹è¿›å»ºè®®
- è‹¥åŸæŠ¥å‘Šåˆç†ï¼Œåº”æ˜ç¡®ç¡®è®¤å…¶æœ‰æ•ˆæ€§
- æ¶‰åŠçº¢ç§»å’Œå…‰è°±è§‚æµ‹æ³¢é•¿çš„è®¡ç®—å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshift å’Œ  predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- è¯·è¾“å‡ºè¯´æ˜æ€§çš„è¯­è¨€
- ç®€æ˜åˆ—å‡ºå®¡æŸ¥æ„è§ï¼ˆä¾‹å¦‚ï¼šâ€œç»“è®ºåæ—©â€ï¼Œâ€œè°±çº¿è§£é‡Šæ­£ç¡®â€ï¼‰
- å¯¹æ¯ä¸ªå‘ç°é™„ä¸Šæ”¹è¿›å»ºè®®
- æœ€åç»™å‡ºæ•´ä½“è¯„ä»·ï¼ˆå¯é /éƒ¨åˆ†å¯ä¿¡/ä¸å¯ä¿¡ï¼‰

å·²çŸ¥ï¼šç»¼åˆåŸæ›²çº¿å’Œ sigma=2ã€sigma=4ã€sigma=16 ä¸‰æ¡é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}

å…¶ä»–åˆ†æå¸ˆç»™å‡ºçš„å…‰è°±åˆ†ææŠ¥å‘Šä¸ºï¼š

{rule_analysis}

è¯¥æŠ¥å‘Šåœ¨çº¢ç§»è®¡ç®—æ—¶ä¿ç•™äº† 3 ä½å°æ•°ã€‚
"""

    async def auditing(self, state: SpectroState):
        header = self._common_prompt_header_QSO(state)

        if state['count'] == 0:
            body = f"""
è¯·å¯¹è¿™ä»½åˆ†ææŠ¥å‘Šè¿›è¡Œæ£€æŸ¥ã€‚
"""
        elif state['count']:     
            auditing_history = state['auditing_history'][-1]
            auditing_history_json = json.dumps(auditing_history, ensure_ascii=False)
            response_history = state['refine_history'][-1]
            response_history_json = json.dumps(response_history, ensure_ascii=False)

            body = f"""
ä½ å¯¹è¿™ä»½åˆ†ææŠ¥å‘Šçš„æœ€æ–°è´¨ç–‘ä¸º
{auditing_history_json}

å…¶ä»–åˆ†æå¸ˆçš„å›ç­”ä¸º
{response_history_json}

è¯·å›åº”å…¶ä»–åˆ†æå¸ˆçš„å›ç­”ï¼Œå¹¶ç»§ç»­è¿›è¡Œå®¡æŸ¥ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context(prompt, parse_json=False, description="æŠ¥å‘Šå®¡æŸ¥")
        state['auditing_history'].append(response)

    async def run(self, state: SpectroState) -> SpectroState:
        await self.auditing(state)
        return state



# # ---------------------------------------------------------
# # 4. Reflective Analyst â€” è‡ªç”±å›åº”å®¡æŸ¥å¹¶æ”¹è¿›
# # ---------------------------------------------------------
class SpectralRefinementAssistant(BaseAgent):
    """æ”¹è¿›è€…ï¼šå›åº”å®¡æŸ¥å¹¶æ”¹è¿›åˆ†æ"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Refinement Assistant',
            mcp_manager=mcp_manager
        )

    def _common_prompt_header_QSO(self, state) -> str:
        peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)
        trough_json = json.dumps(state['troughs'], ensure_ascii=False)
        rule_analysis = "\n\n".join(str(item) for item in state['rule_analysis'])
        return f"""
ä½ æ˜¯ä¸€ä½å…·å¤‡åæ€èƒ½åŠ›çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æå¸ˆã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- é˜…è¯»å¹¶ç†è§£ä»–äººçš„å…‰è°±åˆ†ææŠ¥å‘Š
- é˜…è¯»å¹¶ç†è§£å®¡æŸ¥å®˜æå‡ºçš„åé¦ˆ
- å¯¹è‡ªèº«æˆ–ä»–äººå…ˆå‰çš„åˆ†æè¿›è¡Œæ”¹è¿›
- æå‡ºæ–°çš„è§£é‡Šæˆ–ä¿®æ­£ç»“è®º

å·¥ä½œåŸåˆ™ï¼š
- è®¤çœŸå›åº”æ¯æ¡åé¦ˆï¼Œé€ä¸€è¯´æ˜æ”¹è¿›ä¹‹å¤„
- å¦‚æœè®¤ä¸ºåŸç»“è®ºæ­£ç¡®ï¼Œéœ€ç»™å‡ºå……åˆ†ç†ç”±
- æœ€ç»ˆè¾“å‡ºä¸€ä¸ªæ›´ä¸¥è°¨ã€å®Œå–„çš„åˆ†æç‰ˆæœ¬
- æ¶‰åŠçº¢ç§»å’Œå…‰è°±è§‚æµ‹æ³¢é•¿çš„è®¡ç®—å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshift å’Œ  predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- è¯·è¾“å‡ºè¯´æ˜æ€§çš„è¯­è¨€
- åˆ—å‡ºæ”¶åˆ°çš„åé¦ˆåŠå¯¹åº”å›åº”
- æä¾›æ”¹è¿›åçš„å…‰è°±åˆ†ææ€»ç»“
- è¯´æ˜ä¿®æ”¹å†…å®¹åŠå…¶ç§‘å­¦åˆç†æ€§

å·²çŸ¥ï¼šç»¼åˆåŸæ›²çº¿å’Œ sigma=2ã€sigma=4ã€sigma=16 ä¸‰æ¡é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}
å…¶ä»–åˆ†æå¸ˆç»™å‡ºçš„å…‰è°±åˆ†ææŠ¥å‘Šä¸ºï¼š
{rule_analysis}

è¿™ä»½æŠ¥å‘Šåœ¨çº¢ç§»è®¡ç®—æ—¶ä¿ç•™äº† 3 ä½å°æ•°ã€‚
"""

    async def refine(self, state: SpectroState):
        header = self._common_prompt_header_QSO(state)
        auditing = state['auditing_history'][-1]
        auditing_json = json.dumps(auditing, ensure_ascii=False)
        body = f"""
è´Ÿè´£æ ¸éªŒæŠ¥å‘Šçš„å®¡æŸ¥åˆ†æå¸ˆç»™å‡ºçš„æœ€æ–°å»ºè®®ä¸º
{auditing_json}

è¯·å¯¹å»ºè®®è¿›è¡Œå›åº”ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context(prompt, parse_json=False, description="å›åº”å®¡æŸ¥")
        state['refine_history'].append(response)

    async def run(self, state: SpectroState) -> SpectroState:
        try:
            await self.refine(state)
            return state
        except Exception as e:
            import traceback
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Full traceback:")
            traceback.print_exc()
            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸
            raise  # å¦‚æœä½ å¸Œæœ›è°ƒç”¨è€…ä¹Ÿèƒ½æ•è·è¯¥å¼‚å¸¸


# ---------------------------------------------------------
# ğŸ§© 5. Host Integrator â€” æ±‡æ€»ä¸æ€»ç»“å¤šæ–¹è§‚ç‚¹
# ---------------------------------------------------------
class SpectralSynthesisHost(BaseAgent):
    """æ±‡æ€»ä¸»æŒäººï¼šæ•´åˆå¤šAgentçš„åˆ†æä¸ç»“è®º"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Synthesis Host',
            mcp_manager=mcp_manager
        )

    def get_system_prompt(self) -> str:
        return f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- æ±‡æ€»è§†è§‰åˆ†æå¸ˆã€è§„åˆ™åˆ†æå¸ˆã€å®¡æŸ¥å®˜å’Œå†åˆ†æå¸ˆçš„æ‰€æœ‰è¾“å‡º
- ç»¼åˆä¸åŒè§’åº¦çš„ç»“è®ºï¼Œå½¢æˆæœ€ç»ˆçš„å…‰è°±è§£é‡Š
- æ¸…æ¥šæŒ‡å‡ºå„æ–¹æ„è§çš„å·®å¼‚ä¸ä¸€è‡´ç‚¹

å·¥ä½œåŸåˆ™ï¼š
- æ— éœ€è°ƒç”¨å·¥å…·
- ä¸ç›²ä»ä»»ä½•å•ä¸€åˆ†æ
- ä¿æŒæ•´ä½“ç§‘å­¦æ€§ä¸é€»è¾‘ä¸€è‡´æ€§
- æœ€ç»ˆè¾“å‡ºå¿…é¡»å…·å¤‡å¯è¿½æº¯æ€§ï¼ˆè¯´æ˜æ¥è‡ªå“ªäº›agentçš„ä¾æ®ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- è¾“å‡ºè¯´æ˜æ€§æ–‡å­—
- è¾“å‡ºæ•°æ®ä¿ç•™ 3 ä½å°æ•°
- åªéœ€è¾“å‡ºåˆ†æå†…å®¹ï¼Œæ— éœ€å£°æ˜å„æ®µåˆ†ææ–‡å­—çš„æ¥æº
- ç»™å‡ºæœ€ç»ˆç»¼åˆç»“è®ºåŠå¯ä¿¡åº¦è¯„çº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
- å¦‚æœä»å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
- æŒ‰æ ¼å¼è¾“å‡ºã€‚ä¸è¦è¾“å‡ºå¤šä½™å†…å®¹
"""


    async def summary(self, state):
        try:
            preliminary_classification_json = json.dumps(state['preliminary_classification'], ensure_ascii=False)
            visual_interpretation_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)
            rule_analysis = "\n\n".join(str(item) for item in state['rule_analysis'])
            rule_analysis_json = json.dumps(rule_analysis, ensure_ascii=False)
            auditing = "\n\n".join(str(item) for item in state['auditing_history'])
            auditing_json = json.dumps(auditing, ensure_ascii=False)
            refine = "\n\n".join(str(item) for item in state['refine_history'])
            refine_json = json.dumps(refine, ensure_ascii=False)
        except Exception as e:
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            raise

        header = self.get_system_prompt()

        prompt = f"""

å¯¹å…‰è°±çš„è§†è§‰æè¿°
{visual_interpretation_json}

å…‰è°±çš„åˆæ­¥åˆ†ç±»
{preliminary_classification_json}

è§„åˆ™åˆ†æå¸ˆçš„è§‚ç‚¹ï¼š
{rule_analysis_json}

å®¡æŸ¥åˆ†æå¸ˆçš„è§‚ç‚¹ï¼š
{auditing_json}

å®Œå–„åˆ†æå¸ˆçš„è§‚ç‚¹ï¼š
{refine_json}

è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š

- å…‰è°±çš„è§†è§‰ç‰¹ç‚¹
- åˆ†ææŠ¥å‘Šï¼ˆç»¼åˆè§„åˆ™åˆ†æå¸ˆã€å®¡æŸ¥åˆ†æå¸ˆå’Œå®Œå–„åˆ†æå¸ˆçš„æ‰€æœ‰è§‚ç‚¹ï¼Œé€ä¸ª Step è¿›è¡Œç»“æ„åŒ–è¾“å‡ºï¼‰
    - Step 1
    - Step 2
    - Step 3
    - Step 4
- ç»“è®º
    - è¯¥å¤©ä½“çš„å¤©ä½“ç±»å‹å’Œçº¢ç§» z Â± Î”z
    - è®¤è¯å‡ºçš„è°±çº¿ï¼ˆè¾“å‡º è°±çº¿å-Î»_rest-Î»_obsï¼‰
    - å…‰è°±çš„ä¿¡å™ªæ¯”å¦‚ä½•
    - åˆ†ææŠ¥å‘Šçš„å¯ä¿¡åº¦è¯„åˆ†ï¼ˆå¦‚æœèƒ½è®¤è¯å‡º2æ¡ä»¥ä¸Šçš„è°±çº¿ï¼Œåˆ™å¯ä¿¡åº¦ä¸ºâ€œé«˜â€ï¼›èƒ½è®¤è¯å‡º1æ¡è°±çº¿ï¼Œå¯ä¿¡åº¦ä¸ºâ€œä¸­â€ï¼›å…¶ä»–æƒ…å†µä¸ºâ€œä½â€ï¼‰
    - æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥åˆ¤æ–­
"""
        prompt = header + prompt
        response = await self.call_llm_with_context(prompt, parse_json=False, description="æ€»ç»“")
        state['summary'] = response

    async def in_brief(self, state):
        summary_json = json.dumps(state['summary'], ensure_ascii=False)
        prompt_type = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

- è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **å¤©ä½“ç±»å‹**ï¼ˆä»è¿™ä¸‰ä¸ªè¯è¯­ä¸­é€‰æ‹©ï¼šstar, galaxy, QSOï¼‰

- è¾“å‡ºæ ¼å¼ä¸º str
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_type = await self.call_llm_with_context(prompt_type, parse_json=False, description="æ€»ç»“")
        state['in_brief']['type'] = response_type

        prompt_redshift = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **çº¢ç§» z**ï¼ˆä¸éœ€è¦è¾“å‡º Â± Î”zï¼‰

- è¾“å‡ºæ ¼å¼ä¸º float
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_redshift = await self.call_llm_with_context(prompt_redshift, parse_json=False, description="æ€»ç»“")
        state['in_brief']['redshift'] = response_redshift

        prompt_rms = f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æä¸»æŒäººã€‘

ä½ å·²ç»å¯¹ä¸€å¼ å¤©æ–‡å­¦å…‰è°±åšäº†æ€»ç»“
{summary_json}

è¯·è¾“å‡º **ç»“è®º** éƒ¨åˆ†ä¸­çš„ **çº¢ç§»è¯¯å·® Î”z**ï¼ˆä¸éœ€è¦è¾“å‡º zï¼‰

- è¾“å‡ºæ ¼å¼ä¸º float
- ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯
"""
        response_rms = await self.call_llm_with_context(prompt_rms, parse_json=False, description="æ€»ç»“")
        state['in_brief']['rms'] = response_rms
    
    async def run(self, state: SpectroState) -> SpectroState:
        try:
            await self.summary(state)
            await self.in_brief(state)
            return state
        except Exception as e:
            import traceback
            print("âŒ An error occurred during spectral analysis:")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            print("Full traceback:")
            traceback.print_exc()
            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸