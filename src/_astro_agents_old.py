import json
import os

from .context_manager import SpectroContext
from .base_agent import BaseAgent
from .mcp_manager import MCPManager

from .context_manager import SpectroContext
from .base_agent import BaseAgent
from .mcp_manager import MCPManager

from .utils import (
    _detect_axis_ticks, _detect_chart_border, _crop_img,
    _remap_to_cropped_canvas, _pixel_tickvalue_fitting,
    _process_and_extract_curve_points, _convert_to_spectrum,
    _find_features_multiscale, _plot_spectrum, _plot_features
)

# ---------------------------------------------------------
# 1. Visual Assistant â€” è´Ÿè´£å›¾åƒç†è§£ä¸Žåæ ‡é˜…è¯»
# ---------------------------------------------------------

class SpectralVisualInterpreter(BaseAgent):
    """
    SpectralVisualInterpreter
    ä»Žç§‘å­¦å…‰è°±å›¾ä¸­è‡ªåŠ¨æå–åæ ‡è½´åˆ»åº¦ã€è¾¹æ¡†ã€åƒç´ æ˜ å°„ç­‰ä¿¡æ¯
    """

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Visual Interpreter',
            mcp_manager=mcp_manager
        )

    # --------------------------
    # Step 1.1: æ£€æµ‹åæ ‡è½´åˆ»åº¦
    # --------------------------
    async def detect_axis_ticks(self, ctx: SpectroContext):
        """è°ƒç”¨è§†è§‰ LLM æ£€æµ‹åæ ‡è½´åˆ»åº¦ï¼Œå¦‚æžœæ— å›¾åƒæˆ–éžå…‰è°±å›¾æŠ¥é”™"""
        class NoImageError(Exception): pass
        class NotSpectralImageError(Exception): pass

        if not ctx.image_path or not os.path.exists(ctx.image_path):
            raise NoImageError("âŒ æœªè¾“å…¥å›¾åƒæˆ–å›¾åƒè·¯å¾„ä¸å­˜åœ¨")

        prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè§†è§‰åˆ†æžæ¨¡åž‹ï¼Œæ“…é•¿ä»Žç§‘å­¦å›¾è¡¨æå–åæ ‡è½´åˆ»åº¦ä¿¡æ¯ã€‚
å¦‚æžœè¾“å…¥ä¸­ä¸åŒ…å«å…‰è°±å›¾ï¼Œè¯·è¾“å‡º â€œéžå…‰è°±å›¾â€ã€‚
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema è¾“å‡ºï¼š
{
  "x_axis": {
    "label_and_Unit": "str",
    "tick_range": {"min": float, "max": float},
    "ticks": [float]
  },
  "y_axis": {
    "label_and_Unit": "str",
    "tick_range": {"min": float, "max": float},
    "ticks": [float]
  }
}
"""

        axis_info = await self.call_llm_with_context(
            prompt,
            image_path=ctx.image_path,
            parse_json=True,
            description="åæ ‡è½´ä¿¡æ¯"
        )

        if axis_info in ["æœªè¾“å…¥å›¾åƒ", "éžå…‰è°±å›¾"]:
            raise NotSpectralImageError(f"âŒ å›¾åƒä¸æ˜¯å…‰è°±å›¾ï¼ŒLLM è¾“å‡º: {axis_info}")

        ctx.set("axis_info", axis_info)

    # --------------------------
    # Step 1.2~1.3: åˆå¹¶è§†è§‰+OCRåˆ»åº¦
    # --------------------------
    async def combine_axis_mapping(self, ctx: SpectroContext):
        """ç»“åˆè§†è§‰ç»“æžœä¸Ž OCR ç»“æžœç”Ÿæˆåƒç´ -æ•°å€¼æ˜ å°„"""
        axis_info_json = json.dumps(ctx.axis_info, ensure_ascii=False)
        ocr_json = json.dumps(ctx.OCR_detected_ticks, ensure_ascii=False)

        prompt = f"""
ä½ æ˜¯ç§‘å­¦å›¾è¡¨é˜…è¯»åŠ©æ‰‹ã€‚
è¾“å…¥ä¸¤ç»„åˆ»åº¦ä¿¡æ¯ï¼š
1. è§†è§‰æ¨¡åž‹ï¼š{axis_info_json}
2. OCR/Opencvï¼š{ocr_json}

ä»»åŠ¡ï¼š
- åˆå¹¶ä¸¤ç»„ç»“æžœï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ»åº¦å€¼-åƒç´ æ˜ å°„
- x è½´ pixel å•è°ƒé€’å¢žï¼Œy è½´ pixel å•è°ƒé€’å‡
- ä¿®æ­£ OCR ä¸Žå•è°ƒæ€§å†²çªçš„ pixel
- ç¼ºå¤±åˆ»åº¦ç”¨ nullï¼Œbounding-box-scale_x/y ç¼ºå¤±ä¹Ÿä¸º null
- sigma_pixel = bounding-box-scale / 2ï¼Œç¼ºå¤±ä¸º null
- conf_llm: OCR é«˜å¯ä¿¡åº¦ 0.9ï¼Œæ’å€¼/ä¿®æ­£ 0.7ï¼Œç¼ºå¤±è§†è§‰é¢„æµ‹ 0.5

è¾“å‡ºï¼š
- ä¸¥æ ¼ JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
  "axis" ("x" æˆ– "y"), "value", "position_x", "position_y",
  "bounding-box-scale_x", "bounding-box-scale_y",
  "sigma_pixel", "conf_llm"
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–æ–‡å­—
"""
        tick_pixel_raw = await self.call_llm_with_context(
            prompt,
            image_path=ctx.image_path,
            parse_json=True,
            description="åˆ»åº¦-åƒç´ æ˜ å°„"
        )

        ctx.set("tick_pixel_raw", tick_pixel_raw)

    # --------------------------
    # Step 1.4: æ ¡éªŒä¸Žä¿®æ­£
    # --------------------------
    async def revise_axis_mapping(self, ctx: SpectroContext):
        """æ£€æŸ¥å¹¶ä¿®æ­£åˆ»åº¦å€¼ä¸Žåƒç´ ä½ç½®åŒ¹é…å…³ç³»"""
        axis_mapping_json = json.dumps(ctx.tick_pixel_raw, ensure_ascii=False)

        prompt = f"""
ä½ æ˜¯ç§‘å­¦å›¾è¡¨é˜…è¯»åŠ©æ‰‹ã€‚
æ£€æŸ¥ä»¥ä¸‹åˆ»åº¦å€¼ä¸Žåƒç´ æ˜ å°„ï¼š
{axis_mapping_json}

è§„åˆ™ï¼š
- y è½´: æ•°å€¼ä»Žå°åˆ°å¤§ pixel åº”ä¸¥æ ¼é€’å‡
- x è½´: æ•°å€¼ä»Žå°åˆ°å¤§ pixel åº”ä¸¥æ ¼é€’å¢ž
å…è®¸å­˜åœ¨ null
å¦‚æžœæœ‰é—®é¢˜ï¼Œè¯·ä¿®è®¢å¹¶è¾“å‡º JSONï¼›å¦åˆ™ç›´æŽ¥è¿”å›žåŽŸè¾“å…¥
ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—
"""

        tick_pixel_revised = await self.call_llm_with_context(
            prompt,
            image_path=ctx.image_path,
            parse_json=True,
            description="ä¿®æ­£åŽçš„åˆ»åº¦æ˜ å°„"
        )

        ctx.set("tick_pixel_raw", tick_pixel_revised)

    # --------------------------
    # è¯»å–çŽ¯å¢ƒå˜é‡
    # --------------------------
    def _load_feature_params(self):
        """å®‰å…¨è¯»å–å³°å€¼/è°·å€¼æ£€æµ‹å‚æ•°"""
        def parse_list(val, default):
            if not val or not val.strip():
                return default
            try:
                cleaned = val.strip().strip("[]")
                if not cleaned:
                    return default
                return [int(x.strip()) for x in cleaned.split(",")]
            except Exception:
                print(f"âš ï¸ SIGMA_LIST æ ¼å¼é”™è¯¯: {val}ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default}")
                return default

        def getenv_int(name, default):
            val = os.getenv(name)
            if val and val.strip():
                try: return int(val.strip())
                except Exception: print(f"âš ï¸ {name} æ ¼å¼é”™è¯¯: {val}ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default}")
            return default

        def getenv_float(name, default):
            val = os.getenv(name)
            if val and val.strip():
                try: return float(val.strip())
                except Exception: print(f"âš ï¸ {name} æ ¼å¼é”™è¯¯: {val}ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default}")
            return default

        sigma_list = parse_list(os.getenv("SIGMA_LIST"), [2, 4, 16])
        tol_pixels = getenv_int("TOL_PIXELS", 3)
        prom_peaks = getenv_float("PROM_THRESHOLD_PEAKS", 0.01)
        prom_troughs = getenv_float("PROM_THRESHOLD_TROUGHS", 0.01)
        weight_original = getenv_float("WEIGHT_ORIGINAL", 1.0)
        plot_peaks = getenv_int("PLOT_PEAKS_NUMBER", 10)
        plot_troughs = getenv_int("PLOT_TROUGHS_NUMBER", 15)

        return sigma_list, tol_pixels, prom_peaks, prom_troughs, weight_original, plot_peaks, plot_troughs

    # --------------------------
    # Step 1.1~1.11: ä¸»æµç¨‹
    # --------------------------
    async def run(self, ctx: SpectroContext, plot: bool = True):
        """æ‰§è¡Œå®Œæ•´è§†è§‰åˆ†æžæµç¨‹"""
        try:
            # Step 1.1: è§†è§‰ LLM æå–åæ ‡è½´
            await self.detect_axis_ticks(ctx)

            # Step 1.2: OCR æå–åˆ»åº¦
            ctx.set("OCR_detected_ticks", _detect_axis_ticks(ctx.image_path))

            # Step 1.3: åˆå¹¶
            await self.combine_axis_mapping(ctx)

            # Step 1.4: ä¿®æ­£
            await self.revise_axis_mapping(ctx)

            # Step 1.5: è¾¹æ¡†æ£€æµ‹ä¸Žè£å‰ª
            chart_border = _detect_chart_border(ctx.image_path)
            ctx.set("chart_border", chart_border)
            _crop_img(ctx.image_path, chart_border, ctx.crop_path)

            # Step 1.6: é‡æ˜ å°„åƒç´ 
            ctx.set("tick_pixel_remap", _remap_to_cropped_canvas(ctx.tick_pixel_raw, chart_border))

            # Step 1.7: æ‹Ÿåˆåƒç´ -æ•°å€¼
            ctx.set("pixel_to_value", _pixel_tickvalue_fitting(ctx.tick_pixel_remap))

            # Step 1.8: æå–æ›²çº¿ & ç°åº¦åŒ–
            curve_points, curve_gray_values = _process_and_extract_curve_points(ctx.crop_path)
            ctx.set("curve_points", curve_points)
            ctx.set("curve_gray_values", curve_gray_values)

            # Step 1.9: å…‰è°±è¿˜åŽŸ
            ctx.set("spectrum", _convert_to_spectrum(ctx.curve_points, ctx.curve_gray_values, ctx.pixel_to_value))

            # Step 1.10: æ£€æµ‹å³°å€¼/è°·å€¼
            sigma_list, tol_pixels, prom_peaks, prom_troughs, weight_original, plot_peaks, plot_troughs = self._load_feature_params()
            ctx.set('sigma_list', sigma_list)
            ctx.set("peaks", _find_features_multiscale(ctx, "peak", sigma_list, prom_peaks, tol_pixels, weight_original))
            ctx.set("troughs", _find_features_multiscale(ctx, "trough", sigma_list, prom_troughs, tol_pixels, weight_original))

            # Step 1.11: å¯é€‰ç»˜å›¾
            if plot:
                ctx.set("spectrum_fig", _plot_spectrum(ctx))
                ctx.set("features_fig", _plot_features(ctx, sigma_list, [plot_peaks, plot_troughs]))

        except Exception as e:
            print(f"âŒ run pipeline terminated with error: {e}")
            raise

# ---------------------------------------------------------
# 2. Rule-based Analyst â€” è´Ÿè´£åŸºäºŽè§„åˆ™çš„ç‰©ç†åˆ†æž
# ---------------------------------------------------------
class SpectralRuleAnalyst(BaseAgent):
    
    """è§„åˆ™é©±åŠ¨åž‹åˆ†æžå¸ˆï¼šåŸºäºŽç»™å®šçš„ç‰©ç†ä¸Žè°±çº¿çŸ¥è¯†è¿›è¡Œå®šæ€§åˆ†æž"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Rule Analyst',
            mcp_manager=mcp_manager
        )
    # def __init__(self, agents):
    #     self.main_agent = agents['main']
    #     self.vis_llm = agents['vis']

    
    async def describe_spectrum_picture(self, ctx: SpectroContext):
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æžåŠ©æ‰‹ã€‚

ä½ å°†çœ‹åˆ°ä¸€æ¡å¤©æ–‡å…‰è°±æ›²çº¿ï¼ˆæ¥è‡ªæœªçŸ¥çº¢ç§»çš„å¤©ä½“ï¼‰ã€‚

è¯·ç»“åˆå›¾åƒï¼Œ**å®šæ€§åœ°æè¿°å…‰è°±çš„æ•´ä½“å½¢æ€**ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºŽä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

---

### Step 1: è¿žç»­è°±å½¢æ€
- æ•´ä½“çš„é€šé‡åˆ†å¸ƒè¶‹åŠ¿ï¼ˆä¾‹å¦‚è“ç«¯å¢žå¼º / çº¢ç«¯å¢žå¼º / å¤§è‡´å¹³å¦ / å‘ˆæ‹±å½¢ç­‰ï¼‰ã€‚
- æ˜¯å¦å¯ä»¥çœ‹å‡ºå¹‚å¾‹åž‹è¿žç»­è°±ã€é»‘ä½“åž‹è°±æˆ–å¹³å¦è°±çš„ç‰¹å¾ã€‚
- è¿žç»­è°±ä¸­æ˜¯å¦å­˜åœ¨æ˜Žæ˜¾çš„æ–­è£‚æˆ–æŠ˜ç‚¹ï¼ˆä¾‹å¦‚å·´å°”æœ«æ–­è£‚ã€LyÎ± forest åŒºåŸŸç­‰ï¼‰ã€‚

### Step 2: ä¸»è¦å‘å°„ä¸Žå¸æ”¶ç‰¹å¾
- æ˜¯å¦å­˜åœ¨çªå‡ºçš„å‘å°„å³°æˆ–å¸æ”¶è°·ã€‚
- å‘å°„çº¿ï¼ˆæˆ–å¸æ”¶çº¿ï¼‰çš„å¤§è‡´æ•°é‡ä¸Žç›¸å¯¹å¼ºå¼±ã€‚
- è¿™äº›çº¿æ˜¯å®½çš„è¿˜æ˜¯çª„çš„ã€å¯¹ç§°çš„è¿˜æ˜¯ä¸å¯¹ç§°çš„ã€‚
- è¯·é¿å…ç»™å‡ºå…·ä½“æ•°å€¼ï¼ˆå¦‚ç²¾ç¡®æ³¢é•¿æˆ–é€šé‡ï¼‰ï¼Œåªéœ€è¯´æ˜Žå®ƒä»¬ç›¸å¯¹çš„ä½ç½®ä¸Žç‰¹å¾ã€‚

### Step 3: æ•´ä½“ç»“æž„ä¸Žå™ªå£°ç‰¹å¾
- å…‰è°±ä¿¡å™ªæ¯”çš„æ€»ä½“å°è±¡ï¼ˆé«˜ / ä¸­ / ä½Žï¼‰ã€‚
- æ˜¯å¦å­˜åœ¨å™ªå£°æ³¢åŠ¨ã€å¼‚å¸¸å°–å³°æˆ–æ•°æ®ç¼ºå£ã€‚
- å…‰è°±åœ¨é•¿æ³¢ç«¯æˆ–çŸ­æ³¢ç«¯çš„è´¨é‡å˜åŒ–æƒ…å†µã€‚

---

âš ï¸ **æ³¨æ„ï¼š**
- ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼
- ä¸å°è¯•è®¡ç®—çº¢ç§»
- é‡ç‚¹åœ¨è§†è§‰ä¸Žå½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­
- ä¸è¦è°ƒç”¨å·¥å…·ï¼›

æœ€åŽï¼Œè¯·ä»¥ç»“æž„åŒ–çš„æ–¹å¼è¾“å‡ºä½ çš„è§‚å¯Ÿç»“æžœï¼Œä¾‹å¦‚ä½¿ç”¨åˆ†èŠ‚æ ‡é¢˜ï¼š
-ï¼ˆè¿žç»­è°±ï¼‰
-ï¼ˆå‘å°„ä¸Žå¸æ”¶ï¼‰
-ï¼ˆå™ªå£°ä¸Žæ•°æ®è´¨é‡ï¼‰
"""
        
        response = await self.call_llm_with_context(
            prompt,
            image_path=ctx.image_path,
            parse_json=False,
            description="è§†è§‰å…‰è°±å®šæ€§æè¿°"
        )
        ctx.set('visual_interpretation', response)
    
    async def preliminary_classification(self, ctx: SpectroContext) -> str:
        """åˆæ­¥åˆ†ç±»ï¼šæ ¹æ®å…‰è°±å½¢æ€åˆæ­¥åˆ¤æ–­å¤©ä½“ç±»åž‹"""

        visual_interpretation_json = json.dumps(ctx.visual_interpretation, ensure_ascii=False)
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æžåŠ©æ‰‹ã€‚

ä½ å°†çœ‹åˆ°ä¸€æ¡å¤©æ–‡å…‰è°±æ›²çº¿ï¼ˆæ¥è‡ªæœªçŸ¥çº¢ç§»çš„å¤©ä½“ï¼‰ï¼Œå®ƒå¯èƒ½å±žäºŽä»¥ä¸‹ä¸‰ç±»ä¹‹ä¸€ï¼š
- **Starï¼ˆæ’æ˜Ÿï¼‰**ï¼šè¿žç»­è°±è¾ƒå¼ºï¼Œè°±çº¿é€šå¸¸æ˜¯å¸æ”¶çº¿ï¼ˆå¦‚ Balmer ç³»åˆ—ã€é‡‘å±žçº¿ç­‰ï¼‰ï¼Œå‡ ä¹Žæ²¡æœ‰æ˜Žæ˜¾çº¢ç§»ã€‚
- **Galaxyï¼ˆæ˜Ÿç³»ï¼‰**ï¼šæœ‰ä¸€å®šçº¢ç§»ï¼Œå¸¸è§å‘å°„çº¿æˆ–å¸æ”¶çº¿ï¼ˆå¦‚ [O II], HÎ², [O III], HÎ±ï¼‰ï¼Œè°±çº¿è¾ƒçª„ï¼Œè¿žç»­è°±ç›¸å¯¹è¾ƒå¼±ã€‚
- **QSOï¼ˆç±»æ˜Ÿä½“/ç±»æ˜Ÿä½“å€™é€‰ï¼‰**ï¼šå¼ºçƒˆçš„å®½å‘å°„çº¿è¦†ç›–å¯è§/ç´«å¤–æ³¢æ®µï¼Œè°±çº¿å®½åº¦æ˜¾è‘—å¤§äºŽæ™®é€šæ˜Ÿç³»ï¼Œé€šå¸¸æœ‰æ˜Žæ˜¾çº¢ç§»ã€‚

å‰ä¸€ä½å¤©æ–‡å­¦åŠ©æ‰‹å·²ç»å®šæ€§åœ°æè¿°äº†å…‰è°±çš„æ•´ä½“å½¢æ€ï¼š

{visual_interpretation_json}

è¯·æ ¹æ®ä»–çš„æè¿°è¿›è¡Œåˆ¤æ–­ï¼ŒçŒœæµ‹è¯¥å…‰è°±å¯èƒ½å±žäºŽå“ªä¸€ç±»æˆ–å‡ ç±»ï¼Œç»™å‡ºç½®ä¿¡åº¦ã€‚

ä½ çš„å›žç­”æ ¼å¼è¯·ä¸¥æ ¼éµå¾ªï¼š

çŒœæµ‹ 1ï¼š
- **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
- **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŽŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿žç»­è°±å½¢æ€ï¼‰
- **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½Ž
çŒœæµ‹ 2ï¼š
- **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰
- **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŽŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿žç»­è°±å½¢æ€ï¼‰
- **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½Ž
ç­‰ç­‰ã€‚

âš ï¸ **æ³¨æ„ï¼š**
- åªè¾“å‡ºä¸­ç­‰ç½®ä¿¡åº¦ä»¥ä¸Šçš„å›žç­”
- ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼
- ä¸å°è¯•è®¡ç®—çº¢ç§»
- é‡ç‚¹åœ¨è§†è§‰ä¸Žå½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­
- ä¸è¦è°ƒç”¨å·¥å…·ï¼›
"""
        response = await self.call_llm_with_context(
            prompt,
            image_path=ctx.image_path,
            parse_json=False,
            description="åˆæ­¥åˆ†ç±»"
        )
        ctx.set('preliminary_classification', response)
        
    def _common_prompt_header(self, ctx, include_rule_analysis=True):
        """æž„é€ æ¯ä¸ª step å…¬å…±çš„ prompt å‰æ®µ"""
        visual_json = json.dumps(ctx.visual_interpretation, ensure_ascii=False)
        peak_json = json.dumps(ctx.peaks[:10], ensure_ascii=False)
        trough_json = json.dumps(ctx.troughs, ensure_ascii=False)

        header = f"""
ä½ æ˜¯ä¸€ä½å¤©æ–‡å­¦å…‰è°±åˆ†æžåŠ©æ‰‹ã€‚

ä»¥ä¸‹ä¿¡æ¯å¯èƒ½æ¥è‡ªäºŽä¸€ä¸ªæœªçŸ¥çº¢ç§»çš„ QSO å…‰è°±ã€‚

ä¹‹å‰çš„åŠ©æ‰‹å·²ç»å¯¹è¿™ä¸ªå…‰è°±è¿›è¡Œäº†åˆæ­¥æè¿°ï¼š
{visual_json}
"""

        if include_rule_analysis and ctx.rule_analysis:
            rule_json = json.dumps("\n".join(str(item) for item in ctx.rule_analysis), ensure_ascii=False)
            header += f"\nä¹‹å‰çš„åŠ©æ‰‹å·²ç»åœ¨å‡è®¾å…‰è°±ä¸­å­˜åœ¨ lyÎ± è°±çº¿çš„æƒ…å†µä¸‹è¿›è¡Œäº†åˆæ­¥åˆ†æž:\n{rule_json}\n"

        header += f"""
ç»¼åˆåŽŸæ›²çº¿å’Œ sigma={ctx.sigma_list} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºŽå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}
"""
        return header

    def _common_prompt_tail(self, step_title, extra_notes=""):
        """æž„é€ æ¯ä¸ª step å…¬å…±å°¾éƒ¨ï¼Œä¿ç•™ step ç‰¹æœ‰è¾“å‡º/åˆ†æžæŒ‡ç¤º"""
        tail = f"""
---

è¾“å‡ºæ ¼å¼ä¸ºï¼š
{step_title}
...

---

ðŸ§­ æ³¨æ„ï¼š
- è®¡ç®—å¾—æ¥çš„éžåŽŸå§‹æ•°æ®ï¼Œæœ€ç»ˆä¿ç•™3ä½å°æ•°ã€‚
- ä¸éœ€è¦è¿›è¡Œé‡å¤æ€»ç»“ã€‚
- ä¸éœ€è¦é€è¡Œåœ°é‡å¤è¾“å…¥æ•°æ®ï¼›
- é‡ç‚¹åœ¨ç‰©ç†æŽ¨ç†ä¸Žåˆç†è§£é‡Šï¼›
- è¯·ä¿è¯æœ€ç»ˆè¾“å‡ºå®Œæ•´ï¼Œä¸è¦ä¸­é€”æˆªæ–­ã€‚
"""
        if extra_notes:
            tail = extra_notes + "\n" + tail
        return tail
    
    async def step_1(self, ctx):
        header = self._common_prompt_header(ctx, include_rule_analysis=False)
        tail = self._common_prompt_tail("Step 1: LyÎ± åˆ†æž")

        prompt = header + """
è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æž:

Step 1: LyÎ± è°±çº¿æ£€æµ‹
å‡è®¾è¯¥å…‰è°±ä¸­å­˜åœ¨ LyÎ± å‘å°„çº¿ï¼ˆÎ»_rest = 1216 Ã…ï¼‰ï¼š
1. æ‰¾å‡ºæœ€å¯èƒ½å¯¹åº” LyÎ± çš„è§‚æµ‹å‘å°„çº¿ï¼ˆä»Žæä¾›çš„å³°åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰ã€‚
2. è¾“å‡ºï¼š
   - Î»_obs (è§‚æµ‹æ³¢é•¿)
   - å…‰å¼ºï¼ˆå¯å–ç›¸å¯¹å¼ºåº¦æˆ–å®šæ€§æè¿°ï¼‰
   - çº¿å®½ï¼ˆFWHM æˆ–åƒç´ å®½åº¦è¿‘ä¼¼ï¼‰
3. ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—åŸºäºŽè¯¥å‘å°„çº¿çš„çº¢ç§» zã€‚
4. æ£€æŸ¥è“ç«¯ï¼ˆçŸ­æ³¢é•¿æ–¹å‘ï¼‰æ˜¯å¦å­˜åœ¨ LyÎ± forest ç‰¹å¾ï¼š  
   è‹¥å¸æ”¶çº¿ç›¸å¯¹æ›´å¯†é›†ã€è¾ƒçª„ä¸”åˆ†å¸ƒåœ¨ LyÎ± è“ç«¯é™„è¿‘ï¼Œè¯·æŒ‡å‡ºå¹¶ç»™å‡ºç®€çŸ­è¯´æ˜Žã€‚
""" + tail
        
        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 1 LyÎ±åˆ†æž")
        ctx.append('rule_analysis', response)

    async def step_2(self, ctx):
        header = self._common_prompt_header(ctx)
        tail = self._common_prompt_tail("Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æž")

        prompt = header + """
è¯·ç»§ç»­åˆ†æž:

Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æž
1. ä»¥ Step 1 å¾—åˆ°çš„çº¢ç§»ä¸ºæ ‡å‡†ï¼Œä½¿ç”¨å·¥å…· predict_obs_wavelength æ£€æŸ¥å…‰è°±ä¸­æ˜¯å¦å¯èƒ½å­˜åœ¨å…¶ä»–æ˜¾è‘—å‘å°„çº¿ï¼ˆå¦‚ C IV 1549, C III] 1909, Mg II 2799, HÎ², HÎ± ç­‰ï¼‰ã€‚ä¸è¦è‡ªè¡Œè®¡ç®—ã€‚
2. è¿˜æœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„å‘å°„çº¿ï¼Ÿ
""" + tail

        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 2 å‘å°„çº¿åˆ†æž")
        ctx.append('rule_analysis', response)

    async def step_3(self, ctx):
        header = self._common_prompt_header(ctx)
        tail = self._common_prompt_tail("Step 3: ç»¼åˆåˆ¤æ–­")

        prompt = header + """
è¯·ç»§ç»­åˆ†æž:

Step 3: ç»¼åˆåˆ¤æ–­
- åœ¨ Step 1 åˆ° Step 2 ä¸­ï¼Œå¦‚æžœ LyÎ± çš„å­˜åœ¨è¯æ®ä¸è¶³ï¼ˆä¾‹å¦‚å¯¹åº”æ³¢é•¿æ²¡æœ‰æ˜Žæ˜¾å³°å€¼æˆ–çº¢ç§»ä¸Žå…¶ä»–è°±çº¿ä¸ä¸€è‡´ï¼‰ï¼Œè¯·**ä¼˜å…ˆå‡è®¾ LyÎ± ä¸å­˜åœ¨**ï¼Œå¹¶ç»“æŸåˆ†æžã€‚  
- ä»…åœ¨ LyÎ± çš„å­˜åœ¨æœ‰å……åˆ†è¯æ®ï¼ˆæ˜¾è‘—å³°å€¼ + çº¢ç§»ä¸Žå…¶ä»–è°±çº¿ä¸€è‡´ï¼‰æ—¶ï¼Œæ‰å°† LyÎ± çº³å…¥ç»¼åˆçº¢ç§»è®¡ç®—ã€‚
- å¦‚æžœ Step 1 å’Œ Step 2 çš„çº¢ç§»è®¡ç®—ç»“æžœä¸€è‡´ï¼Œè¯·ç»¼åˆ Step 1 åˆ° Step 2 çš„åˆ†æžï¼Œä½¿ç”¨ Step 1 å’Œ Step 2 å¾—åˆ°çš„è°±çº¿åŒ¹é…ï¼Œç»™å‡ºï¼š
    - å„ä¸ªè°±çº¿çš„çº¢ç§»
    - ç”±å„è°±çº¿åœ¨ sigma=2 å¹³æ»‘ä¸‹çš„å¼ºåº¦ flux ä½œä¸ºæƒé‡ï¼Œä½¿ç”¨å·¥å…· weighted_average è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œè¾“å‡ºå¾—åˆ°çš„åŠ æƒçº¢ç§»å€¼ z Â± Î”z
    - æ¶‰åŠè®¡ç®—çº¢ç§»çš„æµç¨‹å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshiftï¼Œä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚
- ç»™å‡ºè¯¥çº¢ç§»ä¸‹ï¼Œä½ èƒ½ç¡®å®šçš„å„ä¸ªå‘å°„çº¿çš„æ³¢é•¿å’Œå‘å°„çº¿åã€‚
""" + tail

        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 3 ç»¼åˆåˆ¤æ–­")
        ctx.append('rule_analysis', response)

    async def step_4(self, ctx):
        header = self._common_prompt_header(ctx)
        tail = self._common_prompt_tail("Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ lyÎ± ä¸å­˜åœ¨æ—¶çš„ä¸»è¦è°±çº¿æŽ¨æµ‹ï¼‰")

        prompt = header + """
è¯·ç»§ç»­åˆ†æž:

Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾æœ€é«˜å‘å°„çº¿ä¸æ˜¯ lyÎ± æ—¶çš„ä¸»è¦è°±çº¿æŽ¨æµ‹ï¼‰
- æ ¹æ® QSO çš„å…¸åž‹è°±çº¿ç‰¹å¾ï¼Œæ‰¾å‡ºå…‰è°±ä¸­**å¼ºåº¦æœ€é«˜çš„å³°å€¼**ã€‚
- çŒœæµ‹è¯¥å³°å€¼å¯èƒ½å¯¹åº”çš„è°±çº¿ï¼ˆä¾‹å¦‚ C IV, C III], Mg II, HÎ², HÎ± ç­‰ï¼‰ã€‚
- ä»¿ç…§ Step1-3 çš„é€»è¾‘è¿›è¡Œåˆ¤æ–­ã€‚æ¶‰åŠçº¢ç§»è®¡ç®—çš„è¯·ä½¿ç”¨å·¥å…· calculate_redshiftï¼›æ¶‰åŠè§‚æµ‹çº¿æ³¢é•¿è®¡ç®—çš„è¯·ä½¿ç”¨å·¥å…· predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚
    - è¾“å‡ºè¯¥å³°å¯¹åº”è°±çº¿çš„ä¿¡æ¯ï¼š
        - è°±çº¿å
        - Î»_obs
        - å…‰å¼º
        - è°±çº¿å®½åº¦
        - æ ¹æ® Î»_rest åˆæ­¥è®¡ç®—çº¢ç§» zã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚
    - å¦‚æžœå¯èƒ½ï¼ŒæŽ¨æµ‹å…¶ä»–å¯è§å‘å°„çº¿ï¼Œå¹¶è®¡ç®—çº¢ç§»
    - ç»¼åˆæ‰€æœ‰è°±çº¿ï¼Œç»™å‡ºæœ€å¯èƒ½çš„çº¢ç§»å’Œçº¢ç§»èŒƒå›´
- ä»¥ä¸Šåˆ¤æ–­æ˜¯å¦æ”¯æŒ lyÎ± ä¸å­˜åœ¨çš„å‡è®¾ï¼Ÿ
""" + tail

        response = await self.call_llm_with_context(prompt, parse_json=False, description="Step 4 è¡¥å……åˆ†æž")
        ctx.append('rule_analysis', response)

    # --------------------------
    # Run å…¨æµç¨‹
    # --------------------------
    async def run(self, ctx: SpectroContext):
        """æ‰§è¡Œè§„åˆ™åˆ†æžå®Œæ•´æµç¨‹"""
        await self.describe_spectrum_picture(ctx)
        await self.preliminary_classification(ctx)
        await self.step_1(ctx)
        await self.step_2(ctx)
        await self.step_3(ctx)
        await self.step_4(ctx)



# ---------------------------------------------------------
# 3. Revision Supervisor â€” è´Ÿè´£äº¤å‰å®¡æ ¸ä¸Žè¯„ä¼°
# ---------------------------------------------------------
class SpectralAnalysisAuditor(BaseAgent):
    """ç»“æžœç›‘ç£è€…ï¼šå®¡æŸ¥å¹¶æ ¡æ­£å…¶ä»–åˆ†æž agent çš„è¾“å‡º"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Analysis Auditor',
            mcp_manager=mcp_manager
        )

    def _common_prompt_header(self, ctx) -> str:
        peak_json = json.dumps(ctx.peaks[:10], ensure_ascii=False)
        trough_json = json.dumps(ctx.troughs, ensure_ascii=False)
        rule_analysis = "\n\n".join(str(item) for item in ctx.rule_analysis)
        return f"""
ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„ã€å¤©æ–‡å­¦å…‰è°±æŠ¥å‘Šå®¡æŸ¥å®˜ã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- å®¡æ ¸å…¶ä»– agent çš„å…‰è°±åˆ†æžæŠ¥å‘Šæˆ–æƒ³æ³•
- è¯†åˆ«å…¶ä¸­çš„é€»è¾‘æ¼æ´žã€è®¡ç®—æ¼æ´žã€ä¸ä¸€è‡´æˆ–é”™è¯¯æŽ¨æ–­
- æå‡ºä¿®æ­£æ„è§æˆ–è¡¥å……åˆ†æžæ–¹å‘

å·¥ä½œåŽŸåˆ™ï¼š
- ä¿æŒå®¢è§‚ä¸Žæ‰¹åˆ¤æ€§æ€ç»´
- ä¸é‡å¤åŽŸåˆ†æžï¼ŒåªæŒ‡å‡ºé—®é¢˜ä¸Žæ”¹è¿›å»ºè®®
- è‹¥åŽŸæŠ¥å‘Šåˆç†ï¼Œåº”æ˜Žç¡®ç¡®è®¤å…¶æœ‰æ•ˆæ€§
- æ¶‰åŠçº¢ç§»å’Œå…‰è°±è§‚æµ‹æ³¢é•¿çš„è®¡ç®—å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshift å’Œ  predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- è¯·è¾“å‡ºè¯´æ˜Žæ€§çš„è¯­è¨€
- ç®€æ˜Žåˆ—å‡ºå®¡æŸ¥æ„è§ï¼ˆä¾‹å¦‚ï¼šâ€œç»“è®ºåæ—©â€ï¼Œâ€œè°±çº¿è§£é‡Šæ­£ç¡®â€ï¼‰
- å¯¹æ¯ä¸ªå‘çŽ°é™„ä¸Šæ”¹è¿›å»ºè®®
- æœ€åŽç»™å‡ºæ•´ä½“è¯„ä»·ï¼ˆå¯é /éƒ¨åˆ†å¯ä¿¡/ä¸å¯ä¿¡ï¼‰

å·²çŸ¥ï¼šç»¼åˆåŽŸæ›²çº¿å’Œ sigma=2ã€sigma=4ã€sigma=16 ä¸‰æ¡é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºŽå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}

å…¶ä»–åˆ†æžå¸ˆç»™å‡ºçš„å…‰è°±åˆ†æžæŠ¥å‘Šä¸ºï¼š

{rule_analysis}

è¯¥æŠ¥å‘Šåœ¨çº¢ç§»è®¡ç®—æ—¶ä¿ç•™äº† 2 ä½å°æ•°ã€‚
"""
    
    async def auditing(self, ctx: str) -> str:
        header = self._common_prompt_header(ctx)

        body = f"""
è¯·å¯¹è¿™ä»½åˆ†æžæŠ¥å‘Šè¿›è¡Œæ£€æŸ¥ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context(prompt, parse_json=False, description="æŠ¥å‘Šå®¡æŸ¥")
        ctx.append('auditing_history', response)

    async def further_auditing(self, ctx: str) -> str:
        header = self._common_prompt_header(ctx)
        auditing_history_json = ctx.auditing_history[-1]
        response_history_json = ctx.refine_history[-1]

        body = f"""
ä½ å¯¹è¿™ä»½åˆ†æžæŠ¥å‘Šçš„æœ€æ–°è´¨ç–‘ä¸º
{auditing_history_json}

å…¶ä»–åˆ†æžå¸ˆçš„å›žç­”ä¸º
{response_history_json}

è¯·å›žåº”å…¶ä»–åˆ†æžå¸ˆçš„å›žç­”ï¼Œå¹¶ç»§ç»­è¿›è¡Œå®¡æŸ¥ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context(prompt, parse_json=False, description="æŠ¥å‘Šå®¡æŸ¥")
        ctx.append('auditing_history', response)



# ---------------------------------------------------------
# 4. Reflective Analyst â€” è‡ªç”±å›žåº”å®¡æŸ¥å¹¶æ”¹è¿›
# ---------------------------------------------------------
class SpectralRefinementAssistant(BaseAgent):
    """æ”¹è¿›è€…ï¼šå›žåº”å®¡æŸ¥å¹¶æ”¹è¿›åˆ†æž"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Refinement Assistant',
            mcp_manager=mcp_manager
        )

    # def __init__(self, agents):
    #     self.main_agent = agents['main']

    def _common_prompt_header(self, ctx) -> str:
        peak_json = json.dumps(ctx.peaks[:10], ensure_ascii=False)
        trough_json = json.dumps(ctx.troughs, ensure_ascii=False)
        rule_analysis = "\n\n".join(str(item) for item in ctx.rule_analysis)
        return f"""
ä½ æ˜¯ä¸€ä½å…·å¤‡åæ€èƒ½åŠ›çš„ã€å¤©æ–‡å­¦å…‰è°±å†åˆ†æžå¸ˆã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- é˜…è¯»å¹¶ç†è§£ä»–äººçš„å…‰è°±åˆ†æžæŠ¥å‘Š
- é˜…è¯»å¹¶ç†è§£å®¡æŸ¥å®˜æå‡ºçš„åé¦ˆ
- å¯¹è‡ªèº«æˆ–ä»–äººå…ˆå‰çš„åˆ†æžè¿›è¡Œæ”¹è¿›
- æå‡ºæ–°çš„è§£é‡Šæˆ–ä¿®æ­£ç»“è®º

å·¥ä½œåŽŸåˆ™ï¼š
- è®¤çœŸå›žåº”æ¯æ¡åé¦ˆï¼Œé€ä¸€è¯´æ˜Žæ”¹è¿›ä¹‹å¤„
- å¦‚æžœè®¤ä¸ºåŽŸç»“è®ºæ­£ç¡®ï¼Œéœ€ç»™å‡ºå……åˆ†ç†ç”±
- æœ€ç»ˆè¾“å‡ºä¸€ä¸ªæ›´ä¸¥è°¨ã€å®Œå–„çš„åˆ†æžç‰ˆæœ¬
- æ¶‰åŠçº¢ç§»å’Œå…‰è°±è§‚æµ‹æ³¢é•¿çš„è®¡ç®—å¿…é¡»ä½¿ç”¨å·¥å…· calculate_redshift å’Œ  predict_obs_wavelengthã€‚ä¸å…è®¸è‡ªè¡Œè®¡ç®—ã€‚

è¾“å‡ºè¦æ±‚ï¼š
- è¯·è¾“å‡ºè¯´æ˜Žæ€§çš„è¯­è¨€
- åˆ—å‡ºæ”¶åˆ°çš„åé¦ˆåŠå¯¹åº”å›žåº”
- æä¾›æ”¹è¿›åŽçš„å…‰è°±åˆ†æžæ€»ç»“
- è¯´æ˜Žä¿®æ”¹å†…å®¹åŠå…¶ç§‘å­¦åˆç†æ€§

å·²çŸ¥ï¼šç»¼åˆåŽŸæ›²çº¿å’Œ sigma=2ã€sigma=4ã€sigma=16 ä¸‰æ¡é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚
å…³äºŽå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š
- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š
{peak_json}
- å¯èƒ½çš„å¸æ”¶çº¿ï¼š
{trough_json}
å…¶ä»–åˆ†æžå¸ˆç»™å‡ºçš„å…‰è°±åˆ†æžæŠ¥å‘Šä¸ºï¼š
{rule_analysis}

è¿™ä»½æŠ¥å‘Šåœ¨çº¢ç§»è®¡ç®—æ—¶ä¿ç•™äº† 2 ä½å°æ•°ã€‚
"""

    async def refine(self, ctx):
        header = self._common_prompt_header(ctx)
        auditing = ctx.auditing_history[-1]
        body = f"""
è´Ÿè´£æ ¸éªŒæŠ¥å‘Šçš„åˆ†æžå¸ˆç»™å‡ºçš„æœ€æ–°å»ºè®®ä¸º
{auditing}

è¯·å¯¹å»ºè®®è¿›è¡Œå›žåº”ã€‚
"""
        prompt = header + body
        response = await self.call_llm_with_context(prompt, parse_json=False, description="å›žåº”å®¡æŸ¥")
        ctx.append('refine_history', response)



# ---------------------------------------------------------
# ðŸ§© 5. Host Integrator â€” æ±‡æ€»ä¸Žæ€»ç»“å¤šæ–¹è§‚ç‚¹
# ---------------------------------------------------------
from typing import Union
class SpectralSynthesisHost(BaseAgent):
    """æ±‡æ€»ä¸»æŒäººï¼šæ•´åˆå¤šAgentçš„åˆ†æžä¸Žç»“è®º"""

    def __init__(self, mcp_manager: MCPManager):
        super().__init__(
            agent_name='Spectral Synthesis Host',
            mcp_manager=mcp_manager
        )

    def get_system_prompt(self) -> str:
        return f"""
ä½ æ˜¯ä¸€ä½è´Ÿè´£ç»Ÿç­¹çš„ã€å¤©æ–‡å­¦å…‰è°±åˆ†æžä¸»æŒäººã€‘ã€‚

ä»»åŠ¡ç›®æ ‡ï¼š
- æ±‡æ€»è§†è§‰åˆ†æžå¸ˆã€è§„åˆ™åˆ†æžå¸ˆã€å®¡æŸ¥å®˜å’Œå†åˆ†æžå¸ˆçš„æ‰€æœ‰è¾“å‡º
- ç»¼åˆä¸åŒè§’åº¦çš„ç»“è®ºï¼Œå½¢æˆæœ€ç»ˆçš„å…‰è°±è§£é‡Š
- æ¸…æ¥šæŒ‡å‡ºå„æ–¹æ„è§çš„å·®å¼‚ä¸Žä¸€è‡´ç‚¹

å·¥ä½œåŽŸåˆ™ï¼š
- æ— éœ€è°ƒç”¨å·¥å…·
- ä¸ç›²ä»Žä»»ä½•å•ä¸€åˆ†æž
- ä¿æŒæ•´ä½“ç§‘å­¦æ€§ä¸Žé€»è¾‘ä¸€è‡´æ€§
- æœ€ç»ˆè¾“å‡ºå¿…é¡»å…·å¤‡å¯è¿½æº¯æ€§ï¼ˆè¯´æ˜Žæ¥è‡ªå“ªäº›agentçš„ä¾æ®ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- è¾“å‡ºè¯´æ˜Žæ€§æ–‡å­—
- è¾“å‡ºæ•°æ®ä¿ç•™2ä½å°æ•°
- åªéœ€è¾“å‡ºåˆ†æžå†…å®¹ï¼Œæ— éœ€å£°æ˜Žå„æ®µåˆ†æžæ–‡å­—çš„æ¥æº
- ç»™å‡ºæœ€ç»ˆç»¼åˆç»“è®ºåŠå¯ä¿¡åº¦è¯„çº§ï¼ˆé«˜/ä¸­/ä½Žï¼‰
- å¦‚æžœä»å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·æ˜Žç¡®æŒ‡å‡º
"""


    def summary(self, ctx) -> str:
        visual_interpretation_json = json.dumps(ctx.visual_interpretation, ensure_ascii=False)
        rule_analysis = "\n\n".join(str(item) for item in ctx.rule_analysis)
        rule_analysis_json = json.dumps(rule_analysis, ensure_ascii=False)
        auditing = "\n\n".join(str(item) for item in ctx.auditing_history)
        auditing_json = json.dumps(auditing, ensure_ascii=False)
        refine = "\n\n".join(str(item) for item in ctx.refine_history)
        refine_json = json.dumps(refine, ensure_ascii=False)

        header = self.get_system_prompt()

        prompt = f"""

å¯¹å…‰è°±çš„è§†è§‰æè¿°
{visual_interpretation_json}

è§„åˆ™åˆ†æžå¸ˆçš„è§‚ç‚¹ï¼š
{rule_analysis_json}

å®¡æŸ¥å®˜çš„è§‚ç‚¹ï¼š
{auditing_json}

å†åˆ†æžå¸ˆçš„è§‚ç‚¹ï¼š
{refine_json}

è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š

- å…‰è°±çš„è§†è§‰ç‰¹ç‚¹
- åˆ†æžæŠ¥å‘Šï¼ˆç»¼åˆè§„åˆ™åˆ†æžå¸ˆã€å®¡æŸ¥å®˜å’Œå†åˆ†æžå¸ˆçš„æ‰€æœ‰è¾“å‡ºï¼Œé€ä¸ª Step è¿›è¡Œç»“æž„åŒ–è¾“å‡ºï¼‰
- ç»“è®º
    - è¯¥å¤©ä½“çš„å¤©ä½“ç±»åž‹å’Œçº¢ç§» z Â± Î”z
    - è®¤è¯å‡ºçš„è°±çº¿ï¼ˆè¾“å‡º è°±çº¿å-Î»_rest-Î»_obsï¼‰
    - å…‰è°±çš„ä¿¡å™ªæ¯”å¦‚ä½•
    - åˆ†æžæŠ¥å‘Šçš„å¯ä¿¡åº¦è¯„åˆ†ï¼ˆå¦‚æžœèƒ½è®¤è¯å‡º2æ¡ä»¥ä¸Šçš„è°±çº¿ï¼Œåˆ™å¯ä¿¡åº¦ä¸ºâ€œé«˜â€ï¼›èƒ½è®¤è¯å‡º1æ¡è°±çº¿ï¼Œå¯ä¿¡åº¦ä¸ºâ€œä¸­â€ï¼›å…¶ä»–æƒ…å†µä¸ºâ€œä½Žâ€ï¼‰
    - æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥åˆ¤æ–­
"""
        return header + prompt

    async def run(self, ctx: SpectroContext) -> str:
        prompt = self.summary(ctx)
        response = await self.call_llm_with_context(prompt, parse_json=False, description="æ€»ç»“")
        ctx.set('summary', response)