{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from .context_manager import SpectroState\n",
    "from .base_agent import BaseAgent\n",
    "from .mcp_manager import MCPManager\n",
    "\n",
    "from .utils import (\n",
    "    _detect_axis_ticks, _detect_chart_border, _crop_img,\n",
    "    _remap_to_cropped_canvas, _pixel_tickvalue_fitting,\n",
    "    _process_and_extract_curve_points, _convert_to_spectrum,\n",
    "    _find_features_multiscale, _plot_spectrum, _plot_features,\n",
    "    parse_list, getenv_float, getenv_int, _load_feature_params, \n",
    "    _ROI_features_finding, merge_features, plot_merged_features, safe_to_bool, find_overlap_regions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralRuleAnalyst(BaseAgent):\n",
    "    \"\"\"\n",
    "    è§„åˆ™é©±åŠ¨å‹åˆ†æå¸ˆï¼šåŸºäºç»™å®šçš„ç‰©ç†ä¸è°±çº¿çŸ¥è¯†è¿›è¡Œå®šæ€§åˆ†æ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mcp_manager: MCPManager):\n",
    "        super().__init__(\n",
    "            agent_name='Spectral Rule Analyst',\n",
    "            mcp_manager=mcp_manager\n",
    "        )\n",
    "\n",
    "    async def describe_spectrum_picture(self, state: SpectroState):\n",
    "        function_prompt = state['prompt'][f'{self.agent_name}']['describe_spectrum_picture']\n",
    "        async def _filter_noise(state):\n",
    "            band_name = state['band_name']\n",
    "            band_wavelength = state['band_wavelength']\n",
    "\n",
    "            if not band_name or not band_wavelength:\n",
    "                return {\n",
    "    \"filter_noise\": 'false',\n",
    "    \"filter_noise_wavelength\": None\n",
    "}\n",
    "            else:\n",
    "                # æ‰¾å‡ºé‡å åŒºåŸŸ\n",
    "                overlap_regions = find_overlap_regions(band_name, band_wavelength)\n",
    "                spec = state['spectrum']\n",
    "                wl = np.array(spec['new_wavelength'])\n",
    "                ceiling = np.array(spec['max_unresolved_flux'])\n",
    "                floor = np.array(spec['min_unresolved_flux'])\n",
    "                delta = ceiling - floor\n",
    "\n",
    "                system_prompt = function_prompt['_filter_noise']['system_prompt']\n",
    "                band_name_json = json.dumps(band_name, ensure_ascii=False)\n",
    "                ham = f\"\"\"\n",
    "æœ¬å…‰è°±çš„ camera/filters åä¸º\n",
    "{band_name_json}\n",
    "ä¸‹é¢æ˜¯å…‰è°±åœ¨ camera/filters äº¤ç•ŒåŒºåŸŸçš„æ ·æœ¬æ•°æ®ã€‚\n",
    "\"\"\"\n",
    "                for key in overlap_regions.keys():\n",
    "                    overlap = overlap_regions[key]\n",
    "                    scale = overlap[1] - overlap[0]\n",
    "                    scale = scale * 2\n",
    "                    center = (overlap[0] + overlap[1]) / 2\n",
    "                    left = center - scale / 2\n",
    "                    right = center + scale / 2\n",
    "                    mask = (wl >= left) & (wl <= right)\n",
    "                    wl_t = wl[mask]\n",
    "                    wl_t = wl_t.tolist()\n",
    "                    wl_t_json = json.dumps(wl_t, ensure_ascii=False)\n",
    "                    delta_t = delta[mask]\n",
    "                    delta_t = delta_t.tolist()\n",
    "                    delta_t_json = json.dumps(delta_t, ensure_ascii=False)\n",
    "\n",
    "                    ham += f\"\"\"\n",
    "äº¤ç•ŒåŒºåŸŸ {key}:\n",
    "æ³¢é•¿ï¼š{wl_t_json}\n",
    "Flux è¯¯å·®ï¼š{delta_t_json}\n",
    "\"\"\"\n",
    "                user_prompt = function_prompt['_filter_noise']['user_prompt']\n",
    "                user_prompt = ham + user_prompt\n",
    "\n",
    "                response = await self.call_llm_with_context(\n",
    "                    system_prompt=system_prompt,\n",
    "                    user_prompt=user_prompt,\n",
    "                    image_path=None,\n",
    "                    parse_json=True,\n",
    "                    description=\"Filterå™ªå£°åˆ¤æ–­\"\n",
    "                )\n",
    "                return(response)\n",
    "            \n",
    "        async def _cleaning(state):\n",
    "            filter_nosie = state['visual_interpretation'][0]\n",
    "            if not safe_to_bool(filter_nosie.get('filter_noise', False)):\n",
    "                pass\n",
    "            else:\n",
    "                filter_noise_wl = filter_nosie.get('filter_noise_wavelength', [])\n",
    "                # filter_noise_wl_json = json.dumps(filter_noise_wl, ensure_ascii=False)\n",
    "                wavelength = state['spectrum']['new_wavelength']\n",
    "                flux = state['spectrum']['new_flux']\n",
    "                peaks = state['merged_peaks']\n",
    "                continuum = state['continuum']['flux']\n",
    "                cleaned_peaks = []\n",
    "                for p in peaks[:20]:\n",
    "                    # index = p['rep_index']\n",
    "                    wl = p['wavelength']\n",
    "                    flux = p['mean_flux']\n",
    "                    width_in_km_s = p['width_in_km_s']\n",
    "                    width = p['width_mean']\n",
    "                    wl_left = wl - width / 2\n",
    "                    wl_right = wl + width / 2\n",
    "                    mask = (wavelength >= wl_left) & (wavelength <= wl_right)\n",
    "                    ctnm = continuum[mask]\n",
    "                    ctnm = ctnm.tolist()\n",
    "                    ctnm_json = json.dumps(ctnm, ensure_ascii=False)\n",
    "                    flx = flux[mask]\n",
    "\n",
    "                    distance = abs(wl - filter_noise_wl)\n",
    "                    # å¦‚æœåœ¨distanceä¸­è‡³å°‘æœ‰ä¸€ä¸ªå€¼å°äº widthï¼Œåˆ™è®¤ä¸ºè¯¥å³°åœ¨å™ªå£°åŒºåŸŸå†…\n",
    "                    if np.any(distance <= width):\n",
    "                        is_artifact = True\n",
    "\n",
    "                    system_prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªå¤©æ–‡å­¦å…‰è°±åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯†åˆ«å…‰è°±åˆ†æä¸­å¯èƒ½å‡ºç°çš„ä¼ªå³°å€¼ã€‚\n",
    "ä½¿ç”¨scipyæ‰¾å³°ç®—æ³•å¯¹å…‰è°±è¿›è¡Œè¯†åˆ«æ—¶ï¼Œå¯èƒ½ä¼šå°†ä¸¤ä¸ªå¸æ”¶çº¿ä¹‹é—´çš„è¿ç»­åŒºåŸŸè¯¯è®¤ä¸ºå³°å€¼ã€‚\n",
    "è¿™ç±»ä¼ªå³°å€¼é€šå¸¸å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼šè¾ƒä¸ºå¹³å¦ã€æµé‡æ¥è¿‘è¿ç»­è°±ã€å³°å€¼å®½åº¦è¾ƒå®½ï¼ˆ>2000 km/sï¼‰ã€‚\n",
    "\n",
    "è¯·æ ¹æ®æä¾›çš„å³°å€¼ä¿¡æ¯åˆ¤æ–­å…¶æ˜¯å¦ä¸ºè¿ç»­åŒºåŸŸçš„ä¼ªå³°å€¼ï¼Œå¹¶ä¸¥æ ¼æŒ‰ä»¥ä¸‹è§„åˆ™è¾“å‡ºï¼š\n",
    "- å¦‚æœæ˜¯ä¼ªå³°å€¼ï¼Œè¾“å‡º \"true\"\n",
    "- å¦‚æœä¸æ˜¯ä¼ªå³°å€¼ï¼Œè¾“å‡º \"false\"\n",
    "ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚\n",
    "\"\"\"\n",
    "                    user_prompt = f\"\"\"\n",
    "è¯·åˆ†æä»¥ä¸‹å³°å€¼ä¿¡æ¯ï¼š\n",
    "- æ³¢é•¿ï¼š{wl} Ã…\n",
    "- æµé‡ï¼š{flux}\n",
    "- å®½åº¦ï¼š{width} Ã… ï¼ˆçº¦ {width_in_km_s} km/sï¼‰\n",
    "- å³°å€¼åŒºåŸŸçš„è¿ç»­è°±æµé‡åˆ—è¡¨ï¼š{ctnm_json}\n",
    "- å³°å€¼åŒºåŸŸçš„æµé‡åˆ—è¡¨ï¼š{flx}\n",
    "\"\"\"\n",
    "                    response = await self.call_llm_with_context(\n",
    "                        system_prompt=system_prompt,\n",
    "                        user_prompt=user_prompt,\n",
    "                        image_path=None,\n",
    "                        parse_json=True,\n",
    "                        description=\"ä¼ªå³°å€¼åˆ¤æ–­\"\n",
    "                    )\n",
    "                    is_continuum = safe_to_bool(response)\n",
    "\n",
    "                    if not is_continuum and not is_artifact:\n",
    "                        if p['width_in_km_s'] > 2000:\n",
    "                            p['describe'] = 'å®½çº¿'\n",
    "                        elif p['width_in_km_s'] < 1000:\n",
    "                            p['describe'] = 'çª„çº¿'\n",
    "                        else:\n",
    "                            p['describe'] = 'ä¸­ç­‰å®½åº¦'\n",
    "                        cleaned_peaks.append(p)\n",
    "                state['cleaned_peaks'] = cleaned_peaks\n",
    "                cleaned_troughs = []\n",
    "                for t in state['merged_troughs']:\n",
    "                    wl = t['wavelength']\n",
    "                    distance = abs(wl - filter_noise_wl)\n",
    "                    if np.any(distance <= width):\n",
    "                        is_artifact = True\n",
    "                    if not is_artifact:\n",
    "                        if t['width_in_km_s'] > 2000:\n",
    "                            t['describe'] = 'å®½è°·'\n",
    "                        elif t['width_in_km_s'] < 1000:\n",
    "                            t['describe'] = 'çª„è°·'\n",
    "                        else:\n",
    "                            t['describe'] = 'ä¸­ç­‰å®½åº¦'\n",
    "                        cleaned_troughs.append(t)\n",
    "                state['cleaned_troughs'] = cleaned_troughs\n",
    "            return state\n",
    "\n",
    "        async def _visual(state):\n",
    "            system_prompt = function_prompt['_visual']['system_prompt']\n",
    "            user_prompt_1 = function_prompt['_visual']['user_prompt_continuum']\n",
    "            response_1 = await self.call_llm_with_context(\n",
    "                system_prompt=system_prompt,\n",
    "                user_prompt=user_prompt_1,\n",
    "                image_path=state['continuum_path'],\n",
    "                parse_json=True,\n",
    "                description=\"è§†è§‰å…‰è°±å®šæ€§æè¿°â€”â€”continuum\"\n",
    "            )\n",
    "\n",
    "            user_prompt_2 = function_prompt['_visual']['user_prompt_lines']\n",
    "            response_2 = await self.call_llm_with_context(\n",
    "                system_prompt=system_prompt,\n",
    "                user_prompt=user_prompt_2,\n",
    "                image_path=state['spec_extract_path'],\n",
    "                parse_json=True,\n",
    "                description=\"è§†è§‰å…‰è°±å®šæ€§æè¿°\"\n",
    "            )\n",
    "\n",
    "            user_prompt_3 = function_prompt['_visual']['user_prompt_quality']\n",
    "            response_3 = await self.call_llm_with_context(\n",
    "                system_prompt=system_prompt,\n",
    "                user_prompt=user_prompt_3,\n",
    "                image_path=state['spec_extract_path'],\n",
    "                parse_json=True,\n",
    "                description=\"è§†è§‰å…‰è°±å®šæ€§æè¿°\"\n",
    "            )\n",
    "            return '\\n'.join([response_1, response_2, response_3])\n",
    "\n",
    "        # async def _get_ROI(state):\n",
    "        #     _visual_json = json.dumps(state['visual_interpretation'][1], ensure_ascii=False)\n",
    "        #     system_prompt = function_prompt['_get_ROI']['system_prompt']\n",
    "        #     user_prompt = function_prompt['_get_ROI']['user_prompt'].format(_visual_json=_visual_json)\n",
    "\n",
    "        #     response_2 = await self.call_llm_with_context(\n",
    "        #         system_prompt=system_prompt,\n",
    "        #         user_prompt=user_prompt,\n",
    "        #         parse_json=True,\n",
    "        #         description=\"è§†è§‰å…‰è°±å®šæ€§æè¿°\"\n",
    "        #     )\n",
    "        #     return response_2\n",
    "\n",
    "        async def _integrate(state):\n",
    "            # filter_noise_json = json.dumps(state['visual_interpretation'][0], ensure_ascii=False)\n",
    "            visual_json       = json.dumps(state['visual_interpretation'][1], ensure_ascii=False)\n",
    "            # roi_json          = json.dumps(state['visual_interpretation'][2], ensure_ascii=False)\n",
    "\n",
    "            system_prompt = function_prompt['_integrate']['system_prompt']\n",
    "            ham = f\"\"\"\n",
    "{visual_json}\n",
    "\"\"\"\n",
    "            user_prompt_integrate = function_prompt['_integrate']['user_prompt'] + ham\n",
    "            response = await self.call_llm_with_context(\n",
    "                system_prompt=system_prompt,\n",
    "                user_prompt=user_prompt_integrate,\n",
    "                parse_json=True,\n",
    "                description=\"è§†è§‰å…‰è°±å®šæ€§æè¿°\"\n",
    "            )\n",
    "            return response\n",
    "\n",
    "        result_filter_noise = await _filter_noise(state)\n",
    "        state['visual_interpretation'] = [result_filter_noise]\n",
    "        await _cleaning(state)\n",
    "        result_visual = await _visual(state)\n",
    "        state['visual_interpretation'].append(result_visual)\n",
    "        # result_ROI = await _get_ROI(state)\n",
    "        # state['visual_interpretation'].append(result_ROI)\n",
    "        result_integrate = await _integrate(state)\n",
    "        state['visual_interpretation'] = result_integrate\n",
    "\n",
    "        visual_interpretation_path = os.path.join(state['output_dir'], f'{state['image_name']}_visual_interpretation.txt')\n",
    "        with open(visual_interpretation_path, 'w', encoding='utf-8') as f:\n",
    "            json_str = json.dumps(state['visual_interpretation'], indent=2, ensure_ascii=False)\n",
    "            f.write(json_str)\n",
    "    \n",
    "    async def preliminary_classification(self, state: SpectroState) -> str:\n",
    "        \"\"\"åˆæ­¥åˆ†ç±»ï¼šæ ¹æ®å…‰è°±å½¢æ€åˆæ­¥åˆ¤æ–­å¤©ä½“ç±»å‹\"\"\"\n",
    "\n",
    "        visual_interpretation_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)\n",
    "        sigma_list_json = json.dumps(state['sigma_list'], ensure_ascii=False)\n",
    "        peaks_info = [\n",
    "            {\n",
    "                \"wavelength\": pe.get('wavelength'),\n",
    "                \"flux\": pe.get('mean_flux'),\n",
    "                \"width\": pe.get('width_mean'),\n",
    "                \"prominance\": pe.get('max_prominence'),\n",
    "                # \"seen_in_scales_of_sigma\": pe.get('seen_in_scales_of_sigma'),\n",
    "            }\n",
    "            for pe in state.get('merged_peaks', [])[:10]\n",
    "        ]\n",
    "        peak_json = json.dumps(peaks_info, ensure_ascii=False)\n",
    "        trough_info = [\n",
    "            {\n",
    "                \"wavelength\": tr.get('wavelength'),\n",
    "                \"flux\": tr.get('mean_flux'),\n",
    "                \"width\": tr.get('width_mean'),\n",
    "                # \"seen_in_scales_of_sigma\": tr.get('seen_in_scales_of_sigma')\n",
    "            }\n",
    "            for tr in state.get('merged_troughs', [])[:15]\n",
    "        ]\n",
    "        trough_json = json.dumps(trough_info, ensure_ascii=False)\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚\n",
    "\n",
    "ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å…‰è°±çš„å®šæ€§æè¿°å’Œç‰¹å¾æ•°æ®ï¼ŒçŒœæµ‹å¤©ä½“å¯èƒ½å±äºçš„ç±»åˆ«ã€‚\n",
    "\n",
    "å¯é€‰çš„ç±»åˆ«ï¼š\n",
    "1. **Star**ï¼š\n",
    "    - è¿ç»­è°±è¾ƒå¼ºï¼Œè°±çº¿é€šå¸¸æ˜¯å¸æ”¶çº¿ï¼ˆå¦‚ Balmer ç³»åˆ—ã€é‡‘å±çº¿ç­‰ï¼‰ï¼Œå‡ ä¹æ²¡æœ‰æ˜æ˜¾çº¢ç§»ã€‚\n",
    "2. **Galaxy**ï¼š\n",
    "    - æœ‰ä¸€å®šçº¢ç§»ï¼Œå¸¸æœ‰å‘å°„çº¿æˆ–å¸æ”¶çº¿ã€‚\n",
    "    - è°±çº¿é€šå¸¸è¾ƒçª„ã€‚\n",
    "    - è¿ç»­è°±è¾ƒä¸æ˜æ˜¾ã€‚\n",
    "    - éƒ¨åˆ†æ˜Ÿç³»çš„è¿ç»­è°±å‘ˆç°è“ç«¯è¾ƒä½è€Œçº¢ç«¯æ˜¾è‘—å‡é«˜çš„è¶‹åŠ¿ã€‚\n",
    "3. **QSO**ï¼š\n",
    "    - å…·æœ‰**å¼ºå‘å°„çº¿**ã€‚è°±çº¿å®½åº¦æ˜æ˜¾ã€‚\n",
    "    - è¿ç»­è°±è¦†ç›–å¯è§/ç´«å¤–æ³¢æ®µã€‚\n",
    "    - é€šå¸¸æœ‰æ˜æ˜¾çº¢ç§»ã€‚\n",
    "\n",
    "è¾“å‡ºè¦æ±‚ï¼š\n",
    "- æ¯ä¸ªçŒœæµ‹åŒ…å«ï¼šç±»åˆ«ã€ç†ç”±ã€ç½®ä¿¡åº¦\n",
    "- ä¸è¾“å‡ºç²¾ç¡®æ•°å€¼æˆ–è¡¨æ ¼\n",
    "- ä¸å°è¯•è®¡ç®—çº¢ç§»\n",
    "- é‡ç‚¹åœ¨è§†è§‰ä¸å½¢æ€æè¿°ï¼Œåƒäººç±»å¤©æ–‡å­¦å®¶ä¸€æ ·è¿›è¡Œå®šæ€§åˆ¤æ–­\n",
    "- ä¸è¦è°ƒç”¨å·¥å…·\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "çŒœæµ‹ 1ï¼š\n",
    "- **ç±»åˆ«**: Star / Galaxy / QSO ï¼ˆä¸‰é€‰ä¸€ï¼‰\n",
    "- **ç†ç”±**: ç”¨ç®€æ´çš„è¯­è¨€è§£é‡Šåˆ†ç±»åŸå› ï¼ˆå¦‚è°±çº¿å®½åº¦ã€çº¢ç§»ç‰¹å¾ã€è¿ç»­è°±å½¢æ€ï¼‰\n",
    "- **ç½®ä¿¡åº¦**: é«˜ / ä¸­ / ä½\n",
    "çŒœæµ‹ 2ï¼š\n",
    "...\n",
    "\"\"\"\n",
    "        user_prompt = f\"\"\"\n",
    "è¯·æ ¹æ®ä»¥ä¸‹å…‰è°±æ•°æ®è¿›è¡Œåˆ†æï¼š\n",
    "\n",
    "å‰ä¸€ä½å¤©æ–‡å­¦åŠ©æ‰‹å·²ç»å®šæ€§åœ°æè¿°äº†å…‰è°±çš„æ•´ä½“å½¢æ€ï¼š\n",
    "{visual_interpretation_json}\n",
    "å…¶ä¸­ filter noise æ˜¯å› ä¸ºåœ¨ä¸åŒ filterï¼ˆå¦‚ B,R,Zï¼‰é‡å å¤„å‡ºç°çš„éç‰©ç†çš„å™ªå£°ã€‚\n",
    "\n",
    "åœ¨å…¨å±€ä¸Šï¼Œç»¼åˆåŸæ›²çº¿å’Œ sigma={sigma_list_json} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚\n",
    "åœ¨ ROI (region of interest) ä¸Šï¼Œç»¼åˆå±€éƒ¨çš„åŸæ›²çº¿å’Œ sigma={sigma_list_json} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚\n",
    "\n",
    "å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š\n",
    "- ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š\n",
    "{peak_json}\n",
    "- å¯èƒ½çš„å¸æ”¶çº¿ï¼š\n",
    "{trough_json}\n",
    "\n",
    "è¯·æ ¹æ®è¿™äº›æè¿°å’Œæ•°æ®ï¼ŒçŒœæµ‹è¯¥å…‰è°±å¯èƒ½å±äºå“ªä¸€ç±»æˆ–å‡ ç±»å¤©ä½“ã€‚\n",
    "\"\"\"\n",
    "        response = await self.call_llm_with_context(\n",
    "            system_prompt = system_prompt,\n",
    "            user_prompt = user_prompt,\n",
    "            image_path=state['image_path'],\n",
    "            parse_json=True,\n",
    "            description=\"åˆæ­¥åˆ†ç±»\"\n",
    "        )\n",
    "        state['preliminary_classification'] = response\n",
    "\n",
    "    async def preliminary_classification_monkey(self, state):\n",
    "        \"\"\" My dear monkey friend and its typewriter \"\"\"\n",
    "        preliminary_classification_json = json.dumps(state['preliminary_classification'], ensure_ascii=False)\n",
    "        prompt = f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªå¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚\n",
    "ä½ æ¥æ”¶åˆ°çš„æ˜¯å…¶ä»–åŠ©æ‰‹å¯¹ä¸€å¼ å…‰è°±çš„å…‰æºç±»åˆ«çš„åˆæ­¥çŒœæµ‹ï¼š\n",
    "{preliminary_classification_json}\n",
    "\n",
    "è¯·è¾“å‡ºè¿™ä»½çŒœæµ‹é‡Œç»™å‡ºçš„å…‰æºç±»åˆ«ã€‚\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ä¸ºæ•°ç»„ List[str]ï¼Œæ•°ç»„çš„å…ƒç´ å¿…é¡»åœ¨ \"Star\", \"Galaxy\" å’Œ \"QSO\" ä¸­é€‰æ‹©ã€‚\n",
    "\n",
    "- æ³¨æ„ï¼šå³ä½¿åªæœ‰ä¸€ä¸ªæ»¡è¶³æ¡ä»¶çš„å…‰æºç±»åˆ«ï¼Œä¹Ÿè¦ä»¥ List[str] çš„æ ¼å¼è¾“å‡ºã€‚\n",
    "\"\"\"\n",
    "        response = await self.call_llm_with_context(\n",
    "            system_prompt = '',\n",
    "            user_prompt = prompt,\n",
    "            parse_json=True,\n",
    "            description=\"åˆæ­¥åˆ†ç±»çŒ´å­\"\n",
    "        )\n",
    "        return response\n",
    "    ###################################\n",
    "    # QSO part\n",
    "    ###################################\n",
    "    async def _QSO(self, state):\n",
    "        \"\"\"QSO\"\"\"\n",
    "        def _common_prompt_header_QSO(state, include_rule_analysis=True, include_step_1_only=False):\n",
    "            \"\"\"æ„é€ æ¯ä¸ª step å…¬å…±çš„ prompt å‰æ®µ\"\"\"\n",
    "            visual_json = json.dumps(state['visual_interpretation'], ensure_ascii=False)\n",
    "            # peak_json = json.dumps(state['peaks'][:10], ensure_ascii=False)\n",
    "            # trough_json = json.dumps(state['troughs'], ensure_ascii=False)\n",
    "            peaks_info = [\n",
    "                {\n",
    "                    \"wavelength\": pe.get('wavelength'),\n",
    "                    \"flux\": pe.get('mean_flux'),\n",
    "                    \"width\": pe.get('width_mean'),\n",
    "                    \"prominance\": pe.get('max_prominence'),\n",
    "                    \"seen_in_scales_of_sigma\": pe.get('seen_in_scales_of_sigma'),\n",
    "                }\n",
    "                for pe in state.get('merged_peaks', [])[:10]\n",
    "            ]\n",
    "            peak_json = json.dumps(peaks_info, ensure_ascii=False)\n",
    "            trough_info = [\n",
    "                {\n",
    "                    \"wavelength\": tr.get('wavelength'),\n",
    "                    \"flux\": tr.get('mean_flux'),\n",
    "                    \"width\": tr.get('width_mean'),\n",
    "                    \"seen_in_scales_of_sigma\": tr.get('seen_in_scales_of_sigma')\n",
    "                }\n",
    "                for tr in state.get('merged_troughs', [])[:15]\n",
    "            ]\n",
    "            trough_json = json.dumps(trough_info, ensure_ascii=False)\n",
    "\n",
    "            header = f\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä½å¤©æ–‡å­¦å…‰è°±åˆ†æåŠ©æ‰‹ã€‚\n",
    "\n",
    "    ä»¥ä¸‹ä¿¡æ¯å¯èƒ½æ¥è‡ªäºä¸€ä¸ªæœªçŸ¥çº¢ç§»çš„ QSO å…‰è°±ã€‚\n",
    "\n",
    "    ä¹‹å‰çš„åŠ©æ‰‹å·²ç»å¯¹è¿™ä¸ªå…‰è°±è¿›è¡Œäº†åˆæ­¥æè¿°ï¼š\n",
    "    {visual_json}\n",
    "\n",
    "    è¯¥å…‰è°±çš„æ³¢é•¿èŒƒå›´æ˜¯{state['spectrum']['new_wavelength'][0]} Ã… åˆ° {state['spectrum']['new_wavelength'][-1]} Ã…ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "            if include_rule_analysis and state['rule_analysis_QSO']:\n",
    "                if include_step_1_only==True:\n",
    "                    rule_json = json.dumps(state['rule_analysis_QSO'][0], ensure_ascii=False)\n",
    "                else:\n",
    "                    rule_json = json.dumps(\"\\n\".join(str(item) for item in state['rule_analysis_QSO']), ensure_ascii=False)\n",
    "                header += f\"\\nä¹‹å‰çš„åŠ©æ‰‹å·²ç»è¿›è¡Œäº†ä¸€äº›åˆ†æ:\\n{rule_json}\\n\"\n",
    "\n",
    "            tol_pixels = getenv_int(\"TOL_PIXELS\", 10)\n",
    "            a_x = state['pixel_to_value']['x']['a']\n",
    "            tol_wavelength = a_x * tol_pixels\n",
    "            header += f\"\"\"\n",
    "    ç»¼åˆåŸæ›²çº¿å’Œ sigma={state['sigma_list']} çš„é«˜æ–¯å¹³æ»‘æ›²çº¿ï¼Œä½¿ç”¨ scipy å‡½æ•°è¿›è¡Œäº†å³°/è°·è¯†åˆ«ã€‚\n",
    "    å…³äºå³°/è°·çš„è®¨è®ºä»¥ä»¥ä¸‹æ•°æ®ä¸ºå‡†ï¼š\n",
    "    - ä»£è¡¨æ€§çš„å‰ 10 æ¡å‘å°„çº¿ï¼š\n",
    "    {peak_json}\n",
    "    - å¯èƒ½çš„å¸æ”¶çº¿ï¼š\n",
    "    {trough_json}\n",
    "    - æ³¢é•¿è¯¯å·®åœ¨ ~ Â±{tol_wavelength/2} Ã… çš„é‡çº§æˆ–æ›´å¤§\n",
    "    \"\"\"\n",
    "            return header\n",
    "\n",
    "        def _common_prompt_tail(step_title, extra_notes=\"\"):\n",
    "            \"\"\"æ„é€ æ¯ä¸ª step å…¬å…±å°¾éƒ¨ï¼Œä¿ç•™ step ç‰¹æœ‰è¾“å‡º/åˆ†ææŒ‡ç¤º\"\"\"\n",
    "            tail = f\"\"\"\n",
    "    ---\n",
    "\n",
    "    è¾“å‡ºæ ¼å¼ä¸ºï¼š\n",
    "    {step_title}\n",
    "    ...\n",
    "\n",
    "    ---\n",
    "\n",
    "    ğŸ§­ æ³¨æ„ï¼š\n",
    "    - è®¡ç®—å¾—æ¥çš„éåŸå§‹æ•°æ®ï¼Œè¾“å‡ºæ—¶ä¿ç•™ 3 ä½å°æ•°ã€‚\n",
    "    - ä¸éœ€è¦è¿›è¡Œé‡å¤æ€»ç»“ã€‚\n",
    "    - ä¸éœ€è¦é€è¡Œåœ°é‡å¤è¾“å…¥æ•°æ®ï¼›\n",
    "    - é‡ç‚¹åœ¨ç‰©ç†æ¨ç†ä¸åˆç†è§£é‡Šï¼›\n",
    "    - è¯·ä¿è¯æœ€ç»ˆè¾“å‡ºå®Œæ•´ï¼Œä¸è¦ä¸­é€”æˆªæ–­ã€‚\n",
    "    \"\"\"\n",
    "            if extra_notes:\n",
    "                tail = extra_notes + \"\\n\" + tail\n",
    "            return tail\n",
    "    \n",
    "        async def step_1_QSO(state):\n",
    "            header = _common_prompt_header_QSO(state, include_rule_analysis=False)\n",
    "            tail = _common_prompt_tail(\"Step 1: LyÎ± è°±çº¿æ£€æµ‹\")\n",
    "\n",
    "            prompt = header + \"\"\"\n",
    "è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æ:\n",
    "\n",
    "Step 1: LyÎ± è°±çº¿æ£€æµ‹\n",
    "å‡è®¾è¯¥å…‰è°±ä¸­å­˜åœ¨ LyÎ± å‘å°„çº¿ï¼ˆÎ»_rest = 1216 Ã…ï¼‰ï¼š\n",
    "1. åœ¨å…‰è°±è“ç«¯ï¼Œæµé‡è¾ƒå¤§ï¼Œä¸”æœ‰ä¸€å®šå®½åº¦çš„å³°ä¸­ï¼Œæ¨æµ‹å“ªæ¡æœ€å¯èƒ½ä¸º LyÎ± çº¿ï¼ˆä»æä¾›çš„å³°åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰ã€‚\n",
    "2. è¾“å‡ºï¼š\n",
    "- è§‚æµ‹æ³¢é•¿ Î»_obs\n",
    "- æµé‡ Flux\n",
    "- è°±çº¿å®½åº¦\n",
    "3. ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—è¯¥å³°ä¸º LyÎ± å‘å°„çº¿æ—¶çš„çº¢ç§» zã€‚\n",
    "4. æ£€æŸ¥è“ç«¯ï¼ˆçŸ­æ³¢é•¿æ–¹å‘ï¼‰æ˜¯å¦å­˜åœ¨ LyÎ± forest ç‰¹å¾ï¼šå¸æ”¶çº¿ç›¸å¯¹æ›´å¯†é›†ã€è¾ƒçª„ä¸”åˆ†å¸ƒåœ¨ LyÎ± è“ç«¯é™„è¿‘ã€‚è¯·æŒ‡å‡ºå¹¶è¿›è¡Œç®€çŸ­è¯´æ˜ã€‚\n",
    "\"\"\" + tail\n",
    "            \n",
    "            response = await self.call_llm_with_context(\n",
    "                system_prompt='', \n",
    "                user_prompt=prompt, \n",
    "                parse_json=True, \n",
    "                description=\"Step 1 LyÎ± åˆ†æ\"\n",
    "            )\n",
    "            state['rule_analysis_QSO'].append(response)\n",
    "\n",
    "        async def step_2_QSO(state):\n",
    "            header = _common_prompt_header_QSO(state)\n",
    "            tail = _common_prompt_tail(\"Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æ\")\n",
    "\n",
    "            prompt = header + \"\"\"\n",
    "è¯·ç»§ç»­åˆ†æ:\n",
    "\n",
    "Step 2: å…¶ä»–æ˜¾è‘—å‘å°„çº¿åˆ†æ\n",
    "1. åœ¨ Step 1 å¾—åˆ°çš„çº¢ç§»ä¸‹ï¼Œä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—ä»¥ä¸‹ä¸‰æ¡ä¸»è¦å‘å°„çº¿ï¼šC IV 1549, C III] 1909, Mg II 2799 åœ¨å…‰è°±ä¸­çš„ç†è®ºä½ç½®ã€‚\n",
    "2. å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸ä¸‰è€…ç›¸åŒ¹é…çš„å³°ï¼Ÿ\n",
    "3. å¦‚æœå­˜åœ¨å‘å°„çº¿ä¸è§‚æµ‹å³°å€¼çš„åŒ¹é…ï¼Œæ ¹æ®åŒ¹é…ç»“æœï¼Œåˆ†åˆ«ä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—çº¢ç§»ã€‚æŒ‰â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¾“å‡ºã€‚\n",
    "\"\"\" + tail\n",
    "\n",
    "            response = await self.call_llm_with_context('', prompt, parse_json=False, description=\"Step 2 å‘å°„çº¿åˆ†æ\")\n",
    "            state['rule_analysis_QSO'].append(response)\n",
    "\n",
    "        async def step_3_QSO(state):\n",
    "            header = _common_prompt_header_QSO(state)\n",
    "            tail = _common_prompt_tail(\"Step 3: ç»¼åˆåˆ¤æ–­\")\n",
    "\n",
    "            prompt = header + \"\"\"\n",
    "è¯·ç»§ç»­åˆ†æ:\n",
    "\n",
    "Step 3: ç»¼åˆåˆ¤æ–­\n",
    "1. åœ¨ Step 1 åˆ° Step 2 ä¸­ï¼Œå¦‚æœï¼š\n",
    "    - C IV å’Œ C III] ä¸¤æ¡ä¸»è¦è°±çº¿å­˜åœ¨ç¼ºå¤±æˆ–å¤§å¹…åç§»\n",
    "    - ä½¿ç”¨ lyÎ± è°±çº¿è®¡ç®—çš„çº¢ç§»ä¸å…¶ä»–è°±çº¿çš„è®¡ç®—ç»“æœä¸ä¸€è‡´ï¼Œ\n",
    "æ­¤æ—¶è¯·è¾“å‡ºâ€œåº”ä¼˜å…ˆå‡è®¾ LyÎ± è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·â€ï¼Œå¹¶ç»“æŸ Step 3 çš„åˆ†æã€‚ä¸è¦è¾“å‡ºå…¶ä»–ä¿¡æ¯ã€‚\n",
    "2.ä»…åœ¨æœ‰æ˜¾è‘—çš„ LyÎ± å³°å€¼ï¼Œä¸”çº¢ç§»è®¡ç®—ç»“æœä¸å…¶ä»–è°±çº¿åŸºæœ¬ä¸€è‡´æ—¶ï¼Œè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š\n",
    "    - å› ä¸ºå¤©æ–‡å­¦ä¸­å­˜åœ¨å¤–æµç­‰ç°è±¡ï¼Œè¯·å°†å½“å‰æ‰€æœ‰åŒ¹é…ä¸­**æœ€ä½ç”µç¦»æ€è°±çº¿çš„çº¢ç§»**ä½œä¸ºå…‰è°±çš„çº¢ç§»ã€‚è¾“å‡ºçº¢ç§»ç»“æœã€‚ï¼ˆå› ä¸ºå­˜åœ¨ä¸å¯¹ç§°å’Œå±•å®½ï¼ŒLyÎ±çš„ç½®ä¿¡åº¦æ˜¯è¾ƒä½çš„ï¼‰\n",
    "\"\"\" + tail\n",
    "\n",
    "            response = await self.call_llm_with_context('', prompt, parse_json=False, description=\"Step 3 ç»¼åˆåˆ¤æ–­\")\n",
    "            state['rule_analysis_QSO'].append(response)\n",
    "            \n",
    "        async def step_4_QSO(state):\n",
    "            header = _common_prompt_header_QSO(state, include_step_1_only=True)\n",
    "            tail = _common_prompt_tail(\"Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ Step 1 æ‰€é€‰æ‹©çš„è°±çº¿å¹¶é LyÎ±ï¼‰\")\n",
    "\n",
    "            prompt = header + \"\"\"\n",
    "è¯·ç»§ç»­åˆ†æ:\n",
    "\n",
    "Step 4: è¡¥å……æ­¥éª¤ï¼ˆå‡è®¾ Step 1 æ‰€é€‰æ‹©çš„è°±çº¿å¹¶é LyÎ±ï¼‰\n",
    "- è¯·æŠ›å¼€å‰è¿°æ­¥éª¤çš„åˆ†æå†…å®¹ã€‚è€ƒè™‘ Step 1 æ‰€é€‰æ‹©çš„è°±çº¿å®é™…ä¸Šæ˜¯é™¤ LyÎ± å¤–çš„å…¶ä»–ä¸»è¦å‘å°„çº¿ã€‚\n",
    "    - å‡è®¾è¯¥å³°å€¼å¯èƒ½å¯¹åº”çš„è°±çº¿ä¸º C IVï¼š\n",
    "        - è¾“å‡ºè¯¥å³°å¯¹åº”è°±çº¿çš„ä¿¡æ¯ï¼š\n",
    "            - è§‚æµ‹æ³¢é•¿ Î»_obs\n",
    "            - æµé‡ Flux\n",
    "            - è°±çº¿å®½åº¦\n",
    "            - æ ¹æ® Î»_restï¼Œä½¿ç”¨å·¥å…· calculate_redshift åˆæ­¥è®¡ç®—çº¢ç§» z\n",
    "        - ä½¿ç”¨å·¥å…· predict_obs_wavelength è®¡ç®—åœ¨æ­¤çº¢ç§»ä¸‹çš„å…¶ä»–ä¸»è¦å‘å°„çº¿ï¼ˆå¦‚ C III] å’Œ Mg IIï¼‰çš„ç†è®ºä½ç½®ã€‚å…‰è°±ä¸­æ˜¯å¦æœ‰ä¸å®ƒä»¬åŒ¹é…çš„å‘å°„çº¿ï¼Ÿ\n",
    "        - å¦‚æœå­˜åœ¨å¯èƒ½çš„å‘å°„çº¿-è§‚æµ‹æ³¢é•¿åŒ¹é…ç»“æœï¼Œä½¿ç”¨å·¥å…· calculate_redshift è®¡ç®—å®ƒä»¬çš„çº¢ç§»ã€‚æŒ‰ç…§â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€çš„æ ¼å¼è¿›è¡Œè¾“å‡º\n",
    "    \n",
    "    - è‹¥ä»¥ä¸Šå‡è®¾ä¸åˆç†ï¼Œåˆ™å‡è®¾è¯¥å³°å€¼å¯èƒ½å¯¹åº” C III] ç­‰å…¶ä»–ä¸»è¦è°±çº¿ï¼Œé‡å¤æ¨æ–­ã€‚\n",
    "\n",
    "    - ç»¼åˆ Step 4 çš„æ‰€æœ‰åˆ†æï¼Œç»™å‡ºï¼š\n",
    "        - **æœ€ä½ç”µç¦»æ€è°±çº¿çš„çº¢ç§»** ä½œä¸ºå…‰è°±çº¢ç§»\n",
    "        - è¾“å‡º â€œå‘å°„çº¿å--é™æ­¢ç³»æ³¢é•¿--è§‚æµ‹æ³¢é•¿--çº¢ç§»â€ åŒ¹é…\n",
    "\n",
    "- æ³¨æ„ï¼šå…è®¸åœ¨ç”±äºå…‰è°±è¾¹ç¼˜çš„ä¿¡å·æ®‹ç¼ºæˆ–ä¿¡å™ªæ¯”ä¸ä½³å¯¼è‡´éƒ¨åˆ†å‘å°„çº¿ä¸å¯è§ã€‚   \n",
    "- æŠ›å¼€å…¶ä»–æ­¥éª¤çš„åˆ†æå†…å®¹ï¼Œæœ¬èŠ‚çš„åˆ¤æ–­æ˜¯å¦æ”¯æŒ LyÎ± è°±çº¿æœªè¢«æ‰¾å³°ç¨‹åºæ•è·çš„å‡è®¾ï¼Ÿ\n",
    "\"\"\" + tail\n",
    "\n",
    "            response = await self.call_llm_with_context('', prompt, parse_json=False, description=\"Step 4 è¡¥å……åˆ†æ\")\n",
    "            state['rule_analysis_QSO'].append(response)\n",
    "        \n",
    "        await step_1_QSO(state)\n",
    "        await step_2_QSO(state)\n",
    "        await step_3_QSO(state)\n",
    "        await step_4_QSO(state)\n",
    "\n",
    "#     # --------------------------\n",
    "#     # Run å…¨æµç¨‹\n",
    "#     # --------------------------\n",
    "    async def run(self, state: SpectroState):\n",
    "        \"\"\"æ‰§è¡Œè§„åˆ™åˆ†æå®Œæ•´æµç¨‹\"\"\"\n",
    "        try:\n",
    "            await self.describe_spectrum_picture(state)\n",
    "            ROI_peaks, ROI_troughs = _ROI_features_finding(state)\n",
    "            # print(f\"ROI_peaks:\\n{ROI_peaks}\")\n",
    "            # print(f\"ROI_troughs:\\n{ROI_troughs}\")\n",
    "            state['merged_peaks'], state['merged_troughs'] = merge_features(\n",
    "                global_peaks=state['peaks'],\n",
    "                global_troughs=state['troughs'],\n",
    "                ROI_peaks=ROI_peaks,\n",
    "                ROI_troughs=ROI_troughs, \n",
    "                tol_pixels=10,\n",
    "            )\n",
    "            \n",
    "            plot_merged_features(state)\n",
    "            \n",
    "            await self.preliminary_classification(state)\n",
    "            # print(state['preliminary_classification'])\n",
    "\n",
    "            _shakespear = await self.preliminary_classification_monkey(state)\n",
    "            state['possible_object'] = _shakespear\n",
    "            # print(f\"Monkeys types: {_shakespear}\")\n",
    "\n",
    "            if \"QSO\" in _shakespear:\n",
    "                await self._QSO(state)\n",
    "                # await self.step_1_QSO(state)\n",
    "                # await self.step_2_QSO(state)\n",
    "                # await self.step_3_QSO(state)\n",
    "                # await self.step_4_QSO(state)\n",
    "            # if \"Galaxy\" in _shakespear:\n",
    "            #     await self.step_1_galaxy(state)\n",
    "            #     await self.step_2_galaxy(state)\n",
    "            #     await self.step_3_galaxy(state)\n",
    "            #     await self.step_4_galaxy(state)\n",
    "            #     await self.step_5_galaxy(state)\n",
    "            return state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(\"âŒ An error occurred during spectral analysis:\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            print(\"Full traceback:\")\n",
    "            traceback.print_exc()\n",
    "            # å¯é€‰ï¼šè¿”å›å½“å‰çŠ¶æ€æˆ–æŠ›å‡ºå¼‚å¸¸\n",
    "            raise  # å¦‚æœä½ å¸Œæœ›è°ƒç”¨è€…ä¹Ÿèƒ½æ•è·è¯¥å¼‚å¸¸\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
